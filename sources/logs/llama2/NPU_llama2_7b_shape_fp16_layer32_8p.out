Using /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...
Emitting ninja build file /root/.cache/torch_extensions/py37_cpu/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.2315211296081543 seconds
[2023-10-10 15:06:19,010] [WARNING] [runner.py:191:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-10-10 15:06:19,011] [INFO] [runner.py:541:main] cmd = /home/anaconda3/envs/lkl_llama2_main/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None pretrain_llama.py --finetune --checkpoint-activations --use-fused-rotary-pos-emb --triangle-attn --DDP-impl local --tensor-model-parallel-size 1 --pipeline-model-parallel-size 1 --num-layers 32 --hidden-size 4096 --ffn-hidden-size 11008 --num-attention-heads 32 --micro-batch-size 4 --global-batch-size 32 --seq-length 4096 --max-position-embeddings 4096 --train-iters 500000 --lr-decay-iters 320000 --save ./ckpt --load ./ckpt --data-path ./dataset/llama_text_document --tokenizer-name-or-path ./dataset/llama/ --tokenizer-not-use-fast --data-impl mmap --split 949,50,1 --distributed-backend nccl --lr 0.0003 --lr-decay-style cosine --min-lr 3.0e-5 --weight-decay 1.0e-1 --clip-grad 1.0 --lr-warmup-iters 5000 --log-interval 1 --save-interval 10000 --eval-interval 1000 --eval-iters 10 --adam-beta1 0.9 --adam-beta2 0.95 --adam-eps 1.0e-5 --initial-loss-scale 4096.0 --deepspeed-activation-checkpointing --zero-stage=2 --deepspeed_config=deepspeed_config_7B.json --no-pipeline-parallel --deepspeed --fp16
[2023-10-10 15:06:23,553] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2023-10-10 15:06:23,553] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=8, node_rank=0
[2023-10-10 15:06:23,553] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2023-10-10 15:06:23,553] [INFO] [launch.py:247:main] dist_world_size=8
[2023-10-10 15:06:23,554] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
Using /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...
Using /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...
Using /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...
Using /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...
Using /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...
Using /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...
Using /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...
Emitting ninja build file /root/.cache/torch_extensions/py37_cpu/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Using /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...
Loading extension module utils...
Time to load utils op: 0.2472376823425293 seconds
Loading extension module utils...
Time to load utils op: 0.20342445373535156 seconds
Loading extension module utils...Loading extension module utils...

Time to load utils op: 0.2030017375946045 secondsTime to load utils op: 0.2030467987060547 seconds

Loading extension module utils...
Time to load utils op: 0.20280671119689941 seconds
Loading extension module utils...
Time to load utils op: 0.30301928520202637 seconds
Loading extension module utils...
Time to load utils op: 0.10325908660888672 seconds
Loading extension module utils...
Time to load utils op: 0.3025202751159668 seconds
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
Failed to import torch_npu and megatron_npu
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
Failed to import torch_npu and megatron_npu
[warning] torch.jit.script is disabled in this version...[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...

[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...

[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...[warning] torch.jit.script is disabled in this version...

[warning] torch.jit.script is disabled in this version...[warning] torch.jit.script is disabled in this version...

Failed to import torch_npu and megatron_npuFailed to import torch_npu and megatron_npu

[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
Failed to import torch_npu and megatron_npu
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
Failed to import torch_npu and megatron_npu
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...[warning] torch.jit.script is disabled in this version...

[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
[warning] torch.jit.script is disabled in this version...
Failed to import torch_npu and megatron_npuFailed to import torch_npu and megatron_npu

using world size: 8, data-parallel-size: 8, tensor-model-parallel size: 1, pipeline-model-parallel size: 1 
using torch.float16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. False
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.95
  adam_eps ........................................ 1e-05
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  aml_data_download_path .......................... None
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_load ....................................... None
  bf16 ............................................ False
  bias_dropout_fusion ............................. True
  bias_gelu_fusion ................................ True
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  checkpoint_activations .......................... True
  checkpoint_block_layer .......................... 25
  checkpoint_in_cpu ............................... False
  checkpoint_num_layers ........................... 1
  checkpoint_policy ............................... full
  clip_grad ....................................... 1.0
  compression_training ............................ False
  consumed_train_samples .......................... 0
  consumed_train_tokens ........................... 0
  consumed_valid_samples .......................... 0
  contigious_checkpointing ........................ False
  cpu_optimizer ................................... False
  cpu_torch_adam .................................. False
  create_moe_param_group .......................... False
  curriculum_learning_legacy ...................... False
  custom_token_counting ........................... False
  data_efficiency_curriculum_learning ............. False
  data_impl ....................................... mmap
  data_parallel_size .............................. 8
  data_path ....................................... ['./dataset/llama_text_document']
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_seq_length .............................. None
  deepscale ....................................... False
  deepscale_config ................................ None
  deepspeed ....................................... True
  deepspeed_activation_checkpointing .............. True
  deepspeed_config ................................ deepspeed_config_7B.json
  deepspeed_mpi ................................... False
  distribute_checkpointed_activations ............. False
  distributed_backend ............................. nccl
  ds_inference .................................... False
  ds_pipeline_enabled ............................. False
  embed_layernorm ................................. False
  embedding_path .................................. None
  enable_expert_tensor_parallelism ................ False
  encoder_seq_length .............................. 4096
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  expert_interval ................................. 2
  ffn_hidden_size ................................. 11008
  finetune ........................................ True
  foldx_mode ...................................... None
  fp16 ............................................ True
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  global_batch_size ............................... 32
  group_query_attention ........................... False
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 4096
  hidden_size_teacher ............................. None
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_dim ......................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference ....................................... False
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4096.0
  is_instruction_dataset .......................... False
  kd .............................................. False
  kd_alpha_ce ..................................... 1
  kd_beta_ce ...................................... 1
  kd_temp ......................................... 1.0
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ ./ckpt
  load_teacher .................................... None
  local_rank ...................................... 0
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 1
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_num_zeros_in_grad ........................... False
  log_optimizer_states_to_tensorboard ............. False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  lora_adapter_name ............................... default
  lora_alpha ...................................... 32
  lora_load ....................................... None
  lora_modules_to_save ............................ None
  lora_r .......................................... 16
  lora_register_forward_hook ...................... ['word_embeddings', 'input_layernorm']
  lora_target_modules ............................. []
  loss_on_targets_only ............................ False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.0003
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_decay_tokens ................................. None
  lr_warmup_fraction .............................. None
  lr_warmup_iters ................................. 5000
  lr_warmup_samples ............................... 0
  lr_warmup_tokens ................................ None
  make_vocab_size_divisible_by .................... 128
  manual_layers ................................... None
  manual_mbs ...................................... 
  mask_prob ....................................... 0.15
  masked_softmax_fusion ........................... True
  max_position_embeddings ......................... 4096
  memory_centric_tiled_linear ..................... False
  merge_file ...................................... None
  micro_batch_size ................................ 4
  min_loss_scale .................................. 1.0
  min_lr .......................................... 3e-05
  mlp_layer_fusion ................................ False
  mlp_type ........................................ standard
  mmap_warmup ..................................... False
  moe_eval_capacity_factor ........................ 1.0
  moe_expert_parallel_size ........................ 1
  moe_loss_coeff .................................. 0.1
  moe_min_capacity ................................ 4
  moe_token_dropping .............................. True
  moe_train_capacity_factor ....................... 1.0
  mos ............................................. False
  no_load_lr_state ................................ False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_pipeline_parallel ............................ True
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 32
  num_attention_heads_teacher ..................... None
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... [1]
  num_experts_teacher ............................. [1]
  num_layers ...................................... 32
  num_layers_per_virtual_pipeline_stage ........... None
  num_layers_teacher .............................. None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimized_pipeline .............................. False
  optimizer ....................................... adam
  overlap_p2p_comm ................................ False
  override_lr_scheduler ........................... False
  pad_vocab_size_to ............................... None
  params_dtype .................................... torch.float16
  partition_activations ........................... False
  patch_dim ....................................... 16
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  position_embedding_type ......................... PositionEmbeddingType.absolute
  profile_backward ................................ False
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  random_ltd ...................................... False
  rank ............................................ 0
  remote_device ................................... none
  reset_attention_mask ............................ False
  reset_iteration ................................. False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  return_data_index ............................... False
  sample_rate ..................................... 1.0
  save ............................................ ./ckpt
  save_interval ................................... 10000
  scatter_gather_tensors_in_pipeline .............. True
  scattered_embeddings ............................ False
  seed ............................................ 1234
  seq_length ...................................... 4096
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  split_transformers .............................. False
  swiglu .......................................... False
  synchronize_each_layer .......................... False
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_weighted_split_names ....................... None
  test_weighted_split_paths ....................... None
  test_weighted_split_paths_path .................. None
  test_weighted_split_splits ...................... None
  test_weighted_split_weights ..................... None
  tile_factor ..................................... 1
  timing_log_level ................................ 0
  timing_log_option ............................... flatten
  titles_data_path ................................ None
  tokenizer_name_or_path .......................... ./dataset/llama/
  tokenizer_not_use_fast .......................... False
  tokenizer_type .................................. PretrainedFromHF
  topk ............................................ 1
  train_data_exact_num_epochs ..................... None
  train_doc_idx_path .............................. None
  train_idx_path .................................. None
  train_iters ..................................... 500000
  train_sample_idx_path ........................... None
  train_samples ................................... None
  train_shuffle_idx_path .......................... None
  train_tokens .................................... None
  train_weighted_split_paths ...................... None
  train_weighted_split_paths_path ................. None
  triangle_attn ................................... True
  use_checkpoint_lr_scheduler ..................... False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... False
  use_fused_rotary_pos_emb ........................ True
  use_manual_layer_allocation ..................... False
  use_one_sent_docs ............................... False
  use_pin_memory .................................. False
  use_tutel ....................................... False
  valid_weighted_split_names ...................... None
  valid_weighted_split_paths ...................... None
  valid_weighted_split_paths_path ................. None
  valid_weighted_split_splits ..................... None
  valid_weighted_split_weights .................... None
  virtual_pipeline_model_parallel_size ............ None
  vocab_extra_ids ................................. 0
  vocab_file ...................................... None
  weight_decay .................................... 0.1
  world_size ...................................... 8
  zero_allgather_bucket_size ...................... 0.0
  zero_contigious_gradients ....................... False
  zero_reduce_bucket_size ......................... 0.0
  zero_reduce_scatter ............................. False
  zero_stage ...................................... 2
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 1
> building PretrainedFromHF tokenizer ...
 vocab file is un-used. loading tokenizer from pre-trained model
 > padded vocab (size: 32000) with 0 dummy tokens (new size: 32000)
> initializing torch distributed ...
[2023-10-10 15:06:40,144] [INFO] [comm.py:622:init_distributed] Initializing TorchBackend in DeepSpeed with backend hccl
> initializing tensor model parallel with size 1
> initializing pipeline model parallel with size 1
> setting random seeds to 1234 ...
[2023-10-10 15:06:41,639] [INFO] [checkpointing.py:231:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
> compiling dataset index builder ...
make: Entering directory '/npu/l00562083/Baseline/LLaMA2/AscendSpeed/AscendSpeed/ascendspeed/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/npu/l00562083/Baseline/LLaMA2/AscendSpeed/AscendSpeed/ascendspeed/data'
>>> done with dataset index builder. Compilation time: 0.098 seconds
time to initialize ascendspeed (seconds): 4.493
[after ascendspeed is initialized] datetime: 2023-10-10 15:06:44 
Building llama model ...
[2023-10-10 15:06:45,110] [INFO] [utils.py:785:see_memory_usage] Before Building Model ...
[2023-10-10 15:06:45,131] [INFO] [utils.py:789:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB 
[2023-10-10 15:06:45,133] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 74.67 GB, percent = 14.9%
[2023-10-10 15:06:47,396] [INFO] [utils.py:785:see_memory_usage] After Building Model
[2023-10-10 15:06:47,398] [INFO] [utils.py:789:see_memory_usage] MA 12.55 GB         Max_MA 12.55 GB         CA 12.87 GB         Max_CA 13 GB 
[2023-10-10 15:06:47,404] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 76.2 GB, percent = 15.2%
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 6738415616
> learning rate decay style: cosine
DeepSpeed is enabled.
[2023-10-10 15:06:47,414] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.2, git-hash=unknown, git-branch=unknown
[2023-10-10 15:06:50,747] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-10-10 15:06:50,749] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-10-10 15:06:50,749] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
Using /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0007607936859130859 seconds
Using /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...
[2023-10-10 15:06:50,761] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
[2023-10-10 15:06:50,761] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'ascendspeed.optimizer.adam.AdamW'>
[2023-10-10 15:06:50,761] [WARNING] [engine.py:1104:_do_optimizer_sanity_check] **** You are using ZeRO with an untested optimizer, proceed with caution *****
Time to load utils op: 0.0008351802825927734 seconds
[2023-10-10 15:06:50,761] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer
[2023-10-10 15:06:50,762] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 100000000
[2023-10-10 15:06:50,762] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 100000000
[2023-10-10 15:06:50,762] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: False
[2023-10-10 15:06:50,762] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False
Using /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...
Using /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0007052421569824219 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0007734298706054688 seconds
Using /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...
Time to load utils op: 0.0008263587951660156 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0007703304290771484 seconds
Using /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0005948543548583984 seconds
Using /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.001012563705444336 seconds
Rank: 3 partition count [8] and sizes[(842301952, False)] 
Rank: 4 partition count [8] and sizes[(842301952, False)] 
--Rank: 1 partition count [8] and sizes[(842301952, False)] 
-Rank: 6 partition count [8] and sizes[(842301952, False)] 
-Rank: 5 partition count [8] and sizes[(842301952, False)] 
-Rank: 7 partition count [8] and sizes[(842301952, False)] 
-Rank: 0 partition count [8] and sizes[(842301952, False)] 
-Rank: 2 partition count [8] and sizes[(842301952, False)] 
-Using /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0007798671722412109 seconds
Using /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...Using /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...

No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0009903907775878906 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0015230178833007812 seconds
Using /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...
Time to load utils op: 0.0013203620910644531 secondsUsing /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...

No modifications detected for re-loaded extension module utils, skipping build step...No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...

Loading extension module utils...
Time to load utils op: 0.0009331703186035156 seconds
Time to load utils op: 0.0011415481567382812 seconds
Using /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.002575397491455078 seconds
\\\\\[2023-10-10 15:07:51,621] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-10-10 15:07:51,622] [INFO] [utils.py:789:see_memory_usage] MA 15.72 GB         Max_MA 17.29 GB         CA 17.3 GB         Max_CA 17 GB 
[2023-10-10 15:07:51,622] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 76.44 GB, percent = 15.2%
[2023-10-10 15:07:51,809] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-10-10 15:07:51,810] [INFO] [utils.py:789:see_memory_usage] MA 22.0 GB         Max_MA 25.14 GB         CA 26.72 GB         Max_CA 27 GB 
[2023-10-10 15:07:51,810] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 76.44 GB, percent = 15.2%
[2023-10-10 15:07:51,810] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized
[2023-10-10 15:07:51,969] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-10-10 15:07:51,970] [INFO] [utils.py:789:see_memory_usage] MA 22.0 GB         Max_MA 22.0 GB         CA 26.72 GB         Max_CA 27 GB 
[2023-10-10 15:07:51,971] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 76.44 GB, percent = 15.2%
[2023-10-10 15:07:51,975] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW
[2023-10-10 15:07:51,975] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-10-10 15:07:51,976] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <ascendspeed.learning_rates.AnnealingLR object at 0xffff3674d290>
[2023-10-10 15:07:51,976] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[(0.9, 0.95)]
[2023-10-10 15:07:51,977] [INFO] [config.py:955:print] DeepSpeedEngine configuration:
[2023-10-10 15:07:51,977] [INFO] [config.py:959:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-10-10 15:07:51,977] [INFO] [config.py:959:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-10-10 15:07:51,977] [INFO] [config.py:959:print]   amp_enabled .................. False
[2023-10-10 15:07:51,977] [INFO] [config.py:959:print]   amp_params ................... False
[2023-10-10 15:07:51,978] [INFO] [config.py:959:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-10-10 15:07:51,978] [INFO] [config.py:959:print]   bfloat16_enabled ............. False
[2023-10-10 15:07:51,978] [INFO] [config.py:959:print]   checkpoint_parallel_write_pipeline  False
[2023-10-10 15:07:51,978] [INFO] [config.py:959:print]   checkpoint_tag_validation_enabled  True
[2023-10-10 15:07:51,978] [INFO] [config.py:959:print]   checkpoint_tag_validation_fail  False
[2023-10-10 15:07:51,978] [INFO] [config.py:959:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0xffff38d48850>
[2023-10-10 15:07:51,978] [INFO] [config.py:959:print]   communication_data_type ...... None
[2023-10-10 15:07:51,978] [INFO] [config.py:959:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-10-10 15:07:51,978] [INFO] [config.py:959:print]   curriculum_enabled_legacy .... False
[2023-10-10 15:07:51,978] [INFO] [config.py:959:print]   curriculum_params_legacy ..... False
[2023-10-10 15:07:51,978] [INFO] [config.py:959:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-10-10 15:07:51,978] [INFO] [config.py:959:print]   data_efficiency_enabled ...... False
[2023-10-10 15:07:51,978] [INFO] [config.py:959:print]   dataloader_drop_last ......... False
[2023-10-10 15:07:51,978] [INFO] [config.py:959:print]   disable_allgather ............ False
[2023-10-10 15:07:51,978] [INFO] [config.py:959:print]   dump_state ................... False
[2023-10-10 15:07:51,979] [INFO] [config.py:959:print]   dynamic_loss_scale_args ...... {'init_scale': 256, 'scale_window': 1000, 'delayed_shift': 2, 'min_scale': 1}
[2023-10-10 15:07:51,979] [INFO] [config.py:959:print]   eigenvalue_enabled ........... False
[2023-10-10 15:07:51,979] [INFO] [config.py:959:print]   eigenvalue_gas_boundary_resolution  1
[2023-10-10 15:07:51,979] [INFO] [config.py:959:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-10-10 15:07:51,979] [INFO] [config.py:959:print]   eigenvalue_layer_num ......... 0
[2023-10-10 15:07:51,979] [INFO] [config.py:959:print]   eigenvalue_max_iter .......... 100
[2023-10-10 15:07:51,979] [INFO] [config.py:959:print]   eigenvalue_stability ......... 1e-06
[2023-10-10 15:07:51,979] [INFO] [config.py:959:print]   eigenvalue_tol ............... 0.01
[2023-10-10 15:07:51,979] [INFO] [config.py:959:print]   eigenvalue_verbose ........... False
[2023-10-10 15:07:51,979] [INFO] [config.py:959:print]   elasticity_enabled ........... False
[2023-10-10 15:07:51,979] [INFO] [config.py:959:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-10-10 15:07:51,979] [INFO] [config.py:959:print]   fp16_auto_cast ............... False
[2023-10-10 15:07:51,979] [INFO] [config.py:959:print]   fp16_enabled ................. True
[2023-10-10 15:07:51,979] [INFO] [config.py:959:print]   fp16_master_weights_and_gradients  False
[2023-10-10 15:07:51,979] [INFO] [config.py:959:print]   global_rank .................. 0
[2023-10-10 15:07:51,979] [INFO] [config.py:959:print]   grad_accum_dtype ............. None
[2023-10-10 15:07:51,979] [INFO] [config.py:959:print]   gradient_accumulation_steps .. 1
[2023-10-10 15:07:51,979] [INFO] [config.py:959:print]   gradient_clipping ............ 0.0
[2023-10-10 15:07:51,979] [INFO] [config.py:959:print]   gradient_predivide_factor .... 1.0
[2023-10-10 15:07:51,979] [INFO] [config.py:959:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-10-10 15:07:51,979] [INFO] [config.py:959:print]   initial_dynamic_scale ........ 256
[2023-10-10 15:07:51,979] [INFO] [config.py:959:print]   load_universal_checkpoint .... False
[2023-10-10 15:07:51,979] [INFO] [config.py:959:print]   loss_scale ................... 0
[2023-10-10 15:07:51,980] [INFO] [config.py:959:print]   memory_breakdown ............. False
[2023-10-10 15:07:51,980] [INFO] [config.py:959:print]   mics_hierarchial_params_gather  False
[2023-10-10 15:07:51,980] [INFO] [config.py:959:print]   mics_shard_size .............. -1
[2023-10-10 15:07:51,980] [INFO] [config.py:959:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-10-10 15:07:51,980] [INFO] [config.py:959:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-10-10 15:07:51,980] [INFO] [config.py:959:print]   optimizer_legacy_fusion ...... False
[2023-10-10 15:07:51,980] [INFO] [config.py:959:print]   optimizer_name ............... adam
[2023-10-10 15:07:51,980] [INFO] [config.py:959:print]   optimizer_params ............. None
[2023-10-10 15:07:51,980] [INFO] [config.py:959:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-10-10 15:07:51,980] [INFO] [config.py:959:print]   pld_enabled .................. False
[2023-10-10 15:07:51,980] [INFO] [config.py:959:print]   pld_params ................... False
[2023-10-10 15:07:51,980] [INFO] [config.py:959:print]   prescale_gradients ........... False
[2023-10-10 15:07:51,980] [INFO] [config.py:959:print]   scheduler_name ............... None
[2023-10-10 15:07:51,980] [INFO] [config.py:959:print]   scheduler_params ............. None
[2023-10-10 15:07:51,980] [INFO] [config.py:959:print]   sparse_attention ............. None
[2023-10-10 15:07:51,980] [INFO] [config.py:959:print]   sparse_gradients_enabled ..... False
[2023-10-10 15:07:51,980] [INFO] [config.py:959:print]   steps_per_print .............. 10
[2023-10-10 15:07:51,980] [INFO] [config.py:959:print]   train_batch_size ............. 32
[2023-10-10 15:07:51,980] [INFO] [config.py:959:print]   train_micro_batch_size_per_gpu  4
[2023-10-10 15:07:51,980] [INFO] [config.py:959:print]   use_node_local_storage ....... False
[2023-10-10 15:07:51,980] [INFO] [config.py:959:print]   wall_clock_breakdown ......... False
[2023-10-10 15:07:51,980] [INFO] [config.py:959:print]   world_size ................... 8
[2023-10-10 15:07:51,981] [INFO] [config.py:959:print]   zero_allow_untested_optimizer  True
[2023-10-10 15:07:51,981] [INFO] [config.py:959:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=100000000 allgather_partitions=True allgather_bucket_size=100000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-10-10 15:07:51,981] [INFO] [config.py:959:print]   zero_enabled ................. True
[2023-10-10 15:07:51,981] [INFO] [config.py:959:print]   zero_force_ds_cpu_optimizer .. True
[2023-10-10 15:07:51,981] [INFO] [config.py:959:print]   zero_optimization_stage ...... 2
[2023-10-10 15:07:51,981] [INFO] [config.py:951:print_user_config]   json = {
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "loss_scale_window": 1000, 
        "initial_scale_power": 8, 
        "hysteresis": 2, 
        "min_loss_scale": 1
    }, 
    "optimizer": {
        "type": "Adam"
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 1.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 1.000000e+08, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 4, 
    "zero_allow_untested_optimizer": true
}
Using /root/.cache/torch_extensions/py37_cpu as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0005261898040771484 seconds
	setup_model_and_optimizer : no_post_init_checkpoint_loading:False
	setup_model_and_optimizer : args.load:./ckpt
[2023-10-10 15:07:52,178] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:07:52,178] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:07:52,178] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:07:52,178] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:07:52,178] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:07:52,178] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:07:52,178] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:07:52,178] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:00,814] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:01,981] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:02,114] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:02,593] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:02,600] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:02,639] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:02,648] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:02,650] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:03,289] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:03,906] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:03,978] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:04,039] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:04,062] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:04,094] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:04,128] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:05,453] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:09,996] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:12,408] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/zero_pp_rank_2_mp_rank_00_optim_states.pt...
[2023-10-10 15:08:12,552] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:13,308] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:14,048] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:14,276] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:14,467] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:14,470] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:14,771] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/zero_pp_rank_5_mp_rank_00_optim_states.pt...
[2023-10-10 15:08:15,796] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:15,896] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/zero_pp_rank_6_mp_rank_00_optim_states.pt...
[2023-10-10 15:08:16,737] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/zero_pp_rank_4_mp_rank_00_optim_states.pt...
[2023-10-10 15:08:18,019] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/zero_pp_rank_7_mp_rank_00_optim_states.pt...
[2023-10-10 15:08:23,094] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2023-10-10 15:08:26,528] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2023-10-10 15:08:26,727] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/zero_pp_rank_3_mp_rank_00_optim_states.pt...
could not find arguments in the checkpoint ...
 checkpoint version 3.0
  successfully loaded checkpoint from ./ckpt/mp_rank_00_model_states.pt at iteration 0
time (ms) | load-checkpoint: 44544.15
[2023-10-10 15:08:36,730] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:36,730] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:36,730] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:36,730] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:36,730] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:36,730] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:36,730] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:36,730] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:44,515] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:45,760] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:45,821] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:46,011] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:46,241] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:46,260] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:46,368] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:46,369] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:46,585] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:47,066] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:47,321] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:47,725] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:47,741] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:47,746] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:47,763] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:47,840] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/mp_rank_00_model_states.pt...
[2023-10-10 15:08:53,417] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:55,848] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/zero_pp_rank_2_mp_rank_00_optim_states.pt...
[2023-10-10 15:08:56,024] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:56,889] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:57,048] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:57,456] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:57,528] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:57,528] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:57,531] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from ./ckpt/release/mp_rank_00_model_states.pt.
[2023-10-10 15:08:58,280] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/zero_pp_rank_5_mp_rank_00_optim_states.pt...
[2023-10-10 15:08:59,459] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/zero_pp_rank_6_mp_rank_00_optim_states.pt...
[2023-10-10 15:08:59,628] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/zero_pp_rank_7_mp_rank_00_optim_states.pt...
[2023-10-10 15:09:00,314] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2023-10-10 15:09:00,420] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/zero_pp_rank_4_mp_rank_00_optim_states.pt...
[2023-10-10 15:09:01,769] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2023-10-10 15:09:01,790] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from ./ckpt/release/zero_pp_rank_3_mp_rank_00_optim_states.pt...
could not find arguments in the checkpoint ...
 checkpoint version 3.0
  successfully loaded checkpoint from ./ckpt/mp_rank_00_model_states.pt at iteration 0
time (ms) | load-checkpoint: 35758.56
[after model, optimizer, and learning rate scheduler are built] datetime: 2023-10-10 15:09:12 
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      16000000
    validation: 160320
    test:       320
> building train, validation, and test datasets for llama ...
 > building dataset index ...
    reading sizes...
    reading pointers...
    reading document index...
    creating numpy buffer of mmap...
    creating memory view of numpy buffer...
 > finished creating indexed dataset in 0.001121 seconds
    number of documents: 52002
 > dataset split:
    train:
     document indices in [0, 49350) total of 49350 documents
    validation:
     document indices in [49350, 51950) total of 2600 documents
    test:
     document indices in [51950, 52002) total of 52 documents
\|\|\||| > loading doc-idx mapping from ./dataset/llama_text_document_train_indexmap_16000000ns_4096sl_1234s_doc_idx.npy
 > loading sample-idx mapping from ./dataset/llama_text_document_train_indexmap_16000000ns_4096sl_1234s_sample_idx.npy
 > loading shuffle-idx mapping from ./dataset/llama_text_document_train_indexmap_16000000ns_4096sl_1234s_shuffle_idx.npy
    loaded indexed file in 0.002 seconds
    total number of samples: 16000548
    total number of epochs: 10450
 > loading doc-idx mapping from ./dataset/llama_text_document_valid_indexmap_160320ns_4096sl_1234s_doc_idx.npy
 > loading sample-idx mapping from ./dataset/llama_text_document_valid_indexmap_160320ns_4096sl_1234s_sample_idx.npy
 > loading shuffle-idx mapping from ./dataset/llama_text_document_valid_indexmap_160320ns_4096sl_1234s_shuffle_idx.npy
    loaded indexed file in 0.001 seconds
    total number of samples: 160329
    total number of epochs: 1962
 > loading doc-idx mapping from ./dataset/llama_text_document_test_indexmap_320ns_4096sl_1234s_doc_idx.npy
 > loading sample-idx mapping from ./dataset/llama_text_document_test_indexmap_320ns_4096sl_1234s_sample_idx.npy
 > loading shuffle-idx mapping from ./dataset/llama_text_document_test_indexmap_320ns_4096sl_1234s_shuffle_idx.npy
    loaded indexed file in 0.002 seconds
    total number of samples: 322
    total number of epochs: 189
> finished creating llama datasets ...
[after dataloaders are built] datetime: 2023-10-10 15:09:13 
done with setup ...
time (ms) | model-and-optimizer-setup: 147724.62 | train/valid/test-data-iterators-setup: 1199.34
training ...
[before the start of training step] datetime: 2023-10-10 15:09:13 
[2023-10-10 15:09:13,858] [INFO] [checkpointing.py:529:forward] Activation Checkpointing Information
[2023-10-10 15:09:13,859] [INFO] [checkpointing.py:530:forward] ----Partition Activations False, CPU CHECKPOINTING False
[2023-10-10 15:09:13,859] [INFO] [checkpointing.py:532:forward] ----contiguous Memory Checkpointing False with 32 total layers
[2023-10-10 15:09:13,859] [INFO] [checkpointing.py:533:forward] ----Synchronization False
[2023-10-10 15:09:13,859] [INFO] [checkpointing.py:534:forward] ----Profiling time in checkpointing False
Warning: torch.npu_confusion_transpose is deprecated and will be removed in future version. Use torch_npu.npu_confusion_transpose instead.
Warning: torch.npu_confusion_transpose is deprecated and will be removed in future version. Use torch_npu.npu_confusion_transpose instead.
Warning: torch.npu_confusion_transpose is deprecated and will be removed in future version. Use torch_npu.npu_confusion_transpose instead.
Warning: torch.npu_confusion_transpose is deprecated and will be removed in future version. Use torch_npu.npu_confusion_transpose instead.
Warning: torch.npu_confusion_transpose is deprecated and will be removed in future version. Use torch_npu.npu_confusion_transpose instead.
Warning: torch.npu_confusion_transpose is deprecated and will be removed in future version. Use torch_npu.npu_confusion_transpose instead.
Warning: torch.npu_confusion_transpose is deprecated and will be removed in future version. Use torch_npu.npu_confusion_transpose instead.
Warning: torch.npu_confusion_transpose is deprecated and will be removed in future version. Use torch_npu.npu_confusion_transpose instead.
|//|/|//--///----\\\\\--\|\|\||| iteration        1/  500000 | consumed samples:           32 | consumed tokens:       131072 | elapsed time per iteration (ms): 46599.3 | learning rate: 6.000E-08 | global batch size:    32 | lm loss: 1.533763E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.687 | TFLOPs: 21.42 |
[Rank 0] (after 1 iterations) memory (MB) | allocated: 22778.9990234375 | max allocated: 34440.755859375 | reserved: 39448.0 | max reserved: 39448.0time (ms)

 iteration        2/  500000 | consumed samples:           64 | consumed tokens:       262144 | elapsed time per iteration (ms): 6767.0 | learning rate: 1.200E-07 | global batch size:    32 | lm loss: 1.540085E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.49 |
time (ms)
 iteration        3/  500000 | consumed samples:           96 | consumed tokens:       393216 | elapsed time per iteration (ms): 6764.9 | learning rate: 1.800E-07 | global batch size:    32 | lm loss: 1.564673E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration        4/  500000 | consumed samples:          128 | consumed tokens:       524288 | elapsed time per iteration (ms): 6758.8 | learning rate: 2.400E-07 | global batch size:    32 | lm loss: 1.540816E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration        5/  500000 | consumed samples:          160 | consumed tokens:       655360 | elapsed time per iteration (ms): 6760.8 | learning rate: 3.000E-07 | global batch size:    32 | lm loss: 1.517753E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration        6/  500000 | consumed samples:          192 | consumed tokens:       786432 | elapsed time per iteration (ms): 6760.5 | learning rate: 3.600E-07 | global batch size:    32 | lm loss: 1.561824E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration        7/  500000 | consumed samples:          224 | consumed tokens:       917504 | elapsed time per iteration (ms): 6759.4 | learning rate: 4.200E-07 | global batch size:    32 | lm loss: 1.535515E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration        8/  500000 | consumed samples:          256 | consumed tokens:      1048576 | elapsed time per iteration (ms): 6760.9 | learning rate: 4.800E-07 | global batch size:    32 | lm loss: 1.525970E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration        9/  500000 | consumed samples:          288 | consumed tokens:      1179648 | elapsed time per iteration (ms): 6757.7 | learning rate: 5.400E-07 | global batch size:    32 | lm loss: 1.505133E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
[2023-10-10 15:11:01,062] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[6e-07], mom=[(0.9, 0.95)]
[2023-10-10 15:11:01,321] [INFO] [timer.py:208:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=4.742784310551268, CurrSamplesPerSec=4.743551865796843, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration       10/  500000 | consumed samples:          320 | consumed tokens:      1310720 | elapsed time per iteration (ms): 6759.4 | learning rate: 6.000E-07 | global batch size:    32 | lm loss: 1.439419E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration       11/  500000 | consumed samples:          352 | consumed tokens:      1441792 | elapsed time per iteration (ms): 6758.6 | learning rate: 6.600E-07 | global batch size:    32 | lm loss: 1.440082E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration       12/  500000 | consumed samples:          384 | consumed tokens:      1572864 | elapsed time per iteration (ms): 6762.1 | learning rate: 7.200E-07 | global batch size:    32 | lm loss: 1.389381E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration       13/  500000 | consumed samples:          416 | consumed tokens:      1703936 | elapsed time per iteration (ms): 6758.1 | learning rate: 7.800E-07 | global batch size:    32 | lm loss: 1.370391E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration       14/  500000 | consumed samples:          448 | consumed tokens:      1835008 | elapsed time per iteration (ms): 6756.6 | learning rate: 8.400E-07 | global batch size:    32 | lm loss: 1.322997E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration       15/  500000 | consumed samples:          480 | consumed tokens:      1966080 | elapsed time per iteration (ms): 6759.2 | learning rate: 9.000E-07 | global batch size:    32 | lm loss: 1.281799E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration       16/  500000 | consumed samples:          512 | consumed tokens:      2097152 | elapsed time per iteration (ms): 6758.2 | learning rate: 9.600E-07 | global batch size:    32 | lm loss: 1.280328E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration       17/  500000 | consumed samples:          544 | consumed tokens:      2228224 | elapsed time per iteration (ms): 6762.5 | learning rate: 1.020E-06 | global batch size:    32 | lm loss: 1.264356E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration       18/  500000 | consumed samples:          576 | consumed tokens:      2359296 | elapsed time per iteration (ms): 6755.2 | learning rate: 1.080E-06 | global batch size:    32 | lm loss: 1.235816E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration       19/  500000 | consumed samples:          608 | consumed tokens:      2490368 | elapsed time per iteration (ms): 6757.5 | learning rate: 1.140E-06 | global batch size:    32 | lm loss: 1.210260E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
[2023-10-10 15:12:08,698] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[1.2e-06], mom=[(0.9, 0.95)]
[2023-10-10 15:12:08,948] [INFO] [timer.py:208:stop] epoch=0/micro_step=20/global_step=20, RunningAvgSamplesPerSec=4.743273354236804, CurrSamplesPerSec=4.7445502498867045, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration       20/  500000 | consumed samples:          640 | consumed tokens:      2621440 | elapsed time per iteration (ms): 6757.9 | learning rate: 1.200E-06 | global batch size:    32 | lm loss: 1.181466E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration       21/  500000 | consumed samples:          672 | consumed tokens:      2752512 | elapsed time per iteration (ms): 6762.0 | learning rate: 1.260E-06 | global batch size:    32 | lm loss: 1.141603E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration       22/  500000 | consumed samples:          704 | consumed tokens:      2883584 | elapsed time per iteration (ms): 6759.2 | learning rate: 1.320E-06 | global batch size:    32 | lm loss: 1.114839E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration       23/  500000 | consumed samples:          736 | consumed tokens:      3014656 | elapsed time per iteration (ms): 6758.4 | learning rate: 1.380E-06 | global batch size:    32 | lm loss: 1.102191E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration       24/  500000 | consumed samples:          768 | consumed tokens:      3145728 | elapsed time per iteration (ms): 6760.7 | learning rate: 1.440E-06 | global batch size:    32 | lm loss: 1.067155E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration       25/  500000 | consumed samples:          800 | consumed tokens:      3276800 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.500E-06 | global batch size:    32 | lm loss: 1.052947E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration       26/  500000 | consumed samples:          832 | consumed tokens:      3407872 | elapsed time per iteration (ms): 6763.9 | learning rate: 1.560E-06 | global batch size:    32 | lm loss: 1.069224E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration       27/  500000 | consumed samples:          864 | consumed tokens:      3538944 | elapsed time per iteration (ms): 6758.0 | learning rate: 1.620E-06 | global batch size:    32 | lm loss: 1.092435E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration       28/  500000 | consumed samples:          896 | consumed tokens:      3670016 | elapsed time per iteration (ms): 6758.8 | learning rate: 1.680E-06 | global batch size:    32 | lm loss: 1.088279E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration       29/  500000 | consumed samples:          928 | consumed tokens:      3801088 | elapsed time per iteration (ms): 6765.5 | learning rate: 1.740E-06 | global batch size:    32 | lm loss: 1.053694E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
[2023-10-10 15:13:16,338] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=0, lr=[1.8e-06], mom=[(0.9, 0.95)]
[2023-10-10 15:13:16,596] [INFO] [timer.py:208:stop] epoch=0/micro_step=30/global_step=30, RunningAvgSamplesPerSec=4.742924976447558, CurrSamplesPerSec=4.742213409575603, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration       30/  500000 | consumed samples:          960 | consumed tokens:      3932160 | elapsed time per iteration (ms): 6761.2 | learning rate: 1.800E-06 | global batch size:    32 | lm loss: 1.050926E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration       31/  500000 | consumed samples:          992 | consumed tokens:      4063232 | elapsed time per iteration (ms): 6765.5 | learning rate: 1.860E-06 | global batch size:    32 | lm loss: 1.027866E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration       32/  500000 | consumed samples:         1024 | consumed tokens:      4194304 | elapsed time per iteration (ms): 6759.5 | learning rate: 1.920E-06 | global batch size:    32 | lm loss: 1.030998E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration       33/  500000 | consumed samples:         1056 | consumed tokens:      4325376 | elapsed time per iteration (ms): 6761.3 | learning rate: 1.980E-06 | global batch size:    32 | lm loss: 1.015112E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration       34/  500000 | consumed samples:         1088 | consumed tokens:      4456448 | elapsed time per iteration (ms): 6767.0 | learning rate: 2.040E-06 | global batch size:    32 | lm loss: 1.005794E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.49 |
time (ms)
 iteration       35/  500000 | consumed samples:         1120 | consumed tokens:      4587520 | elapsed time per iteration (ms): 6762.2 | learning rate: 2.100E-06 | global batch size:    32 | lm loss: 1.016184E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration       36/  500000 | consumed samples:         1152 | consumed tokens:      4718592 | elapsed time per iteration (ms): 6758.6 | learning rate: 2.160E-06 | global batch size:    32 | lm loss: 1.015405E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration       37/  500000 | consumed samples:         1184 | consumed tokens:      4849664 | elapsed time per iteration (ms): 6762.0 | learning rate: 2.220E-06 | global batch size:    32 | lm loss: 1.014028E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration       38/  500000 | consumed samples:         1216 | consumed tokens:      4980736 | elapsed time per iteration (ms): 6764.5 | learning rate: 2.280E-06 | global batch size:    32 | lm loss: 1.004971E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.54 |
time (ms)
 iteration       39/  500000 | consumed samples:         1248 | consumed tokens:      5111808 | elapsed time per iteration (ms): 6759.8 | learning rate: 2.340E-06 | global batch size:    32 | lm loss: 9.946061E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
[2023-10-10 15:14:23,996] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=0, lr=[2.4e-06], mom=[(0.9, 0.95)]
[2023-10-10 15:14:24,257] [INFO] [timer.py:208:stop] epoch=0/micro_step=40/global_step=40, RunningAvgSamplesPerSec=4.742507042407798, CurrSamplesPerSec=4.743032215070291, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration       40/  500000 | consumed samples:         1280 | consumed tokens:      5242880 | elapsed time per iteration (ms): 6760.5 | learning rate: 2.400E-06 | global batch size:    32 | lm loss: 1.004685E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration       41/  500000 | consumed samples:         1312 | consumed tokens:      5373952 | elapsed time per iteration (ms): 6764.0 | learning rate: 2.460E-06 | global batch size:    32 | lm loss: 1.000088E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration       42/  500000 | consumed samples:         1344 | consumed tokens:      5505024 | elapsed time per iteration (ms): 6765.0 | learning rate: 2.520E-06 | global batch size:    32 | lm loss: 9.894985E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration       43/  500000 | consumed samples:         1376 | consumed tokens:      5636096 | elapsed time per iteration (ms): 6758.8 | learning rate: 2.580E-06 | global batch size:    32 | lm loss: 1.000304E+00 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration       44/  500000 | consumed samples:         1408 | consumed tokens:      5767168 | elapsed time per iteration (ms): 6760.5 | learning rate: 2.640E-06 | global batch size:    32 | lm loss: 9.967028E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration       45/  500000 | consumed samples:         1440 | consumed tokens:      5898240 | elapsed time per iteration (ms): 6762.3 | learning rate: 2.700E-06 | global batch size:    32 | lm loss: 9.956329E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration       46/  500000 | consumed samples:         1472 | consumed tokens:      6029312 | elapsed time per iteration (ms): 6761.1 | learning rate: 2.760E-06 | global batch size:    32 | lm loss: 9.754719E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration       47/  500000 | consumed samples:         1504 | consumed tokens:      6160384 | elapsed time per iteration (ms): 6762.8 | learning rate: 2.820E-06 | global batch size:    32 | lm loss: 9.848444E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration       48/  500000 | consumed samples:         1536 | consumed tokens:      6291456 | elapsed time per iteration (ms): 6761.3 | learning rate: 2.880E-06 | global batch size:    32 | lm loss: 9.723136E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration       49/  500000 | consumed samples:         1568 | consumed tokens:      6422528 | elapsed time per iteration (ms): 6761.1 | learning rate: 2.940E-06 | global batch size:    32 | lm loss: 9.538265E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
[2023-10-10 15:15:31,661] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=0, lr=[3e-06], mom=[(0.9, 0.95)]
[2023-10-10 15:15:31,918] [INFO] [timer.py:208:stop] epoch=0/micro_step=50/global_step=50, RunningAvgSamplesPerSec=4.742287978831249, CurrSamplesPerSec=4.742118576452817, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration       50/  500000 | consumed samples:         1600 | consumed tokens:      6553600 | elapsed time per iteration (ms): 6760.6 | learning rate: 3.000E-06 | global batch size:    32 | lm loss: 9.641249E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration       51/  500000 | consumed samples:         1632 | consumed tokens:      6684672 | elapsed time per iteration (ms): 6759.9 | learning rate: 3.060E-06 | global batch size:    32 | lm loss: 9.582776E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration       52/  500000 | consumed samples:         1664 | consumed tokens:      6815744 | elapsed time per iteration (ms): 6766.5 | learning rate: 3.120E-06 | global batch size:    32 | lm loss: 9.587479E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.50 |
time (ms)
 iteration       53/  500000 | consumed samples:         1696 | consumed tokens:      6946816 | elapsed time per iteration (ms): 6763.7 | learning rate: 3.180E-06 | global batch size:    32 | lm loss: 9.664071E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration       54/  500000 | consumed samples:         1728 | consumed tokens:      7077888 | elapsed time per iteration (ms): 6761.3 | learning rate: 3.240E-06 | global batch size:    32 | lm loss: 9.709948E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration       55/  500000 | consumed samples:         1760 | consumed tokens:      7208960 | elapsed time per iteration (ms): 6763.9 | learning rate: 3.300E-06 | global batch size:    32 | lm loss: 9.611025E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration       56/  500000 | consumed samples:         1792 | consumed tokens:      7340032 | elapsed time per iteration (ms): 6759.8 | learning rate: 3.360E-06 | global batch size:    32 | lm loss: 9.372030E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration       57/  500000 | consumed samples:         1824 | consumed tokens:      7471104 | elapsed time per iteration (ms): 6763.0 | learning rate: 3.420E-06 | global batch size:    32 | lm loss: 9.424302E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration       58/  500000 | consumed samples:         1856 | consumed tokens:      7602176 | elapsed time per iteration (ms): 6763.4 | learning rate: 3.480E-06 | global batch size:    32 | lm loss: 9.516285E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration       59/  500000 | consumed samples:         1888 | consumed tokens:      7733248 | elapsed time per iteration (ms): 6761.9 | learning rate: 3.540E-06 | global batch size:    32 | lm loss: 9.609135E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
[2023-10-10 15:16:39,333] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=0, lr=[3.6e-06], mom=[(0.9, 0.95)]
[2023-10-10 15:16:39,589] [INFO] [timer.py:208:stop] epoch=0/micro_step=60/global_step=60, RunningAvgSamplesPerSec=4.742028328469704, CurrSamplesPerSec=4.738664278488197, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration       60/  500000 | consumed samples:         1920 | consumed tokens:      7864320 | elapsed time per iteration (ms): 6766.8 | learning rate: 3.600E-06 | global batch size:    32 | lm loss: 9.371928E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.49 |
time (ms)
 iteration       61/  500000 | consumed samples:         1952 | consumed tokens:      7995392 | elapsed time per iteration (ms): 6762.5 | learning rate: 3.660E-06 | global batch size:    32 | lm loss: 9.337261E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration       62/  500000 | consumed samples:         1984 | consumed tokens:      8126464 | elapsed time per iteration (ms): 6762.1 | learning rate: 3.720E-06 | global batch size:    32 | lm loss: 9.449699E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration       63/  500000 | consumed samples:         2016 | consumed tokens:      8257536 | elapsed time per iteration (ms): 6762.3 | learning rate: 3.780E-06 | global batch size:    32 | lm loss: 9.293369E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration       64/  500000 | consumed samples:         2048 | consumed tokens:      8388608 | elapsed time per iteration (ms): 6760.1 | learning rate: 3.840E-06 | global batch size:    32 | lm loss: 9.207537E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration       65/  500000 | consumed samples:         2080 | consumed tokens:      8519680 | elapsed time per iteration (ms): 6769.0 | learning rate: 3.900E-06 | global batch size:    32 | lm loss: 9.251931E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.727 | TFLOPs: 147.44 |
time (ms)
 iteration       66/  500000 | consumed samples:         2112 | consumed tokens:      8650752 | elapsed time per iteration (ms): 6769.3 | learning rate: 3.960E-06 | global batch size:    32 | lm loss: 9.143319E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.727 | TFLOPs: 147.44 |
time (ms)
 iteration       67/  500000 | consumed samples:         2144 | consumed tokens:      8781824 | elapsed time per iteration (ms): 6758.6 | learning rate: 4.020E-06 | global batch size:    32 | lm loss: 9.070284E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration       68/  500000 | consumed samples:         2176 | consumed tokens:      8912896 | elapsed time per iteration (ms): 6761.7 | learning rate: 4.080E-06 | global batch size:    32 | lm loss: 9.069374E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration       69/  500000 | consumed samples:         2208 | consumed tokens:      9043968 | elapsed time per iteration (ms): 6761.4 | learning rate: 4.140E-06 | global batch size:    32 | lm loss: 8.786678E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
[2023-10-10 15:17:47,006] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=0, lr=[4.2e-06], mom=[(0.9, 0.95)]
[2023-10-10 15:17:47,260] [INFO] [timer.py:208:stop] epoch=0/micro_step=70/global_step=70, RunningAvgSamplesPerSec=4.741852968789469, CurrSamplesPerSec=4.740488910840285, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration       70/  500000 | consumed samples:         2240 | consumed tokens:      9175040 | elapsed time per iteration (ms): 6763.7 | learning rate: 4.200E-06 | global batch size:    32 | lm loss: 8.781389E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration       71/  500000 | consumed samples:         2272 | consumed tokens:      9306112 | elapsed time per iteration (ms): 6761.9 | learning rate: 4.260E-06 | global batch size:    32 | lm loss: 8.748333E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration       72/  500000 | consumed samples:         2304 | consumed tokens:      9437184 | elapsed time per iteration (ms): 6756.7 | learning rate: 4.320E-06 | global batch size:    32 | lm loss: 8.689547E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration       73/  500000 | consumed samples:         2336 | consumed tokens:      9568256 | elapsed time per iteration (ms): 6767.7 | learning rate: 4.380E-06 | global batch size:    32 | lm loss: 8.750194E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.728 | TFLOPs: 147.47 |
time (ms)
 iteration       74/  500000 | consumed samples:         2368 | consumed tokens:      9699328 | elapsed time per iteration (ms): 6767.4 | learning rate: 4.440E-06 | global batch size:    32 | lm loss: 8.786174E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.48 |
time (ms)
 iteration       75/  500000 | consumed samples:         2400 | consumed tokens:      9830400 | elapsed time per iteration (ms): 6763.8 | learning rate: 4.500E-06 | global batch size:    32 | lm loss: 8.555586E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration       76/  500000 | consumed samples:         2432 | consumed tokens:      9961472 | elapsed time per iteration (ms): 6763.5 | learning rate: 4.560E-06 | global batch size:    32 | lm loss: 8.621647E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration       77/  500000 | consumed samples:         2464 | consumed tokens:     10092544 | elapsed time per iteration (ms): 6760.2 | learning rate: 4.620E-06 | global batch size:    32 | lm loss: 8.539876E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration       78/  500000 | consumed samples:         2496 | consumed tokens:     10223616 | elapsed time per iteration (ms): 6760.5 | learning rate: 4.680E-06 | global batch size:    32 | lm loss: 8.822621E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration       79/  500000 | consumed samples:         2528 | consumed tokens:     10354688 | elapsed time per iteration (ms): 6763.7 | learning rate: 4.740E-06 | global batch size:    32 | lm loss: 8.633325E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
[2023-10-10 15:18:54,698] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=0, lr=[4.8e-06], mom=[(0.9, 0.95)]
[2023-10-10 15:18:54,928] [INFO] [timer.py:208:stop] epoch=0/micro_step=80/global_step=80, RunningAvgSamplesPerSec=4.741761218457286, CurrSamplesPerSec=4.742326678134374, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration       80/  500000 | consumed samples:         2560 | consumed tokens:     10485760 | elapsed time per iteration (ms): 6760.5 | learning rate: 4.800E-06 | global batch size:    32 | lm loss: 8.575031E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration       81/  500000 | consumed samples:         2592 | consumed tokens:     10616832 | elapsed time per iteration (ms): 6758.0 | learning rate: 4.860E-06 | global batch size:    32 | lm loss: 8.574308E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration       82/  500000 | consumed samples:         2624 | consumed tokens:     10747904 | elapsed time per iteration (ms): 6759.1 | learning rate: 4.920E-06 | global batch size:    32 | lm loss: 8.646375E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration       83/  500000 | consumed samples:         2656 | consumed tokens:     10878976 | elapsed time per iteration (ms): 6759.3 | learning rate: 4.980E-06 | global batch size:    32 | lm loss: 8.662760E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration       84/  500000 | consumed samples:         2688 | consumed tokens:     11010048 | elapsed time per iteration (ms): 6758.5 | learning rate: 5.040E-06 | global batch size:    32 | lm loss: 8.493950E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration       85/  500000 | consumed samples:         2720 | consumed tokens:     11141120 | elapsed time per iteration (ms): 6758.8 | learning rate: 5.100E-06 | global batch size:    32 | lm loss: 8.510237E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration       86/  500000 | consumed samples:         2752 | consumed tokens:     11272192 | elapsed time per iteration (ms): 6761.2 | learning rate: 5.160E-06 | global batch size:    32 | lm loss: 8.623457E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration       87/  500000 | consumed samples:         2784 | consumed tokens:     11403264 | elapsed time per iteration (ms): 6759.1 | learning rate: 5.220E-06 | global batch size:    32 | lm loss: 8.568394E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration       88/  500000 | consumed samples:         2816 | consumed tokens:     11534336 | elapsed time per iteration (ms): 6756.2 | learning rate: 5.280E-06 | global batch size:    32 | lm loss: 8.628963E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration       89/  500000 | consumed samples:         2848 | consumed tokens:     11665408 | elapsed time per iteration (ms): 6757.1 | learning rate: 5.340E-06 | global batch size:    32 | lm loss: 8.625188E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
[2023-10-10 15:20:02,299] [INFO] [logging.py:96:log_dist] [Rank 0] step=90, skipped=0, lr=[5.399999999999999e-06], mom=[(0.9, 0.95)]
[2023-10-10 15:20:02,557] [INFO] [timer.py:208:stop] epoch=0/micro_step=90/global_step=90, RunningAvgSamplesPerSec=4.742028068887823, CurrSamplesPerSec=4.745321543580022, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration       90/  500000 | consumed samples:         2880 | consumed tokens:     11796480 | elapsed time per iteration (ms): 6760.9 | learning rate: 5.400E-06 | global batch size:    32 | lm loss: 8.513537E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration       91/  500000 | consumed samples:         2912 | consumed tokens:     11927552 | elapsed time per iteration (ms): 6764.4 | learning rate: 5.460E-06 | global batch size:    32 | lm loss: 8.380943E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.54 |
time (ms)
 iteration       92/  500000 | consumed samples:         2944 | consumed tokens:     12058624 | elapsed time per iteration (ms): 6758.3 | learning rate: 5.520E-06 | global batch size:    32 | lm loss: 8.650277E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration       93/  500000 | consumed samples:         2976 | consumed tokens:     12189696 | elapsed time per iteration (ms): 6757.7 | learning rate: 5.580E-06 | global batch size:    32 | lm loss: 8.315960E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration       94/  500000 | consumed samples:         3008 | consumed tokens:     12320768 | elapsed time per iteration (ms): 6759.3 | learning rate: 5.640E-06 | global batch size:    32 | lm loss: 8.512747E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration       95/  500000 | consumed samples:         3040 | consumed tokens:     12451840 | elapsed time per iteration (ms): 6761.8 | learning rate: 5.700E-06 | global batch size:    32 | lm loss: 8.610557E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration       96/  500000 | consumed samples:         3072 | consumed tokens:     12582912 | elapsed time per iteration (ms): 6756.7 | learning rate: 5.760E-06 | global batch size:    32 | lm loss: 8.400623E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration       97/  500000 | consumed samples:         3104 | consumed tokens:     12713984 | elapsed time per iteration (ms): 6757.2 | learning rate: 5.820E-06 | global batch size:    32 | lm loss: 8.445771E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration       98/  500000 | consumed samples:         3136 | consumed tokens:     12845056 | elapsed time per iteration (ms): 6756.2 | learning rate: 5.880E-06 | global batch size:    32 | lm loss: 8.450845E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration       99/  500000 | consumed samples:         3168 | consumed tokens:     12976128 | elapsed time per iteration (ms): 6760.8 | learning rate: 5.940E-06 | global batch size:    32 | lm loss: 8.527932E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
[2023-10-10 15:21:09,937] [INFO] [logging.py:96:log_dist] [Rank 0] step=100, skipped=0, lr=[6e-06], mom=[(0.9, 0.95)]
[2023-10-10 15:21:10,197] [INFO] [timer.py:208:stop] epoch=0/micro_step=100/global_step=100, RunningAvgSamplesPerSec=4.742100060945293, CurrSamplesPerSec=4.738612582631, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      100/  500000 | consumed samples:         3200 | consumed tokens:     13107200 | elapsed time per iteration (ms): 6766.3 | learning rate: 6.000E-06 | global batch size:    32 | lm loss: 8.462147E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.50 |
time (ms)
 iteration      101/  500000 | consumed samples:         3232 | consumed tokens:     13238272 | elapsed time per iteration (ms): 6759.5 | learning rate: 6.060E-06 | global batch size:    32 | lm loss: 8.305936E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      102/  500000 | consumed samples:         3264 | consumed tokens:     13369344 | elapsed time per iteration (ms): 6763.1 | learning rate: 6.120E-06 | global batch size:    32 | lm loss: 8.152670E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration      103/  500000 | consumed samples:         3296 | consumed tokens:     13500416 | elapsed time per iteration (ms): 6763.2 | learning rate: 6.180E-06 | global batch size:    32 | lm loss: 8.451134E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration      104/  500000 | consumed samples:         3328 | consumed tokens:     13631488 | elapsed time per iteration (ms): 6762.2 | learning rate: 6.240E-06 | global batch size:    32 | lm loss: 8.402096E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      105/  500000 | consumed samples:         3360 | consumed tokens:     13762560 | elapsed time per iteration (ms): 6761.8 | learning rate: 6.300E-06 | global batch size:    32 | lm loss: 8.303983E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      106/  500000 | consumed samples:         3392 | consumed tokens:     13893632 | elapsed time per iteration (ms): 6762.7 | learning rate: 6.360E-06 | global batch size:    32 | lm loss: 8.327829E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration      107/  500000 | consumed samples:         3424 | consumed tokens:     14024704 | elapsed time per iteration (ms): 6762.3 | learning rate: 6.420E-06 | global batch size:    32 | lm loss: 8.284641E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      108/  500000 | consumed samples:         3456 | consumed tokens:     14155776 | elapsed time per iteration (ms): 6764.7 | learning rate: 6.480E-06 | global batch size:    32 | lm loss: 8.431602E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration      109/  500000 | consumed samples:         3488 | consumed tokens:     14286848 | elapsed time per iteration (ms): 6760.9 | learning rate: 6.540E-06 | global batch size:    32 | lm loss: 8.610790E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
[2023-10-10 15:22:17,601] [INFO] [logging.py:96:log_dist] [Rank 0] step=110, skipped=0, lr=[6.599999999999999e-06], mom=[(0.9, 0.95)]
[2023-10-10 15:22:17,862] [INFO] [timer.py:208:stop] epoch=0/micro_step=110/global_step=110, RunningAvgSamplesPerSec=4.742015491156284, CurrSamplesPerSec=4.741315997810805, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      110/  500000 | consumed samples:         3520 | consumed tokens:     14417920 | elapsed time per iteration (ms): 6761.5 | learning rate: 6.600E-06 | global batch size:    32 | lm loss: 8.323587E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      111/  500000 | consumed samples:         3552 | consumed tokens:     14548992 | elapsed time per iteration (ms): 6758.9 | learning rate: 6.660E-06 | global batch size:    32 | lm loss: 8.393550E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.66 |
time (ms)
 iteration      112/  500000 | consumed samples:         3584 | consumed tokens:     14680064 | elapsed time per iteration (ms): 6764.0 | learning rate: 6.720E-06 | global batch size:    32 | lm loss: 8.392024E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration      113/  500000 | consumed samples:         3616 | consumed tokens:     14811136 | elapsed time per iteration (ms): 6760.4 | learning rate: 6.780E-06 | global batch size:    32 | lm loss: 8.304040E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      114/  500000 | consumed samples:         3648 | consumed tokens:     14942208 | elapsed time per iteration (ms): 6760.4 | learning rate: 6.840E-06 | global batch size:    32 | lm loss: 8.288751E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      115/  500000 | consumed samples:         3680 | consumed tokens:     15073280 | elapsed time per iteration (ms): 6758.7 | learning rate: 6.900E-06 | global batch size:    32 | lm loss: 8.141930E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      116/  500000 | consumed samples:         3712 | consumed tokens:     15204352 | elapsed time per iteration (ms): 6754.6 | learning rate: 6.960E-06 | global batch size:    32 | lm loss: 8.376821E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.738 | TFLOPs: 147.76 |
time (ms)
 iteration      117/  500000 | consumed samples:         3744 | consumed tokens:     15335424 | elapsed time per iteration (ms): 6760.0 | learning rate: 7.020E-06 | global batch size:    32 | lm loss: 8.407882E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      118/  500000 | consumed samples:         3776 | consumed tokens:     15466496 | elapsed time per iteration (ms): 6760.1 | learning rate: 7.080E-06 | global batch size:    32 | lm loss: 8.434992E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      119/  500000 | consumed samples:         3808 | consumed tokens:     15597568 | elapsed time per iteration (ms): 6759.8 | learning rate: 7.140E-06 | global batch size:    32 | lm loss: 8.247942E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
[2023-10-10 15:23:25,244] [INFO] [logging.py:96:log_dist] [Rank 0] step=120, skipped=0, lr=[7.2e-06], mom=[(0.9, 0.95)]
[2023-10-10 15:23:25,500] [INFO] [timer.py:208:stop] epoch=0/micro_step=120/global_step=120, RunningAvgSamplesPerSec=4.742097797958393, CurrSamplesPerSec=4.742653612263942, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      120/  500000 | consumed samples:         3840 | consumed tokens:     15728640 | elapsed time per iteration (ms): 6760.3 | learning rate: 7.200E-06 | global batch size:    32 | lm loss: 8.257678E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      121/  500000 | consumed samples:         3872 | consumed tokens:     15859712 | elapsed time per iteration (ms): 6757.0 | learning rate: 7.260E-06 | global batch size:    32 | lm loss: 8.132421E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      122/  500000 | consumed samples:         3904 | consumed tokens:     15990784 | elapsed time per iteration (ms): 6763.5 | learning rate: 7.320E-06 | global batch size:    32 | lm loss: 8.313585E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration      123/  500000 | consumed samples:         3936 | consumed tokens:     16121856 | elapsed time per iteration (ms): 6759.0 | learning rate: 7.380E-06 | global batch size:    32 | lm loss: 8.294865E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      124/  500000 | consumed samples:         3968 | consumed tokens:     16252928 | elapsed time per iteration (ms): 6763.0 | learning rate: 7.440E-06 | global batch size:    32 | lm loss: 8.272763E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration      125/  500000 | consumed samples:         4000 | consumed tokens:     16384000 | elapsed time per iteration (ms): 6766.3 | learning rate: 7.500E-06 | global batch size:    32 | lm loss: 8.242053E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.50 |
time (ms)
 iteration      126/  500000 | consumed samples:         4032 | consumed tokens:     16515072 | elapsed time per iteration (ms): 6763.1 | learning rate: 7.560E-06 | global batch size:    32 | lm loss: 8.185661E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration      127/  500000 | consumed samples:         4064 | consumed tokens:     16646144 | elapsed time per iteration (ms): 6763.8 | learning rate: 7.620E-06 | global batch size:    32 | lm loss: 8.341337E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration      128/  500000 | consumed samples:         4096 | consumed tokens:     16777216 | elapsed time per iteration (ms): 6765.9 | learning rate: 7.680E-06 | global batch size:    32 | lm loss: 8.229010E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.51 |
time (ms)
 iteration      129/  500000 | consumed samples:         4128 | consumed tokens:     16908288 | elapsed time per iteration (ms): 6765.9 | learning rate: 7.740E-06 | global batch size:    32 | lm loss: 8.226795E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.51 |
time (ms)
[2023-10-10 15:24:32,918] [INFO] [logging.py:96:log_dist] [Rank 0] step=130, skipped=0, lr=[7.8e-06], mom=[(0.9, 0.95)]
[2023-10-10 15:24:33,177] [INFO] [timer.py:208:stop] epoch=0/micro_step=130/global_step=130, RunningAvgSamplesPerSec=4.741985506509428, CurrSamplesPerSec=4.738896170870357, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      130/  500000 | consumed samples:         4160 | consumed tokens:     17039360 | elapsed time per iteration (ms): 6766.7 | learning rate: 7.800E-06 | global batch size:    32 | lm loss: 8.392645E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.49 |
time (ms)
 iteration      131/  500000 | consumed samples:         4192 | consumed tokens:     17170432 | elapsed time per iteration (ms): 6767.8 | learning rate: 7.860E-06 | global batch size:    32 | lm loss: 8.295803E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.728 | TFLOPs: 147.47 |
time (ms)
 iteration      132/  500000 | consumed samples:         4224 | consumed tokens:     17301504 | elapsed time per iteration (ms): 6755.8 | learning rate: 7.920E-06 | global batch size:    32 | lm loss: 8.154018E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration      133/  500000 | consumed samples:         4256 | consumed tokens:     17432576 | elapsed time per iteration (ms): 6760.8 | learning rate: 7.980E-06 | global batch size:    32 | lm loss: 8.163722E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      134/  500000 | consumed samples:         4288 | consumed tokens:     17563648 | elapsed time per iteration (ms): 6760.0 | learning rate: 8.040E-06 | global batch size:    32 | lm loss: 8.171563E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      135/  500000 | consumed samples:         4320 | consumed tokens:     17694720 | elapsed time per iteration (ms): 6757.4 | learning rate: 8.100E-06 | global batch size:    32 | lm loss: 8.300589E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      136/  500000 | consumed samples:         4352 | consumed tokens:     17825792 | elapsed time per iteration (ms): 6765.6 | learning rate: 8.160E-06 | global batch size:    32 | lm loss: 8.324580E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration      137/  500000 | consumed samples:         4384 | consumed tokens:     17956864 | elapsed time per iteration (ms): 6760.9 | learning rate: 8.220E-06 | global batch size:    32 | lm loss: 8.070239E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      138/  500000 | consumed samples:         4416 | consumed tokens:     18087936 | elapsed time per iteration (ms): 6763.7 | learning rate: 8.280E-06 | global batch size:    32 | lm loss: 8.204982E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration      139/  500000 | consumed samples:         4448 | consumed tokens:     18219008 | elapsed time per iteration (ms): 6758.3 | learning rate: 8.340E-06 | global batch size:    32 | lm loss: 8.141493E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
[2023-10-10 15:25:40,572] [INFO] [logging.py:96:log_dist] [Rank 0] step=140, skipped=0, lr=[8.4e-06], mom=[(0.9, 0.95)]
[2023-10-10 15:25:40,832] [INFO] [timer.py:208:stop] epoch=0/micro_step=140/global_step=140, RunningAvgSamplesPerSec=4.741976446784963, CurrSamplesPerSec=4.740833006929003, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      140/  500000 | consumed samples:         4480 | consumed tokens:     18350080 | elapsed time per iteration (ms): 6763.3 | learning rate: 8.400E-06 | global batch size:    32 | lm loss: 8.188184E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration      141/  500000 | consumed samples:         4512 | consumed tokens:     18481152 | elapsed time per iteration (ms): 6759.9 | learning rate: 8.460E-06 | global batch size:    32 | lm loss: 8.097560E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      142/  500000 | consumed samples:         4544 | consumed tokens:     18612224 | elapsed time per iteration (ms): 6760.4 | learning rate: 8.520E-06 | global batch size:    32 | lm loss: 8.156380E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      143/  500000 | consumed samples:         4576 | consumed tokens:     18743296 | elapsed time per iteration (ms): 6758.8 | learning rate: 8.580E-06 | global batch size:    32 | lm loss: 8.197024E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      144/  500000 | consumed samples:         4608 | consumed tokens:     18874368 | elapsed time per iteration (ms): 6760.2 | learning rate: 8.640E-06 | global batch size:    32 | lm loss: 8.280843E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      145/  500000 | consumed samples:         4640 | consumed tokens:     19005440 | elapsed time per iteration (ms): 6756.1 | learning rate: 8.700E-06 | global batch size:    32 | lm loss: 7.861782E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      146/  500000 | consumed samples:         4672 | consumed tokens:     19136512 | elapsed time per iteration (ms): 6761.7 | learning rate: 8.760E-06 | global batch size:    32 | lm loss: 8.129838E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration      147/  500000 | consumed samples:         4704 | consumed tokens:     19267584 | elapsed time per iteration (ms): 6762.5 | learning rate: 8.820E-06 | global batch size:    32 | lm loss: 8.213637E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      148/  500000 | consumed samples:         4736 | consumed tokens:     19398656 | elapsed time per iteration (ms): 6757.7 | learning rate: 8.880E-06 | global batch size:    32 | lm loss: 8.019133E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      149/  500000 | consumed samples:         4768 | consumed tokens:     19529728 | elapsed time per iteration (ms): 6761.4 | learning rate: 8.940E-06 | global batch size:    32 | lm loss: 7.962490E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
[2023-10-10 15:26:48,219] [INFO] [logging.py:96:log_dist] [Rank 0] step=150, skipped=0, lr=[9e-06], mom=[(0.9, 0.95)]
[2023-10-10 15:26:48,472] [INFO] [timer.py:208:stop] epoch=0/micro_step=150/global_step=150, RunningAvgSamplesPerSec=4.742029371027536, CurrSamplesPerSec=4.7428785208527104, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      150/  500000 | consumed samples:         4800 | consumed tokens:     19660800 | elapsed time per iteration (ms): 6759.6 | learning rate: 9.000E-06 | global batch size:    32 | lm loss: 7.957213E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      151/  500000 | consumed samples:         4832 | consumed tokens:     19791872 | elapsed time per iteration (ms): 6757.3 | learning rate: 9.060E-06 | global batch size:    32 | lm loss: 8.169190E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      152/  500000 | consumed samples:         4864 | consumed tokens:     19922944 | elapsed time per iteration (ms): 6759.8 | learning rate: 9.120E-06 | global batch size:    32 | lm loss: 7.981314E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      153/  500000 | consumed samples:         4896 | consumed tokens:     20054016 | elapsed time per iteration (ms): 6754.8 | learning rate: 9.180E-06 | global batch size:    32 | lm loss: 8.045244E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.75 |
time (ms)
 iteration      154/  500000 | consumed samples:         4928 | consumed tokens:     20185088 | elapsed time per iteration (ms): 6758.0 | learning rate: 9.240E-06 | global batch size:    32 | lm loss: 8.161987E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      155/  500000 | consumed samples:         4960 | consumed tokens:     20316160 | elapsed time per iteration (ms): 6757.3 | learning rate: 9.300E-06 | global batch size:    32 | lm loss: 7.861323E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      156/  500000 | consumed samples:         4992 | consumed tokens:     20447232 | elapsed time per iteration (ms): 6758.7 | learning rate: 9.360E-06 | global batch size:    32 | lm loss: 8.150398E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      157/  500000 | consumed samples:         5024 | consumed tokens:     20578304 | elapsed time per iteration (ms): 6757.5 | learning rate: 9.420E-06 | global batch size:    32 | lm loss: 8.017540E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      158/  500000 | consumed samples:         5056 | consumed tokens:     20709376 | elapsed time per iteration (ms): 6760.5 | learning rate: 9.480E-06 | global batch size:    32 | lm loss: 7.951444E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      159/  500000 | consumed samples:         5088 | consumed tokens:     20840448 | elapsed time per iteration (ms): 6758.0 | learning rate: 9.540E-06 | global batch size:    32 | lm loss: 8.116435E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
[2023-10-10 15:27:55,840] [INFO] [logging.py:96:log_dist] [Rank 0] step=160, skipped=0, lr=[9.6e-06], mom=[(0.9, 0.95)]
[2023-10-10 15:27:56,098] [INFO] [timer.py:208:stop] epoch=0/micro_step=160/global_step=160, RunningAvgSamplesPerSec=4.74214885481412, CurrSamplesPerSec=4.743583216111265, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      160/  500000 | consumed samples:         5120 | consumed tokens:     20971520 | elapsed time per iteration (ms): 6759.8 | learning rate: 9.600E-06 | global batch size:    32 | lm loss: 7.816611E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      161/  500000 | consumed samples:         5152 | consumed tokens:     21102592 | elapsed time per iteration (ms): 6761.4 | learning rate: 9.660E-06 | global batch size:    32 | lm loss: 8.088474E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      162/  500000 | consumed samples:         5184 | consumed tokens:     21233664 | elapsed time per iteration (ms): 6756.7 | learning rate: 9.720E-06 | global batch size:    32 | lm loss: 7.994159E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      163/  500000 | consumed samples:         5216 | consumed tokens:     21364736 | elapsed time per iteration (ms): 6761.2 | learning rate: 9.780E-06 | global batch size:    32 | lm loss: 7.917928E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      164/  500000 | consumed samples:         5248 | consumed tokens:     21495808 | elapsed time per iteration (ms): 6761.3 | learning rate: 9.840E-06 | global batch size:    32 | lm loss: 7.954026E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      165/  500000 | consumed samples:         5280 | consumed tokens:     21626880 | elapsed time per iteration (ms): 6763.9 | learning rate: 9.900E-06 | global batch size:    32 | lm loss: 7.808903E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration      166/  500000 | consumed samples:         5312 | consumed tokens:     21757952 | elapsed time per iteration (ms): 6763.4 | learning rate: 9.960E-06 | global batch size:    32 | lm loss: 8.059009E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration      167/  500000 | consumed samples:         5344 | consumed tokens:     21889024 | elapsed time per iteration (ms): 6760.3 | learning rate: 1.002E-05 | global batch size:    32 | lm loss: 8.020399E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      168/  500000 | consumed samples:         5376 | consumed tokens:     22020096 | elapsed time per iteration (ms): 6759.6 | learning rate: 1.008E-05 | global batch size:    32 | lm loss: 8.119868E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      169/  500000 | consumed samples:         5408 | consumed tokens:     22151168 | elapsed time per iteration (ms): 6760.8 | learning rate: 1.014E-05 | global batch size:    32 | lm loss: 7.934477E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
[2023-10-10 15:29:03,493] [INFO] [logging.py:96:log_dist] [Rank 0] step=170, skipped=0, lr=[1.0199999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:29:03,749] [INFO] [timer.py:208:stop] epoch=0/micro_step=170/global_step=170, RunningAvgSamplesPerSec=4.742181337348572, CurrSamplesPerSec=4.744719483596663, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      170/  500000 | consumed samples:         5440 | consumed tokens:     22282240 | elapsed time per iteration (ms): 6756.8 | learning rate: 1.020E-05 | global batch size:    32 | lm loss: 7.988054E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      171/  500000 | consumed samples:         5472 | consumed tokens:     22413312 | elapsed time per iteration (ms): 6759.6 | learning rate: 1.026E-05 | global batch size:    32 | lm loss: 8.013350E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      172/  500000 | consumed samples:         5504 | consumed tokens:     22544384 | elapsed time per iteration (ms): 6765.2 | learning rate: 1.032E-05 | global batch size:    32 | lm loss: 7.916884E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration      173/  500000 | consumed samples:         5536 | consumed tokens:     22675456 | elapsed time per iteration (ms): 6764.0 | learning rate: 1.038E-05 | global batch size:    32 | lm loss: 7.852829E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration      174/  500000 | consumed samples:         5568 | consumed tokens:     22806528 | elapsed time per iteration (ms): 6762.1 | learning rate: 1.044E-05 | global batch size:    32 | lm loss: 8.111699E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      175/  500000 | consumed samples:         5600 | consumed tokens:     22937600 | elapsed time per iteration (ms): 6761.1 | learning rate: 1.050E-05 | global batch size:    32 | lm loss: 7.929241E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      176/  500000 | consumed samples:         5632 | consumed tokens:     23068672 | elapsed time per iteration (ms): 6764.2 | learning rate: 1.056E-05 | global batch size:    32 | lm loss: 7.949576E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration      177/  500000 | consumed samples:         5664 | consumed tokens:     23199744 | elapsed time per iteration (ms): 6763.8 | learning rate: 1.062E-05 | global batch size:    32 | lm loss: 7.969053E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration      178/  500000 | consumed samples:         5696 | consumed tokens:     23330816 | elapsed time per iteration (ms): 6760.8 | learning rate: 1.068E-05 | global batch size:    32 | lm loss: 7.780222E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      179/  500000 | consumed samples:         5728 | consumed tokens:     23461888 | elapsed time per iteration (ms): 6758.6 | learning rate: 1.074E-05 | global batch size:    32 | lm loss: 7.860878E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
[2023-10-10 15:30:11,163] [INFO] [logging.py:96:log_dist] [Rank 0] step=180, skipped=0, lr=[1.0799999999999998e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:30:11,412] [INFO] [timer.py:208:stop] epoch=0/micro_step=180/global_step=180, RunningAvgSamplesPerSec=4.742166392588539, CurrSamplesPerSec=4.744714451696756, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      180/  500000 | consumed samples:         5760 | consumed tokens:     23592960 | elapsed time per iteration (ms): 6758.0 | learning rate: 1.080E-05 | global batch size:    32 | lm loss: 7.944542E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      181/  500000 | consumed samples:         5792 | consumed tokens:     23724032 | elapsed time per iteration (ms): 6759.4 | learning rate: 1.086E-05 | global batch size:    32 | lm loss: 8.044391E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      182/  500000 | consumed samples:         5824 | consumed tokens:     23855104 | elapsed time per iteration (ms): 6757.3 | learning rate: 1.092E-05 | global batch size:    32 | lm loss: 8.059613E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      183/  500000 | consumed samples:         5856 | consumed tokens:     23986176 | elapsed time per iteration (ms): 6756.6 | learning rate: 1.098E-05 | global batch size:    32 | lm loss: 7.813488E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      184/  500000 | consumed samples:         5888 | consumed tokens:     24117248 | elapsed time per iteration (ms): 6759.9 | learning rate: 1.104E-05 | global batch size:    32 | lm loss: 7.743002E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      185/  500000 | consumed samples:         5920 | consumed tokens:     24248320 | elapsed time per iteration (ms): 6758.7 | learning rate: 1.110E-05 | global batch size:    32 | lm loss: 7.983940E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      186/  500000 | consumed samples:         5952 | consumed tokens:     24379392 | elapsed time per iteration (ms): 6756.8 | learning rate: 1.116E-05 | global batch size:    32 | lm loss: 7.857520E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      187/  500000 | consumed samples:         5984 | consumed tokens:     24510464 | elapsed time per iteration (ms): 6757.8 | learning rate: 1.122E-05 | global batch size:    32 | lm loss: 7.829244E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      188/  500000 | consumed samples:         6016 | consumed tokens:     24641536 | elapsed time per iteration (ms): 6760.9 | learning rate: 1.128E-05 | global batch size:    32 | lm loss: 8.002324E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      189/  500000 | consumed samples:         6048 | consumed tokens:     24772608 | elapsed time per iteration (ms): 6762.3 | learning rate: 1.134E-05 | global batch size:    32 | lm loss: 7.822400E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
[2023-10-10 15:31:18,783] [INFO] [logging.py:96:log_dist] [Rank 0] step=190, skipped=0, lr=[1.14e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:31:19,046] [INFO] [timer.py:208:stop] epoch=0/micro_step=190/global_step=190, RunningAvgSamplesPerSec=4.742228714881991, CurrSamplesPerSec=4.740943027749857, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      190/  500000 | consumed samples:         6080 | consumed tokens:     24903680 | elapsed time per iteration (ms): 6762.2 | learning rate: 1.140E-05 | global batch size:    32 | lm loss: 7.902801E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      191/  500000 | consumed samples:         6112 | consumed tokens:     25034752 | elapsed time per iteration (ms): 6768.9 | learning rate: 1.146E-05 | global batch size:    32 | lm loss: 7.787929E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.728 | TFLOPs: 147.45 |
time (ms)
 iteration      192/  500000 | consumed samples:         6144 | consumed tokens:     25165824 | elapsed time per iteration (ms): 6757.8 | learning rate: 1.152E-05 | global batch size:    32 | lm loss: 7.819026E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      193/  500000 | consumed samples:         6176 | consumed tokens:     25296896 | elapsed time per iteration (ms): 6756.6 | learning rate: 1.158E-05 | global batch size:    32 | lm loss: 7.906125E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      194/  500000 | consumed samples:         6208 | consumed tokens:     25427968 | elapsed time per iteration (ms): 6760.3 | learning rate: 1.164E-05 | global batch size:    32 | lm loss: 7.887027E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration      195/  500000 | consumed samples:         6240 | consumed tokens:     25559040 | elapsed time per iteration (ms): 6755.4 | learning rate: 1.170E-05 | global batch size:    32 | lm loss: 7.878771E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration      196/  500000 | consumed samples:         6272 | consumed tokens:     25690112 | elapsed time per iteration (ms): 6755.8 | learning rate: 1.176E-05 | global batch size:    32 | lm loss: 7.885026E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration      197/  500000 | consumed samples:         6304 | consumed tokens:     25821184 | elapsed time per iteration (ms): 6763.3 | learning rate: 1.182E-05 | global batch size:    32 | lm loss: 7.768021E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration      198/  500000 | consumed samples:         6336 | consumed tokens:     25952256 | elapsed time per iteration (ms): 6756.5 | learning rate: 1.188E-05 | global batch size:    32 | lm loss: 7.780132E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      199/  500000 | consumed samples:         6368 | consumed tokens:     26083328 | elapsed time per iteration (ms): 6757.3 | learning rate: 1.194E-05 | global batch size:    32 | lm loss: 7.700974E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
[2023-10-10 15:32:26,419] [INFO] [logging.py:96:log_dist] [Rank 0] step=200, skipped=0, lr=[1.2e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:32:26,677] [INFO] [timer.py:208:stop] epoch=0/micro_step=200/global_step=200, RunningAvgSamplesPerSec=4.742295732012203, CurrSamplesPerSec=4.744938549318836, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      200/  500000 | consumed samples:         6400 | consumed tokens:     26214400 | elapsed time per iteration (ms): 6757.0 | learning rate: 1.200E-05 | global batch size:    32 | lm loss: 7.650533E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      201/  500000 | consumed samples:         6432 | consumed tokens:     26345472 | elapsed time per iteration (ms): 6758.2 | learning rate: 1.206E-05 | global batch size:    32 | lm loss: 7.842546E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      202/  500000 | consumed samples:         6464 | consumed tokens:     26476544 | elapsed time per iteration (ms): 6757.8 | learning rate: 1.212E-05 | global batch size:    32 | lm loss: 7.831556E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      203/  500000 | consumed samples:         6496 | consumed tokens:     26607616 | elapsed time per iteration (ms): 6758.9 | learning rate: 1.218E-05 | global batch size:    32 | lm loss: 7.666901E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      204/  500000 | consumed samples:         6528 | consumed tokens:     26738688 | elapsed time per iteration (ms): 6757.4 | learning rate: 1.224E-05 | global batch size:    32 | lm loss: 7.819787E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      205/  500000 | consumed samples:         6560 | consumed tokens:     26869760 | elapsed time per iteration (ms): 6758.8 | learning rate: 1.230E-05 | global batch size:    32 | lm loss: 7.741874E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      206/  500000 | consumed samples:         6592 | consumed tokens:     27000832 | elapsed time per iteration (ms): 6753.2 | learning rate: 1.236E-05 | global batch size:    32 | lm loss: 7.737572E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.738 | TFLOPs: 147.79 |
time (ms)
 iteration      207/  500000 | consumed samples:         6624 | consumed tokens:     27131904 | elapsed time per iteration (ms): 6754.7 | learning rate: 1.242E-05 | global batch size:    32 | lm loss: 7.826272E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.76 |
time (ms)
 iteration      208/  500000 | consumed samples:         6656 | consumed tokens:     27262976 | elapsed time per iteration (ms): 6759.6 | learning rate: 1.248E-05 | global batch size:    32 | lm loss: 7.798331E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      209/  500000 | consumed samples:         6688 | consumed tokens:     27394048 | elapsed time per iteration (ms): 6761.2 | learning rate: 1.254E-05 | global batch size:    32 | lm loss: 7.793752E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
[2023-10-10 15:33:34,043] [INFO] [logging.py:96:log_dist] [Rank 0] step=210, skipped=0, lr=[1.26e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:33:34,305] [INFO] [timer.py:208:stop] epoch=0/micro_step=210/global_step=210, RunningAvgSamplesPerSec=4.7423710000553045, CurrSamplesPerSec=4.739852255506164, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      210/  500000 | consumed samples:         6720 | consumed tokens:     27525120 | elapsed time per iteration (ms): 6765.0 | learning rate: 1.260E-05 | global batch size:    32 | lm loss: 7.681577E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration      211/  500000 | consumed samples:         6752 | consumed tokens:     27656192 | elapsed time per iteration (ms): 6763.6 | learning rate: 1.266E-05 | global batch size:    32 | lm loss: 7.668381E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration      212/  500000 | consumed samples:         6784 | consumed tokens:     27787264 | elapsed time per iteration (ms): 6757.7 | learning rate: 1.272E-05 | global batch size:    32 | lm loss: 7.777927E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      213/  500000 | consumed samples:         6816 | consumed tokens:     27918336 | elapsed time per iteration (ms): 6759.6 | learning rate: 1.278E-05 | global batch size:    32 | lm loss: 7.612147E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      214/  500000 | consumed samples:         6848 | consumed tokens:     28049408 | elapsed time per iteration (ms): 6757.4 | learning rate: 1.284E-05 | global batch size:    32 | lm loss: 7.818722E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      215/  500000 | consumed samples:         6880 | consumed tokens:     28180480 | elapsed time per iteration (ms): 6756.8 | learning rate: 1.290E-05 | global batch size:    32 | lm loss: 7.588476E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      216/  500000 | consumed samples:         6912 | consumed tokens:     28311552 | elapsed time per iteration (ms): 6757.9 | learning rate: 1.296E-05 | global batch size:    32 | lm loss: 7.645348E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      217/  500000 | consumed samples:         6944 | consumed tokens:     28442624 | elapsed time per iteration (ms): 6761.0 | learning rate: 1.302E-05 | global batch size:    32 | lm loss: 7.508480E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      218/  500000 | consumed samples:         6976 | consumed tokens:     28573696 | elapsed time per iteration (ms): 6759.9 | learning rate: 1.308E-05 | global batch size:    32 | lm loss: 7.652681E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      219/  500000 | consumed samples:         7008 | consumed tokens:     28704768 | elapsed time per iteration (ms): 6765.0 | learning rate: 1.314E-05 | global batch size:    32 | lm loss: 7.879114E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
[2023-10-10 15:34:41,694] [INFO] [logging.py:96:log_dist] [Rank 0] step=220, skipped=0, lr=[1.3199999999999997e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:34:41,945] [INFO] [timer.py:208:stop] epoch=0/micro_step=220/global_step=220, RunningAvgSamplesPerSec=4.742395220814644, CurrSamplesPerSec=4.7441340098098, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      220/  500000 | consumed samples:         7040 | consumed tokens:     28835840 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.320E-05 | global batch size:    32 | lm loss: 7.815968E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      221/  500000 | consumed samples:         7072 | consumed tokens:     28966912 | elapsed time per iteration (ms): 6758.3 | learning rate: 1.326E-05 | global batch size:    32 | lm loss: 7.627535E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      222/  500000 | consumed samples:         7104 | consumed tokens:     29097984 | elapsed time per iteration (ms): 6758.3 | learning rate: 1.332E-05 | global batch size:    32 | lm loss: 7.643015E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      223/  500000 | consumed samples:         7136 | consumed tokens:     29229056 | elapsed time per iteration (ms): 6762.0 | learning rate: 1.338E-05 | global batch size:    32 | lm loss: 7.580917E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      224/  500000 | consumed samples:         7168 | consumed tokens:     29360128 | elapsed time per iteration (ms): 6759.8 | learning rate: 1.344E-05 | global batch size:    32 | lm loss: 7.666126E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      225/  500000 | consumed samples:         7200 | consumed tokens:     29491200 | elapsed time per iteration (ms): 6756.9 | learning rate: 1.350E-05 | global batch size:    32 | lm loss: 7.579269E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      226/  500000 | consumed samples:         7232 | consumed tokens:     29622272 | elapsed time per iteration (ms): 6758.2 | learning rate: 1.356E-05 | global batch size:    32 | lm loss: 7.540056E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      227/  500000 | consumed samples:         7264 | consumed tokens:     29753344 | elapsed time per iteration (ms): 6760.1 | learning rate: 1.362E-05 | global batch size:    32 | lm loss: 7.610853E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      228/  500000 | consumed samples:         7296 | consumed tokens:     29884416 | elapsed time per iteration (ms): 6759.7 | learning rate: 1.368E-05 | global batch size:    32 | lm loss: 7.738428E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      229/  500000 | consumed samples:         7328 | consumed tokens:     30015488 | elapsed time per iteration (ms): 6756.8 | learning rate: 1.374E-05 | global batch size:    32 | lm loss: 7.625429E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
[2023-10-10 15:35:49,328] [INFO] [logging.py:96:log_dist] [Rank 0] step=230, skipped=0, lr=[1.3799999999999998e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:35:49,574] [INFO] [timer.py:208:stop] epoch=0/micro_step=230/global_step=230, RunningAvgSamplesPerSec=4.742449267638518, CurrSamplesPerSec=4.744847632911275, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      230/  500000 | consumed samples:         7360 | consumed tokens:     30146560 | elapsed time per iteration (ms): 6757.1 | learning rate: 1.380E-05 | global batch size:    32 | lm loss: 7.620203E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      231/  500000 | consumed samples:         7392 | consumed tokens:     30277632 | elapsed time per iteration (ms): 6755.4 | learning rate: 1.386E-05 | global batch size:    32 | lm loss: 7.645001E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration      232/  500000 | consumed samples:         7424 | consumed tokens:     30408704 | elapsed time per iteration (ms): 6757.8 | learning rate: 1.392E-05 | global batch size:    32 | lm loss: 7.595724E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      233/  500000 | consumed samples:         7456 | consumed tokens:     30539776 | elapsed time per iteration (ms): 6762.1 | learning rate: 1.398E-05 | global batch size:    32 | lm loss: 7.514937E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      234/  500000 | consumed samples:         7488 | consumed tokens:     30670848 | elapsed time per iteration (ms): 6758.6 | learning rate: 1.404E-05 | global batch size:    32 | lm loss: 7.490340E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      235/  500000 | consumed samples:         7520 | consumed tokens:     30801920 | elapsed time per iteration (ms): 6759.1 | learning rate: 1.410E-05 | global batch size:    32 | lm loss: 7.579520E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      236/  500000 | consumed samples:         7552 | consumed tokens:     30932992 | elapsed time per iteration (ms): 6760.6 | learning rate: 1.416E-05 | global batch size:    32 | lm loss: 7.588250E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      237/  500000 | consumed samples:         7584 | consumed tokens:     31064064 | elapsed time per iteration (ms): 6761.0 | learning rate: 1.422E-05 | global batch size:    32 | lm loss: 7.591324E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      238/  500000 | consumed samples:         7616 | consumed tokens:     31195136 | elapsed time per iteration (ms): 6761.0 | learning rate: 1.428E-05 | global batch size:    32 | lm loss: 7.649117E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      239/  500000 | consumed samples:         7648 | consumed tokens:     31326208 | elapsed time per iteration (ms): 6757.4 | learning rate: 1.434E-05 | global batch size:    32 | lm loss: 7.521423E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
[2023-10-10 15:36:56,953] [INFO] [logging.py:96:log_dist] [Rank 0] step=240, skipped=0, lr=[1.44e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:36:57,210] [INFO] [timer.py:208:stop] epoch=0/micro_step=240/global_step=240, RunningAvgSamplesPerSec=4.742479834576676, CurrSamplesPerSec=4.741976166343793, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      240/  500000 | consumed samples:         7680 | consumed tokens:     31457280 | elapsed time per iteration (ms): 6760.9 | learning rate: 1.440E-05 | global batch size:    32 | lm loss: 7.466017E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      241/  500000 | consumed samples:         7712 | consumed tokens:     31588352 | elapsed time per iteration (ms): 6756.6 | learning rate: 1.446E-05 | global batch size:    32 | lm loss: 7.669051E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      242/  500000 | consumed samples:         7744 | consumed tokens:     31719424 | elapsed time per iteration (ms): 6762.0 | learning rate: 1.452E-05 | global batch size:    32 | lm loss: 7.368451E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      243/  500000 | consumed samples:         7776 | consumed tokens:     31850496 | elapsed time per iteration (ms): 6761.4 | learning rate: 1.458E-05 | global batch size:    32 | lm loss: 7.517005E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      244/  500000 | consumed samples:         7808 | consumed tokens:     31981568 | elapsed time per iteration (ms): 6757.9 | learning rate: 1.464E-05 | global batch size:    32 | lm loss: 7.588336E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      245/  500000 | consumed samples:         7840 | consumed tokens:     32112640 | elapsed time per iteration (ms): 6759.6 | learning rate: 1.470E-05 | global batch size:    32 | lm loss: 7.470884E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      246/  500000 | consumed samples:         7872 | consumed tokens:     32243712 | elapsed time per iteration (ms): 6762.7 | learning rate: 1.476E-05 | global batch size:    32 | lm loss: 7.409158E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration      247/  500000 | consumed samples:         7904 | consumed tokens:     32374784 | elapsed time per iteration (ms): 6762.0 | learning rate: 1.482E-05 | global batch size:    32 | lm loss: 7.510385E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      248/  500000 | consumed samples:         7936 | consumed tokens:     32505856 | elapsed time per iteration (ms): 6760.0 | learning rate: 1.488E-05 | global batch size:    32 | lm loss: 7.300485E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      249/  500000 | consumed samples:         7968 | consumed tokens:     32636928 | elapsed time per iteration (ms): 6758.6 | learning rate: 1.494E-05 | global batch size:    32 | lm loss: 7.282436E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
[2023-10-10 15:38:04,608] [INFO] [logging.py:96:log_dist] [Rank 0] step=250, skipped=0, lr=[1.4999999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:38:04,858] [INFO] [timer.py:208:stop] epoch=0/micro_step=250/global_step=250, RunningAvgSamplesPerSec=4.7424799919847604, CurrSamplesPerSec=4.739447048088794, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      250/  500000 | consumed samples:         8000 | consumed tokens:     32768000 | elapsed time per iteration (ms): 6765.8 | learning rate: 1.500E-05 | global batch size:    32 | lm loss: 7.483673E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.51 |
time (ms)
 iteration      251/  500000 | consumed samples:         8032 | consumed tokens:     32899072 | elapsed time per iteration (ms): 6762.1 | learning rate: 1.506E-05 | global batch size:    32 | lm loss: 7.414258E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      252/  500000 | consumed samples:         8064 | consumed tokens:     33030144 | elapsed time per iteration (ms): 6758.7 | learning rate: 1.512E-05 | global batch size:    32 | lm loss: 7.638986E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      253/  500000 | consumed samples:         8096 | consumed tokens:     33161216 | elapsed time per iteration (ms): 6757.5 | learning rate: 1.518E-05 | global batch size:    32 | lm loss: 7.316111E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      254/  500000 | consumed samples:         8128 | consumed tokens:     33292288 | elapsed time per iteration (ms): 6757.7 | learning rate: 1.524E-05 | global batch size:    32 | lm loss: 7.529650E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      255/  500000 | consumed samples:         8160 | consumed tokens:     33423360 | elapsed time per iteration (ms): 6761.0 | learning rate: 1.530E-05 | global batch size:    32 | lm loss: 7.504022E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      256/  500000 | consumed samples:         8192 | consumed tokens:     33554432 | elapsed time per iteration (ms): 6760.2 | learning rate: 1.536E-05 | global batch size:    32 | lm loss: 7.276496E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      257/  500000 | consumed samples:         8224 | consumed tokens:     33685504 | elapsed time per iteration (ms): 6759.9 | learning rate: 1.542E-05 | global batch size:    32 | lm loss: 7.531850E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      258/  500000 | consumed samples:         8256 | consumed tokens:     33816576 | elapsed time per iteration (ms): 6759.5 | learning rate: 1.548E-05 | global batch size:    32 | lm loss: 7.283965E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      259/  500000 | consumed samples:         8288 | consumed tokens:     33947648 | elapsed time per iteration (ms): 6759.1 | learning rate: 1.554E-05 | global batch size:    32 | lm loss: 7.234142E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
[2023-10-10 15:39:12,252] [INFO] [logging.py:96:log_dist] [Rank 0] step=260, skipped=0, lr=[1.56e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:39:12,498] [INFO] [timer.py:208:stop] epoch=0/micro_step=260/global_step=260, RunningAvgSamplesPerSec=4.742506093438518, CurrSamplesPerSec=4.743617081622379, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      260/  500000 | consumed samples:         8320 | consumed tokens:     34078720 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.560E-05 | global batch size:    32 | lm loss: 7.491952E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      261/  500000 | consumed samples:         8352 | consumed tokens:     34209792 | elapsed time per iteration (ms): 6760.9 | learning rate: 1.566E-05 | global batch size:    32 | lm loss: 7.455863E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      262/  500000 | consumed samples:         8384 | consumed tokens:     34340864 | elapsed time per iteration (ms): 6760.0 | learning rate: 1.572E-05 | global batch size:    32 | lm loss: 7.351850E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      263/  500000 | consumed samples:         8416 | consumed tokens:     34471936 | elapsed time per iteration (ms): 6759.4 | learning rate: 1.578E-05 | global batch size:    32 | lm loss: 7.393828E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      264/  500000 | consumed samples:         8448 | consumed tokens:     34603008 | elapsed time per iteration (ms): 6762.7 | learning rate: 1.584E-05 | global batch size:    32 | lm loss: 7.541847E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration      265/  500000 | consumed samples:         8480 | consumed tokens:     34734080 | elapsed time per iteration (ms): 6757.5 | learning rate: 1.590E-05 | global batch size:    32 | lm loss: 7.404572E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      266/  500000 | consumed samples:         8512 | consumed tokens:     34865152 | elapsed time per iteration (ms): 6758.0 | learning rate: 1.596E-05 | global batch size:    32 | lm loss: 7.376366E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      267/  500000 | consumed samples:         8544 | consumed tokens:     34996224 | elapsed time per iteration (ms): 6761.6 | learning rate: 1.602E-05 | global batch size:    32 | lm loss: 7.318575E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration      268/  500000 | consumed samples:         8576 | consumed tokens:     35127296 | elapsed time per iteration (ms): 6757.5 | learning rate: 1.608E-05 | global batch size:    32 | lm loss: 7.207863E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      269/  500000 | consumed samples:         8608 | consumed tokens:     35258368 | elapsed time per iteration (ms): 6763.2 | learning rate: 1.614E-05 | global batch size:    32 | lm loss: 7.349258E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
[2023-10-10 15:40:19,882] [INFO] [logging.py:96:log_dist] [Rank 0] step=270, skipped=0, lr=[1.6199999999999997e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:40:20,142] [INFO] [timer.py:208:stop] epoch=0/micro_step=270/global_step=270, RunningAvgSamplesPerSec=4.74251638733052, CurrSamplesPerSec=4.742711261910822, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      270/  500000 | consumed samples:         8640 | consumed tokens:     35389440 | elapsed time per iteration (ms): 6760.0 | learning rate: 1.620E-05 | global batch size:    32 | lm loss: 7.429785E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      271/  500000 | consumed samples:         8672 | consumed tokens:     35520512 | elapsed time per iteration (ms): 6762.5 | learning rate: 1.626E-05 | global batch size:    32 | lm loss: 7.417524E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration      272/  500000 | consumed samples:         8704 | consumed tokens:     35651584 | elapsed time per iteration (ms): 6761.6 | learning rate: 1.632E-05 | global batch size:    32 | lm loss: 7.240624E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration      273/  500000 | consumed samples:         8736 | consumed tokens:     35782656 | elapsed time per iteration (ms): 6760.2 | learning rate: 1.638E-05 | global batch size:    32 | lm loss: 7.163919E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      274/  500000 | consumed samples:         8768 | consumed tokens:     35913728 | elapsed time per iteration (ms): 6759.8 | learning rate: 1.644E-05 | global batch size:    32 | lm loss: 7.247822E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      275/  500000 | consumed samples:         8800 | consumed tokens:     36044800 | elapsed time per iteration (ms): 6761.4 | learning rate: 1.650E-05 | global batch size:    32 | lm loss: 7.262092E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      276/  500000 | consumed samples:         8832 | consumed tokens:     36175872 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.656E-05 | global batch size:    32 | lm loss: 7.297465E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      277/  500000 | consumed samples:         8864 | consumed tokens:     36306944 | elapsed time per iteration (ms): 6755.8 | learning rate: 1.662E-05 | global batch size:    32 | lm loss: 7.409222E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration      278/  500000 | consumed samples:         8896 | consumed tokens:     36438016 | elapsed time per iteration (ms): 6761.8 | learning rate: 1.668E-05 | global batch size:    32 | lm loss: 7.328591E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      279/  500000 | consumed samples:         8928 | consumed tokens:     36569088 | elapsed time per iteration (ms): 6763.9 | learning rate: 1.674E-05 | global batch size:    32 | lm loss: 7.213859E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
[2023-10-10 15:41:27,531] [INFO] [logging.py:96:log_dist] [Rank 0] step=280, skipped=0, lr=[1.68e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:41:27,791] [INFO] [timer.py:208:stop] epoch=0/micro_step=280/global_step=280, RunningAvgSamplesPerSec=4.742506328458546, CurrSamplesPerSec=4.743815422517395, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      280/  500000 | consumed samples:         8960 | consumed tokens:     36700160 | elapsed time per iteration (ms): 6758.8 | learning rate: 1.680E-05 | global batch size:    32 | lm loss: 7.249053E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      281/  500000 | consumed samples:         8992 | consumed tokens:     36831232 | elapsed time per iteration (ms): 6760.8 | learning rate: 1.686E-05 | global batch size:    32 | lm loss: 7.052162E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      282/  500000 | consumed samples:         9024 | consumed tokens:     36962304 | elapsed time per iteration (ms): 6757.0 | learning rate: 1.692E-05 | global batch size:    32 | lm loss: 7.072103E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      283/  500000 | consumed samples:         9056 | consumed tokens:     37093376 | elapsed time per iteration (ms): 6755.7 | learning rate: 1.698E-05 | global batch size:    32 | lm loss: 7.326135E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration      284/  500000 | consumed samples:         9088 | consumed tokens:     37224448 | elapsed time per iteration (ms): 6758.7 | learning rate: 1.704E-05 | global batch size:    32 | lm loss: 7.112049E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      285/  500000 | consumed samples:         9120 | consumed tokens:     37355520 | elapsed time per iteration (ms): 6760.3 | learning rate: 1.710E-05 | global batch size:    32 | lm loss: 7.091653E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      286/  500000 | consumed samples:         9152 | consumed tokens:     37486592 | elapsed time per iteration (ms): 6758.4 | learning rate: 1.716E-05 | global batch size:    32 | lm loss: 7.382863E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      287/  500000 | consumed samples:         9184 | consumed tokens:     37617664 | elapsed time per iteration (ms): 6759.4 | learning rate: 1.722E-05 | global batch size:    32 | lm loss: 7.129188E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      288/  500000 | consumed samples:         9216 | consumed tokens:     37748736 | elapsed time per iteration (ms): 6756.4 | learning rate: 1.728E-05 | global batch size:    32 | lm loss: 7.145430E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      289/  500000 | consumed samples:         9248 | consumed tokens:     37879808 | elapsed time per iteration (ms): 6756.0 | learning rate: 1.734E-05 | global batch size:    32 | lm loss: 7.255007E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
[2023-10-10 15:42:35,177] [INFO] [logging.py:96:log_dist] [Rank 0] step=290, skipped=0, lr=[1.74e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:42:35,417] [INFO] [timer.py:208:stop] epoch=0/micro_step=290/global_step=290, RunningAvgSamplesPerSec=4.742556861742355, CurrSamplesPerSec=4.7436279790431435, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      290/  500000 | consumed samples:         9280 | consumed tokens:     38010880 | elapsed time per iteration (ms): 6761.7 | learning rate: 1.740E-05 | global batch size:    32 | lm loss: 7.040179E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration      291/  500000 | consumed samples:         9312 | consumed tokens:     38141952 | elapsed time per iteration (ms): 6758.2 | learning rate: 1.746E-05 | global batch size:    32 | lm loss: 7.020023E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      292/  500000 | consumed samples:         9344 | consumed tokens:     38273024 | elapsed time per iteration (ms): 6755.7 | learning rate: 1.752E-05 | global batch size:    32 | lm loss: 7.110760E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration      293/  500000 | consumed samples:         9376 | consumed tokens:     38404096 | elapsed time per iteration (ms): 6758.9 | learning rate: 1.758E-05 | global batch size:    32 | lm loss: 7.076849E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      294/  500000 | consumed samples:         9408 | consumed tokens:     38535168 | elapsed time per iteration (ms): 6761.7 | learning rate: 1.764E-05 | global batch size:    32 | lm loss: 7.208637E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration      295/  500000 | consumed samples:         9440 | consumed tokens:     38666240 | elapsed time per iteration (ms): 6756.7 | learning rate: 1.770E-05 | global batch size:    32 | lm loss: 7.213554E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      296/  500000 | consumed samples:         9472 | consumed tokens:     38797312 | elapsed time per iteration (ms): 6763.9 | learning rate: 1.776E-05 | global batch size:    32 | lm loss: 7.219550E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration      297/  500000 | consumed samples:         9504 | consumed tokens:     38928384 | elapsed time per iteration (ms): 6756.5 | learning rate: 1.782E-05 | global batch size:    32 | lm loss: 6.957877E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      298/  500000 | consumed samples:         9536 | consumed tokens:     39059456 | elapsed time per iteration (ms): 6757.0 | learning rate: 1.788E-05 | global batch size:    32 | lm loss: 7.089254E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      299/  500000 | consumed samples:         9568 | consumed tokens:     39190528 | elapsed time per iteration (ms): 6754.9 | learning rate: 1.794E-05 | global batch size:    32 | lm loss: 7.091210E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.75 |
time (ms)
[2023-10-10 15:43:42,799] [INFO] [logging.py:96:log_dist] [Rank 0] step=300, skipped=0, lr=[1.8e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:43:43,042] [INFO] [timer.py:208:stop] epoch=0/micro_step=300/global_step=300, RunningAvgSamplesPerSec=4.742616888001163, CurrSamplesPerSec=4.743358575953352, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      300/  500000 | consumed samples:         9600 | consumed tokens:     39321600 | elapsed time per iteration (ms): 6759.0 | learning rate: 1.800E-05 | global batch size:    32 | lm loss: 6.999788E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      301/  500000 | consumed samples:         9632 | consumed tokens:     39452672 | elapsed time per iteration (ms): 6756.8 | learning rate: 1.806E-05 | global batch size:    32 | lm loss: 7.149402E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      302/  500000 | consumed samples:         9664 | consumed tokens:     39583744 | elapsed time per iteration (ms): 6760.0 | learning rate: 1.812E-05 | global batch size:    32 | lm loss: 6.964180E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      303/  500000 | consumed samples:         9696 | consumed tokens:     39714816 | elapsed time per iteration (ms): 6761.2 | learning rate: 1.818E-05 | global batch size:    32 | lm loss: 6.996123E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      304/  500000 | consumed samples:         9728 | consumed tokens:     39845888 | elapsed time per iteration (ms): 6761.4 | learning rate: 1.824E-05 | global batch size:    32 | lm loss: 6.864517E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      305/  500000 | consumed samples:         9760 | consumed tokens:     39976960 | elapsed time per iteration (ms): 6760.7 | learning rate: 1.830E-05 | global batch size:    32 | lm loss: 7.140704E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      306/  500000 | consumed samples:         9792 | consumed tokens:     40108032 | elapsed time per iteration (ms): 6767.5 | learning rate: 1.836E-05 | global batch size:    32 | lm loss: 6.902568E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.728 | TFLOPs: 147.48 |
time (ms)
 iteration      307/  500000 | consumed samples:         9824 | consumed tokens:     40239104 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.842E-05 | global batch size:    32 | lm loss: 7.075763E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      308/  500000 | consumed samples:         9856 | consumed tokens:     40370176 | elapsed time per iteration (ms): 6764.7 | learning rate: 1.848E-05 | global batch size:    32 | lm loss: 6.899239E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration      309/  500000 | consumed samples:         9888 | consumed tokens:     40501248 | elapsed time per iteration (ms): 6763.7 | learning rate: 1.854E-05 | global batch size:    32 | lm loss: 6.913365E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
[2023-10-10 15:44:50,445] [INFO] [logging.py:96:log_dist] [Rank 0] step=310, skipped=0, lr=[1.8599999999999998e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:44:50,703] [INFO] [timer.py:208:stop] epoch=0/micro_step=310/global_step=310, RunningAvgSamplesPerSec=4.74258476501703, CurrSamplesPerSec=4.74156758058143, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      310/  500000 | consumed samples:         9920 | consumed tokens:     40632320 | elapsed time per iteration (ms): 6761.7 | learning rate: 1.860E-05 | global batch size:    32 | lm loss: 7.098686E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration      311/  500000 | consumed samples:         9952 | consumed tokens:     40763392 | elapsed time per iteration (ms): 6758.2 | learning rate: 1.866E-05 | global batch size:    32 | lm loss: 6.981508E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      312/  500000 | consumed samples:         9984 | consumed tokens:     40894464 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.872E-05 | global batch size:    32 | lm loss: 6.743202E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      313/  500000 | consumed samples:        10016 | consumed tokens:     41025536 | elapsed time per iteration (ms): 6758.0 | learning rate: 1.878E-05 | global batch size:    32 | lm loss: 6.938783E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      314/  500000 | consumed samples:        10048 | consumed tokens:     41156608 | elapsed time per iteration (ms): 6759.5 | learning rate: 1.884E-05 | global batch size:    32 | lm loss: 6.833649E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      315/  500000 | consumed samples:        10080 | consumed tokens:     41287680 | elapsed time per iteration (ms): 6757.4 | learning rate: 1.890E-05 | global batch size:    32 | lm loss: 7.040600E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      316/  500000 | consumed samples:        10112 | consumed tokens:     41418752 | elapsed time per iteration (ms): 6757.8 | learning rate: 1.896E-05 | global batch size:    32 | lm loss: 7.003067E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      317/  500000 | consumed samples:        10144 | consumed tokens:     41549824 | elapsed time per iteration (ms): 6763.2 | learning rate: 1.902E-05 | global batch size:    32 | lm loss: 6.859761E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration      318/  500000 | consumed samples:        10176 | consumed tokens:     41680896 | elapsed time per iteration (ms): 6759.5 | learning rate: 1.908E-05 | global batch size:    32 | lm loss: 7.005921E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      319/  500000 | consumed samples:        10208 | consumed tokens:     41811968 | elapsed time per iteration (ms): 6758.2 | learning rate: 1.914E-05 | global batch size:    32 | lm loss: 6.805874E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
[2023-10-10 15:45:58,085] [INFO] [logging.py:96:log_dist] [Rank 0] step=320, skipped=0, lr=[1.92e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:45:58,335] [INFO] [timer.py:208:stop] epoch=0/micro_step=320/global_step=320, RunningAvgSamplesPerSec=4.7426154012786075, CurrSamplesPerSec=4.742970367453555, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      320/  500000 | consumed samples:        10240 | consumed tokens:     41943040 | elapsed time per iteration (ms): 6759.5 | learning rate: 1.920E-05 | global batch size:    32 | lm loss: 6.858706E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      321/  500000 | consumed samples:        10272 | consumed tokens:     42074112 | elapsed time per iteration (ms): 6758.6 | learning rate: 1.926E-05 | global batch size:    32 | lm loss: 6.862833E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      322/  500000 | consumed samples:        10304 | consumed tokens:     42205184 | elapsed time per iteration (ms): 6758.2 | learning rate: 1.932E-05 | global batch size:    32 | lm loss: 6.762780E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      323/  500000 | consumed samples:        10336 | consumed tokens:     42336256 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.938E-05 | global batch size:    32 | lm loss: 6.874278E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      324/  500000 | consumed samples:        10368 | consumed tokens:     42467328 | elapsed time per iteration (ms): 6760.1 | learning rate: 1.944E-05 | global batch size:    32 | lm loss: 6.673543E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      325/  500000 | consumed samples:        10400 | consumed tokens:     42598400 | elapsed time per iteration (ms): 6760.1 | learning rate: 1.950E-05 | global batch size:    32 | lm loss: 6.523097E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      326/  500000 | consumed samples:        10432 | consumed tokens:     42729472 | elapsed time per iteration (ms): 6756.8 | learning rate: 1.956E-05 | global batch size:    32 | lm loss: 6.709644E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      327/  500000 | consumed samples:        10464 | consumed tokens:     42860544 | elapsed time per iteration (ms): 6760.9 | learning rate: 1.962E-05 | global batch size:    32 | lm loss: 6.768271E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      328/  500000 | consumed samples:        10496 | consumed tokens:     42991616 | elapsed time per iteration (ms): 6760.8 | learning rate: 1.968E-05 | global batch size:    32 | lm loss: 6.782455E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      329/  500000 | consumed samples:        10528 | consumed tokens:     43122688 | elapsed time per iteration (ms): 6755.9 | learning rate: 1.974E-05 | global batch size:    32 | lm loss: 6.807320E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
[2023-10-10 15:47:05,709] [INFO] [logging.py:96:log_dist] [Rank 0] step=330, skipped=0, lr=[1.9799999999999997e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:47:05,968] [INFO] [timer.py:208:stop] epoch=0/micro_step=330/global_step=330, RunningAvgSamplesPerSec=4.74263727184418, CurrSamplesPerSec=4.743745842039213, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      330/  500000 | consumed samples:        10560 | consumed tokens:     43253760 | elapsed time per iteration (ms): 6758.5 | learning rate: 1.980E-05 | global batch size:    32 | lm loss: 6.739819E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      331/  500000 | consumed samples:        10592 | consumed tokens:     43384832 | elapsed time per iteration (ms): 6756.2 | learning rate: 1.986E-05 | global batch size:    32 | lm loss: 6.562717E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      332/  500000 | consumed samples:        10624 | consumed tokens:     43515904 | elapsed time per iteration (ms): 6761.0 | learning rate: 1.992E-05 | global batch size:    32 | lm loss: 6.946916E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      333/  500000 | consumed samples:        10656 | consumed tokens:     43646976 | elapsed time per iteration (ms): 6758.9 | learning rate: 1.998E-05 | global batch size:    32 | lm loss: 6.720784E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      334/  500000 | consumed samples:        10688 | consumed tokens:     43778048 | elapsed time per iteration (ms): 6763.4 | learning rate: 2.004E-05 | global batch size:    32 | lm loss: 6.919907E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration      335/  500000 | consumed samples:        10720 | consumed tokens:     43909120 | elapsed time per iteration (ms): 6761.2 | learning rate: 2.010E-05 | global batch size:    32 | lm loss: 6.768319E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      336/  500000 | consumed samples:        10752 | consumed tokens:     44040192 | elapsed time per iteration (ms): 6757.6 | learning rate: 2.016E-05 | global batch size:    32 | lm loss: 6.866138E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      337/  500000 | consumed samples:        10784 | consumed tokens:     44171264 | elapsed time per iteration (ms): 6759.9 | learning rate: 2.022E-05 | global batch size:    32 | lm loss: 6.580310E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      338/  500000 | consumed samples:        10816 | consumed tokens:     44302336 | elapsed time per iteration (ms): 6753.2 | learning rate: 2.028E-05 | global batch size:    32 | lm loss: 6.681988E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.738 | TFLOPs: 147.79 |
time (ms)
 iteration      339/  500000 | consumed samples:        10848 | consumed tokens:     44433408 | elapsed time per iteration (ms): 6759.2 | learning rate: 2.034E-05 | global batch size:    32 | lm loss: 6.708851E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
[2023-10-10 15:48:13,345] [INFO] [logging.py:96:log_dist] [Rank 0] step=340, skipped=0, lr=[2.0399999999999998e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:48:13,599] [INFO] [timer.py:208:stop] epoch=0/micro_step=340/global_step=340, RunningAvgSamplesPerSec=4.742661671190962, CurrSamplesPerSec=4.74386136351812, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      340/  500000 | consumed samples:        10880 | consumed tokens:     44564480 | elapsed time per iteration (ms): 6758.2 | learning rate: 2.040E-05 | global batch size:    32 | lm loss: 6.664013E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      341/  500000 | consumed samples:        10912 | consumed tokens:     44695552 | elapsed time per iteration (ms): 6756.1 | learning rate: 2.046E-05 | global batch size:    32 | lm loss: 6.485553E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.73 |
time (ms)
 iteration      342/  500000 | consumed samples:        10944 | consumed tokens:     44826624 | elapsed time per iteration (ms): 6759.2 | learning rate: 2.052E-05 | global batch size:    32 | lm loss: 6.493746E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      343/  500000 | consumed samples:        10976 | consumed tokens:     44957696 | elapsed time per iteration (ms): 6757.4 | learning rate: 2.058E-05 | global batch size:    32 | lm loss: 6.569207E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      344/  500000 | consumed samples:        11008 | consumed tokens:     45088768 | elapsed time per iteration (ms): 6762.5 | learning rate: 2.064E-05 | global batch size:    32 | lm loss: 6.575961E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration      345/  500000 | consumed samples:        11040 | consumed tokens:     45219840 | elapsed time per iteration (ms): 6762.1 | learning rate: 2.070E-05 | global batch size:    32 | lm loss: 6.602455E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      346/  500000 | consumed samples:        11072 | consumed tokens:     45350912 | elapsed time per iteration (ms): 6761.0 | learning rate: 2.076E-05 | global batch size:    32 | lm loss: 6.732681E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      347/  500000 | consumed samples:        11104 | consumed tokens:     45481984 | elapsed time per iteration (ms): 6759.0 | learning rate: 2.082E-05 | global batch size:    32 | lm loss: 6.626066E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      348/  500000 | consumed samples:        11136 | consumed tokens:     45613056 | elapsed time per iteration (ms): 6755.2 | learning rate: 2.088E-05 | global batch size:    32 | lm loss: 6.481436E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.75 |
time (ms)
 iteration      349/  500000 | consumed samples:        11168 | consumed tokens:     45744128 | elapsed time per iteration (ms): 6760.0 | learning rate: 2.094E-05 | global batch size:    32 | lm loss: 6.500280E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
[2023-10-10 15:49:20,974] [INFO] [logging.py:96:log_dist] [Rank 0] step=350, skipped=0, lr=[2.1e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:49:21,231] [INFO] [timer.py:208:stop] epoch=0/micro_step=350/global_step=350, RunningAvgSamplesPerSec=4.742686882765899, CurrSamplesPerSec=4.74445381387619, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      350/  500000 | consumed samples:        11200 | consumed tokens:     45875200 | elapsed time per iteration (ms): 6757.3 | learning rate: 2.100E-05 | global batch size:    32 | lm loss: 6.421716E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      351/  500000 | consumed samples:        11232 | consumed tokens:     46006272 | elapsed time per iteration (ms): 6760.5 | learning rate: 2.106E-05 | global batch size:    32 | lm loss: 6.552094E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      352/  500000 | consumed samples:        11264 | consumed tokens:     46137344 | elapsed time per iteration (ms): 6758.5 | learning rate: 2.112E-05 | global batch size:    32 | lm loss: 6.641948E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      353/  500000 | consumed samples:        11296 | consumed tokens:     46268416 | elapsed time per iteration (ms): 6758.8 | learning rate: 2.118E-05 | global batch size:    32 | lm loss: 6.524736E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      354/  500000 | consumed samples:        11328 | consumed tokens:     46399488 | elapsed time per iteration (ms): 6758.8 | learning rate: 2.124E-05 | global batch size:    32 | lm loss: 6.477570E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      355/  500000 | consumed samples:        11360 | consumed tokens:     46530560 | elapsed time per iteration (ms): 6762.4 | learning rate: 2.130E-05 | global batch size:    32 | lm loss: 6.333309E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      356/  500000 | consumed samples:        11392 | consumed tokens:     46661632 | elapsed time per iteration (ms): 6764.8 | learning rate: 2.136E-05 | global batch size:    32 | lm loss: 6.325042E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration      357/  500000 | consumed samples:        11424 | consumed tokens:     46792704 | elapsed time per iteration (ms): 6758.5 | learning rate: 2.142E-05 | global batch size:    32 | lm loss: 6.400096E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      358/  500000 | consumed samples:        11456 | consumed tokens:     46923776 | elapsed time per iteration (ms): 6758.7 | learning rate: 2.148E-05 | global batch size:    32 | lm loss: 6.587814E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      359/  500000 | consumed samples:        11488 | consumed tokens:     47054848 | elapsed time per iteration (ms): 6759.8 | learning rate: 2.154E-05 | global batch size:    32 | lm loss: 6.562103E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
[2023-10-10 15:50:28,621] [INFO] [logging.py:96:log_dist] [Rank 0] step=360, skipped=0, lr=[2.1599999999999996e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:50:28,871] [INFO] [timer.py:208:stop] epoch=0/micro_step=360/global_step=360, RunningAvgSamplesPerSec=4.742695772690403, CurrSamplesPerSec=4.74422791738725, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      360/  500000 | consumed samples:        11520 | consumed tokens:     47185920 | elapsed time per iteration (ms): 6758.5 | learning rate: 2.160E-05 | global batch size:    32 | lm loss: 6.234617E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      361/  500000 | consumed samples:        11552 | consumed tokens:     47316992 | elapsed time per iteration (ms): 6757.4 | learning rate: 2.166E-05 | global batch size:    32 | lm loss: 6.380296E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      362/  500000 | consumed samples:        11584 | consumed tokens:     47448064 | elapsed time per iteration (ms): 6760.8 | learning rate: 2.172E-05 | global batch size:    32 | lm loss: 6.470047E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      363/  500000 | consumed samples:        11616 | consumed tokens:     47579136 | elapsed time per iteration (ms): 6756.7 | learning rate: 2.178E-05 | global batch size:    32 | lm loss: 6.480954E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      364/  500000 | consumed samples:        11648 | consumed tokens:     47710208 | elapsed time per iteration (ms): 6758.1 | learning rate: 2.184E-05 | global batch size:    32 | lm loss: 6.230893E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      365/  500000 | consumed samples:        11680 | consumed tokens:     47841280 | elapsed time per iteration (ms): 6761.6 | learning rate: 2.190E-05 | global batch size:    32 | lm loss: 6.360651E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration      366/  500000 | consumed samples:        11712 | consumed tokens:     47972352 | elapsed time per iteration (ms): 6759.2 | learning rate: 2.196E-05 | global batch size:    32 | lm loss: 6.371839E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      367/  500000 | consumed samples:        11744 | consumed tokens:     48103424 | elapsed time per iteration (ms): 6763.6 | learning rate: 2.202E-05 | global batch size:    32 | lm loss: 6.151582E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration      368/  500000 | consumed samples:        11776 | consumed tokens:     48234496 | elapsed time per iteration (ms): 6758.6 | learning rate: 2.208E-05 | global batch size:    32 | lm loss: 6.225048E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      369/  500000 | consumed samples:        11808 | consumed tokens:     48365568 | elapsed time per iteration (ms): 6756.7 | learning rate: 2.214E-05 | global batch size:    32 | lm loss: 6.331841E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
[2023-10-10 15:51:36,252] [INFO] [logging.py:96:log_dist] [Rank 0] step=370, skipped=0, lr=[2.2199999999999998e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:51:36,511] [INFO] [timer.py:208:stop] epoch=0/micro_step=370/global_step=370, RunningAvgSamplesPerSec=4.74270490039804, CurrSamplesPerSec=4.740755643747552, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      370/  500000 | consumed samples:        11840 | consumed tokens:     48496640 | elapsed time per iteration (ms): 6761.9 | learning rate: 2.220E-05 | global batch size:    32 | lm loss: 6.062379E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      371/  500000 | consumed samples:        11872 | consumed tokens:     48627712 | elapsed time per iteration (ms): 6763.1 | learning rate: 2.226E-05 | global batch size:    32 | lm loss: 6.238302E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration      372/  500000 | consumed samples:        11904 | consumed tokens:     48758784 | elapsed time per iteration (ms): 6758.7 | learning rate: 2.232E-05 | global batch size:    32 | lm loss: 6.275507E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      373/  500000 | consumed samples:        11936 | consumed tokens:     48889856 | elapsed time per iteration (ms): 6761.7 | learning rate: 2.238E-05 | global batch size:    32 | lm loss: 6.249735E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration      374/  500000 | consumed samples:        11968 | consumed tokens:     49020928 | elapsed time per iteration (ms): 6760.0 | learning rate: 2.244E-05 | global batch size:    32 | lm loss: 6.209453E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      375/  500000 | consumed samples:        12000 | consumed tokens:     49152000 | elapsed time per iteration (ms): 6760.1 | learning rate: 2.250E-05 | global batch size:    32 | lm loss: 6.196077E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      376/  500000 | consumed samples:        12032 | consumed tokens:     49283072 | elapsed time per iteration (ms): 6758.4 | learning rate: 2.256E-05 | global batch size:    32 | lm loss: 6.136754E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      377/  500000 | consumed samples:        12064 | consumed tokens:     49414144 | elapsed time per iteration (ms): 6761.3 | learning rate: 2.262E-05 | global batch size:    32 | lm loss: 6.175267E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      378/  500000 | consumed samples:        12096 | consumed tokens:     49545216 | elapsed time per iteration (ms): 6762.1 | learning rate: 2.268E-05 | global batch size:    32 | lm loss: 6.170152E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      379/  500000 | consumed samples:        12128 | consumed tokens:     49676288 | elapsed time per iteration (ms): 6758.4 | learning rate: 2.274E-05 | global batch size:    32 | lm loss: 6.170462E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
[2023-10-10 15:52:43,909] [INFO] [logging.py:96:log_dist] [Rank 0] step=380, skipped=0, lr=[2.28e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:52:44,158] [INFO] [timer.py:208:stop] epoch=0/micro_step=380/global_step=380, RunningAvgSamplesPerSec=4.742697969276097, CurrSamplesPerSec=4.742936846384093, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      380/  500000 | consumed samples:        12160 | consumed tokens:     49807360 | elapsed time per iteration (ms): 6761.0 | learning rate: 2.280E-05 | global batch size:    32 | lm loss: 6.312484E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      381/  500000 | consumed samples:        12192 | consumed tokens:     49938432 | elapsed time per iteration (ms): 6755.0 | learning rate: 2.286E-05 | global batch size:    32 | lm loss: 6.117746E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.75 |
time (ms)
 iteration      382/  500000 | consumed samples:        12224 | consumed tokens:     50069504 | elapsed time per iteration (ms): 6757.9 | learning rate: 2.292E-05 | global batch size:    32 | lm loss: 6.103880E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      383/  500000 | consumed samples:        12256 | consumed tokens:     50200576 | elapsed time per iteration (ms): 6762.5 | learning rate: 2.298E-05 | global batch size:    32 | lm loss: 6.103306E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      384/  500000 | consumed samples:        12288 | consumed tokens:     50331648 | elapsed time per iteration (ms): 6758.8 | learning rate: 2.304E-05 | global batch size:    32 | lm loss: 6.341750E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      385/  500000 | consumed samples:        12320 | consumed tokens:     50462720 | elapsed time per iteration (ms): 6766.7 | learning rate: 2.310E-05 | global batch size:    32 | lm loss: 5.866222E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.49 |
time (ms)
 iteration      386/  500000 | consumed samples:        12352 | consumed tokens:     50593792 | elapsed time per iteration (ms): 6760.8 | learning rate: 2.316E-05 | global batch size:    32 | lm loss: 6.067092E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      387/  500000 | consumed samples:        12384 | consumed tokens:     50724864 | elapsed time per iteration (ms): 6760.1 | learning rate: 2.322E-05 | global batch size:    32 | lm loss: 6.020246E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      388/  500000 | consumed samples:        12416 | consumed tokens:     50855936 | elapsed time per iteration (ms): 6762.0 | learning rate: 2.328E-05 | global batch size:    32 | lm loss: 6.028247E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      389/  500000 | consumed samples:        12448 | consumed tokens:     50987008 | elapsed time per iteration (ms): 6762.1 | learning rate: 2.334E-05 | global batch size:    32 | lm loss: 5.969207E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
[2023-10-10 15:53:51,573] [INFO] [logging.py:96:log_dist] [Rank 0] step=390, skipped=0, lr=[2.34e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:53:51,809] [INFO] [timer.py:208:stop] epoch=0/micro_step=390/global_step=390, RunningAvgSamplesPerSec=4.742695007636913, CurrSamplesPerSec=4.742100649062607, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      390/  500000 | consumed samples:        12480 | consumed tokens:     51118080 | elapsed time per iteration (ms): 6761.2 | learning rate: 2.340E-05 | global batch size:    32 | lm loss: 6.044401E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      391/  500000 | consumed samples:        12512 | consumed tokens:     51249152 | elapsed time per iteration (ms): 6755.8 | learning rate: 2.346E-05 | global batch size:    32 | lm loss: 6.001266E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration      392/  500000 | consumed samples:        12544 | consumed tokens:     51380224 | elapsed time per iteration (ms): 6765.6 | learning rate: 2.352E-05 | global batch size:    32 | lm loss: 6.167052E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration      393/  500000 | consumed samples:        12576 | consumed tokens:     51511296 | elapsed time per iteration (ms): 6759.7 | learning rate: 2.358E-05 | global batch size:    32 | lm loss: 5.907372E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      394/  500000 | consumed samples:        12608 | consumed tokens:     51642368 | elapsed time per iteration (ms): 6758.9 | learning rate: 2.364E-05 | global batch size:    32 | lm loss: 5.929598E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.66 |
time (ms)
 iteration      395/  500000 | consumed samples:        12640 | consumed tokens:     51773440 | elapsed time per iteration (ms): 6759.3 | learning rate: 2.370E-05 | global batch size:    32 | lm loss: 5.964022E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      396/  500000 | consumed samples:        12672 | consumed tokens:     51904512 | elapsed time per iteration (ms): 6758.8 | learning rate: 2.376E-05 | global batch size:    32 | lm loss: 5.989956E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      397/  500000 | consumed samples:        12704 | consumed tokens:     52035584 | elapsed time per iteration (ms): 6754.7 | learning rate: 2.382E-05 | global batch size:    32 | lm loss: 5.974525E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.76 |
time (ms)
 iteration      398/  500000 | consumed samples:        12736 | consumed tokens:     52166656 | elapsed time per iteration (ms): 6757.9 | learning rate: 2.388E-05 | global batch size:    32 | lm loss: 5.785110E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      399/  500000 | consumed samples:        12768 | consumed tokens:     52297728 | elapsed time per iteration (ms): 6762.2 | learning rate: 2.394E-05 | global batch size:    32 | lm loss: 5.889833E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
[2023-10-10 15:54:59,191] [INFO] [logging.py:96:log_dist] [Rank 0] step=400, skipped=0, lr=[2.4e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:54:59,442] [INFO] [timer.py:208:stop] epoch=0/micro_step=400/global_step=400, RunningAvgSamplesPerSec=4.74272332913551, CurrSamplesPerSec=4.742850196615, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      400/  500000 | consumed samples:        12800 | consumed tokens:     52428800 | elapsed time per iteration (ms): 6759.5 | learning rate: 2.400E-05 | global batch size:    32 | lm loss: 5.961965E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      401/  500000 | consumed samples:        12832 | consumed tokens:     52559872 | elapsed time per iteration (ms): 6758.7 | learning rate: 2.406E-05 | global batch size:    32 | lm loss: 5.722687E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      402/  500000 | consumed samples:        12864 | consumed tokens:     52690944 | elapsed time per iteration (ms): 6757.4 | learning rate: 2.412E-05 | global batch size:    32 | lm loss: 5.809375E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      403/  500000 | consumed samples:        12896 | consumed tokens:     52822016 | elapsed time per iteration (ms): 6758.6 | learning rate: 2.418E-05 | global batch size:    32 | lm loss: 5.887297E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      404/  500000 | consumed samples:        12928 | consumed tokens:     52953088 | elapsed time per iteration (ms): 6761.0 | learning rate: 2.424E-05 | global batch size:    32 | lm loss: 5.819180E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      405/  500000 | consumed samples:        12960 | consumed tokens:     53084160 | elapsed time per iteration (ms): 6756.7 | learning rate: 2.430E-05 | global batch size:    32 | lm loss: 5.914252E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      406/  500000 | consumed samples:        12992 | consumed tokens:     53215232 | elapsed time per iteration (ms): 6761.7 | learning rate: 2.436E-05 | global batch size:    32 | lm loss: 5.890604E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration      407/  500000 | consumed samples:        13024 | consumed tokens:     53346304 | elapsed time per iteration (ms): 6759.5 | learning rate: 2.442E-05 | global batch size:    32 | lm loss: 5.715498E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      408/  500000 | consumed samples:        13056 | consumed tokens:     53477376 | elapsed time per iteration (ms): 6757.6 | learning rate: 2.448E-05 | global batch size:    32 | lm loss: 5.765319E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      409/  500000 | consumed samples:        13088 | consumed tokens:     53608448 | elapsed time per iteration (ms): 6759.6 | learning rate: 2.454E-05 | global batch size:    32 | lm loss: 5.769652E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
[2023-10-10 15:56:06,815] [INFO] [logging.py:96:log_dist] [Rank 0] step=410, skipped=0, lr=[2.4599999999999998e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:56:07,072] [INFO] [timer.py:208:stop] epoch=0/micro_step=410/global_step=410, RunningAvgSamplesPerSec=4.742753605835012, CurrSamplesPerSec=4.7461293390583, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      410/  500000 | consumed samples:        13120 | consumed tokens:     53739520 | elapsed time per iteration (ms): 6757.1 | learning rate: 2.460E-05 | global batch size:    32 | lm loss: 5.745727E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      411/  500000 | consumed samples:        13152 | consumed tokens:     53870592 | elapsed time per iteration (ms): 6757.2 | learning rate: 2.466E-05 | global batch size:    32 | lm loss: 5.714594E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      412/  500000 | consumed samples:        13184 | consumed tokens:     54001664 | elapsed time per iteration (ms): 6763.2 | learning rate: 2.472E-05 | global batch size:    32 | lm loss: 5.769684E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration      413/  500000 | consumed samples:        13216 | consumed tokens:     54132736 | elapsed time per iteration (ms): 6763.7 | learning rate: 2.478E-05 | global batch size:    32 | lm loss: 5.675783E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration      414/  500000 | consumed samples:        13248 | consumed tokens:     54263808 | elapsed time per iteration (ms): 6758.0 | learning rate: 2.484E-05 | global batch size:    32 | lm loss: 5.747679E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      415/  500000 | consumed samples:        13280 | consumed tokens:     54394880 | elapsed time per iteration (ms): 6758.7 | learning rate: 2.490E-05 | global batch size:    32 | lm loss: 5.695416E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      416/  500000 | consumed samples:        13312 | consumed tokens:     54525952 | elapsed time per iteration (ms): 6756.3 | learning rate: 2.496E-05 | global batch size:    32 | lm loss: 5.654019E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      417/  500000 | consumed samples:        13344 | consumed tokens:     54657024 | elapsed time per iteration (ms): 6760.9 | learning rate: 2.502E-05 | global batch size:    32 | lm loss: 5.766978E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      418/  500000 | consumed samples:        13376 | consumed tokens:     54788096 | elapsed time per iteration (ms): 6757.3 | learning rate: 2.508E-05 | global batch size:    32 | lm loss: 5.537121E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      419/  500000 | consumed samples:        13408 | consumed tokens:     54919168 | elapsed time per iteration (ms): 6761.8 | learning rate: 2.514E-05 | global batch size:    32 | lm loss: 5.537119E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
[2023-10-10 15:57:14,457] [INFO] [logging.py:96:log_dist] [Rank 0] step=420, skipped=0, lr=[2.52e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:57:14,710] [INFO] [timer.py:208:stop] epoch=0/micro_step=420/global_step=420, RunningAvgSamplesPerSec=4.742764155427744, CurrSamplesPerSec=4.744071462718273, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      420/  500000 | consumed samples:        13440 | consumed tokens:     55050240 | elapsed time per iteration (ms): 6758.1 | learning rate: 2.520E-05 | global batch size:    32 | lm loss: 5.705246E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      421/  500000 | consumed samples:        13472 | consumed tokens:     55181312 | elapsed time per iteration (ms): 6757.7 | learning rate: 2.526E-05 | global batch size:    32 | lm loss: 5.393906E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      422/  500000 | consumed samples:        13504 | consumed tokens:     55312384 | elapsed time per iteration (ms): 6760.4 | learning rate: 2.532E-05 | global batch size:    32 | lm loss: 5.584728E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      423/  500000 | consumed samples:        13536 | consumed tokens:     55443456 | elapsed time per iteration (ms): 6761.2 | learning rate: 2.538E-05 | global batch size:    32 | lm loss: 5.511474E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      424/  500000 | consumed samples:        13568 | consumed tokens:     55574528 | elapsed time per iteration (ms): 6757.9 | learning rate: 2.544E-05 | global batch size:    32 | lm loss: 5.863040E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      425/  500000 | consumed samples:        13600 | consumed tokens:     55705600 | elapsed time per iteration (ms): 6762.0 | learning rate: 2.550E-05 | global batch size:    32 | lm loss: 5.520978E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      426/  500000 | consumed samples:        13632 | consumed tokens:     55836672 | elapsed time per iteration (ms): 6759.2 | learning rate: 2.556E-05 | global batch size:    32 | lm loss: 5.558794E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      427/  500000 | consumed samples:        13664 | consumed tokens:     55967744 | elapsed time per iteration (ms): 6758.9 | learning rate: 2.562E-05 | global batch size:    32 | lm loss: 5.548527E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.66 |
time (ms)
 iteration      428/  500000 | consumed samples:        13696 | consumed tokens:     56098816 | elapsed time per iteration (ms): 6762.5 | learning rate: 2.568E-05 | global batch size:    32 | lm loss: 5.459344E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration      429/  500000 | consumed samples:        13728 | consumed tokens:     56229888 | elapsed time per iteration (ms): 6757.3 | learning rate: 2.574E-05 | global batch size:    32 | lm loss: 5.633633E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
[2023-10-10 15:58:22,093] [INFO] [logging.py:96:log_dist] [Rank 0] step=430, skipped=0, lr=[2.5799999999999994e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:58:22,351] [INFO] [timer.py:208:stop] epoch=0/micro_step=430/global_step=430, RunningAvgSamplesPerSec=4.7427749212289205, CurrSamplesPerSec=4.740610469007673, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      430/  500000 | consumed samples:        13760 | consumed tokens:     56360960 | elapsed time per iteration (ms): 6763.2 | learning rate: 2.580E-05 | global batch size:    32 | lm loss: 5.373750E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration      431/  500000 | consumed samples:        13792 | consumed tokens:     56492032 | elapsed time per iteration (ms): 6763.2 | learning rate: 2.586E-05 | global batch size:    32 | lm loss: 5.483280E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration      432/  500000 | consumed samples:        13824 | consumed tokens:     56623104 | elapsed time per iteration (ms): 6763.5 | learning rate: 2.592E-05 | global batch size:    32 | lm loss: 5.464255E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration      433/  500000 | consumed samples:        13856 | consumed tokens:     56754176 | elapsed time per iteration (ms): 6766.6 | learning rate: 2.598E-05 | global batch size:    32 | lm loss: 5.343494E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.50 |
time (ms)
 iteration      434/  500000 | consumed samples:        13888 | consumed tokens:     56885248 | elapsed time per iteration (ms): 6760.6 | learning rate: 2.604E-05 | global batch size:    32 | lm loss: 5.317759E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      435/  500000 | consumed samples:        13920 | consumed tokens:     57016320 | elapsed time per iteration (ms): 6761.2 | learning rate: 2.610E-05 | global batch size:    32 | lm loss: 5.431327E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      436/  500000 | consumed samples:        13952 | consumed tokens:     57147392 | elapsed time per iteration (ms): 6757.5 | learning rate: 2.616E-05 | global batch size:    32 | lm loss: 5.300833E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      437/  500000 | consumed samples:        13984 | consumed tokens:     57278464 | elapsed time per iteration (ms): 6759.9 | learning rate: 2.622E-05 | global batch size:    32 | lm loss: 5.355775E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      438/  500000 | consumed samples:        14016 | consumed tokens:     57409536 | elapsed time per iteration (ms): 6760.6 | learning rate: 2.628E-05 | global batch size:    32 | lm loss: 5.524130E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      439/  500000 | consumed samples:        14048 | consumed tokens:     57540608 | elapsed time per iteration (ms): 6761.1 | learning rate: 2.634E-05 | global batch size:    32 | lm loss: 5.297164E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
[2023-10-10 15:59:29,747] [INFO] [logging.py:96:log_dist] [Rank 0] step=440, skipped=0, lr=[2.6399999999999995e-05], mom=[(0.9, 0.95)]
[2023-10-10 15:59:30,006] [INFO] [timer.py:208:stop] epoch=0/micro_step=440/global_step=440, RunningAvgSamplesPerSec=4.742762260166708, CurrSamplesPerSec=4.744883361637432, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      440/  500000 | consumed samples:        14080 | consumed tokens:     57671680 | elapsed time per iteration (ms): 6756.5 | learning rate: 2.640E-05 | global batch size:    32 | lm loss: 5.257982E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      441/  500000 | consumed samples:        14112 | consumed tokens:     57802752 | elapsed time per iteration (ms): 6755.3 | learning rate: 2.646E-05 | global batch size:    32 | lm loss: 5.196831E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration      442/  500000 | consumed samples:        14144 | consumed tokens:     57933824 | elapsed time per iteration (ms): 6762.1 | learning rate: 2.652E-05 | global batch size:    32 | lm loss: 5.179461E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      443/  500000 | consumed samples:        14176 | consumed tokens:     58064896 | elapsed time per iteration (ms): 6758.0 | learning rate: 2.658E-05 | global batch size:    32 | lm loss: 5.164244E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      444/  500000 | consumed samples:        14208 | consumed tokens:     58195968 | elapsed time per iteration (ms): 6760.3 | learning rate: 2.664E-05 | global batch size:    32 | lm loss: 5.263669E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration      445/  500000 | consumed samples:        14240 | consumed tokens:     58327040 | elapsed time per iteration (ms): 6758.1 | learning rate: 2.670E-05 | global batch size:    32 | lm loss: 5.092769E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      446/  500000 | consumed samples:        14272 | consumed tokens:     58458112 | elapsed time per iteration (ms): 6758.0 | learning rate: 2.676E-05 | global batch size:    32 | lm loss: 5.131820E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      447/  500000 | consumed samples:        14304 | consumed tokens:     58589184 | elapsed time per iteration (ms): 6758.5 | learning rate: 2.682E-05 | global batch size:    32 | lm loss: 5.077338E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      448/  500000 | consumed samples:        14336 | consumed tokens:     58720256 | elapsed time per iteration (ms): 6756.2 | learning rate: 2.688E-05 | global batch size:    32 | lm loss: 5.208125E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      449/  500000 | consumed samples:        14368 | consumed tokens:     58851328 | elapsed time per iteration (ms): 6756.3 | learning rate: 2.694E-05 | global batch size:    32 | lm loss: 5.125815E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
[2023-10-10 16:00:37,369] [INFO] [logging.py:96:log_dist] [Rank 0] step=450, skipped=0, lr=[2.6999999999999996e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:00:37,628] [INFO] [timer.py:208:stop] epoch=0/micro_step=450/global_step=450, RunningAvgSamplesPerSec=4.742791483409246, CurrSamplesPerSec=4.743982423993378, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      450/  500000 | consumed samples:        14400 | consumed tokens:     58982400 | elapsed time per iteration (ms): 6758.0 | learning rate: 2.700E-05 | global batch size:    32 | lm loss: 5.084823E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      451/  500000 | consumed samples:        14432 | consumed tokens:     59113472 | elapsed time per iteration (ms): 6759.5 | learning rate: 2.706E-05 | global batch size:    32 | lm loss: 5.115314E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      452/  500000 | consumed samples:        14464 | consumed tokens:     59244544 | elapsed time per iteration (ms): 6760.7 | learning rate: 2.712E-05 | global batch size:    32 | lm loss: 5.188080E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      453/  500000 | consumed samples:        14496 | consumed tokens:     59375616 | elapsed time per iteration (ms): 6759.8 | learning rate: 2.718E-05 | global batch size:    32 | lm loss: 5.027830E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      454/  500000 | consumed samples:        14528 | consumed tokens:     59506688 | elapsed time per iteration (ms): 6757.5 | learning rate: 2.724E-05 | global batch size:    32 | lm loss: 5.024026E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      455/  500000 | consumed samples:        14560 | consumed tokens:     59637760 | elapsed time per iteration (ms): 6760.3 | learning rate: 2.730E-05 | global batch size:    32 | lm loss: 5.075999E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      456/  500000 | consumed samples:        14592 | consumed tokens:     59768832 | elapsed time per iteration (ms): 6760.0 | learning rate: 2.736E-05 | global batch size:    32 | lm loss: 4.800053E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      457/  500000 | consumed samples:        14624 | consumed tokens:     59899904 | elapsed time per iteration (ms): 6760.8 | learning rate: 2.742E-05 | global batch size:    32 | lm loss: 4.922127E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      458/  500000 | consumed samples:        14656 | consumed tokens:     60030976 | elapsed time per iteration (ms): 6763.5 | learning rate: 2.748E-05 | global batch size:    32 | lm loss: 4.825469E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration      459/  500000 | consumed samples:        14688 | consumed tokens:     60162048 | elapsed time per iteration (ms): 6761.0 | learning rate: 2.754E-05 | global batch size:    32 | lm loss: 5.062218E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
[2023-10-10 16:01:45,012] [INFO] [logging.py:96:log_dist] [Rank 0] step=460, skipped=0, lr=[2.7599999999999997e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:01:45,272] [INFO] [timer.py:208:stop] epoch=0/micro_step=460/global_step=460, RunningAvgSamplesPerSec=4.742786011094119, CurrSamplesPerSec=4.743504086702911, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      460/  500000 | consumed samples:        14720 | consumed tokens:     60293120 | elapsed time per iteration (ms): 6759.3 | learning rate: 2.760E-05 | global batch size:    32 | lm loss: 5.086600E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      461/  500000 | consumed samples:        14752 | consumed tokens:     60424192 | elapsed time per iteration (ms): 6756.3 | learning rate: 2.766E-05 | global batch size:    32 | lm loss: 4.880909E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      462/  500000 | consumed samples:        14784 | consumed tokens:     60555264 | elapsed time per iteration (ms): 6761.9 | learning rate: 2.772E-05 | global batch size:    32 | lm loss: 5.028026E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      463/  500000 | consumed samples:        14816 | consumed tokens:     60686336 | elapsed time per iteration (ms): 6762.8 | learning rate: 2.778E-05 | global batch size:    32 | lm loss: 4.948284E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration      464/  500000 | consumed samples:        14848 | consumed tokens:     60817408 | elapsed time per iteration (ms): 6764.7 | learning rate: 2.784E-05 | global batch size:    32 | lm loss: 4.824795E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration      465/  500000 | consumed samples:        14880 | consumed tokens:     60948480 | elapsed time per iteration (ms): 6762.3 | learning rate: 2.790E-05 | global batch size:    32 | lm loss: 4.966940E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      466/  500000 | consumed samples:        14912 | consumed tokens:     61079552 | elapsed time per iteration (ms): 6761.6 | learning rate: 2.796E-05 | global batch size:    32 | lm loss: 4.858407E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      467/  500000 | consumed samples:        14944 | consumed tokens:     61210624 | elapsed time per iteration (ms): 6761.3 | learning rate: 2.802E-05 | global batch size:    32 | lm loss: 4.695291E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      468/  500000 | consumed samples:        14976 | consumed tokens:     61341696 | elapsed time per iteration (ms): 6760.8 | learning rate: 2.808E-05 | global batch size:    32 | lm loss: 4.857869E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      469/  500000 | consumed samples:        15008 | consumed tokens:     61472768 | elapsed time per iteration (ms): 6760.7 | learning rate: 2.814E-05 | global batch size:    32 | lm loss: 4.784474E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
[2023-10-10 16:02:52,692] [INFO] [logging.py:96:log_dist] [Rank 0] step=470, skipped=0, lr=[2.8199999999999998e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:02:52,928] [INFO] [timer.py:208:stop] epoch=0/micro_step=470/global_step=470, RunningAvgSamplesPerSec=4.74275771330834, CurrSamplesPerSec=4.742147227049423, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      470/  500000 | consumed samples:        15040 | consumed tokens:     61603840 | elapsed time per iteration (ms): 6760.4 | learning rate: 2.820E-05 | global batch size:    32 | lm loss: 4.754395E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      471/  500000 | consumed samples:        15072 | consumed tokens:     61734912 | elapsed time per iteration (ms): 6758.8 | learning rate: 2.826E-05 | global batch size:    32 | lm loss: 4.825166E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      472/  500000 | consumed samples:        15104 | consumed tokens:     61865984 | elapsed time per iteration (ms): 6759.6 | learning rate: 2.832E-05 | global batch size:    32 | lm loss: 4.742743E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      473/  500000 | consumed samples:        15136 | consumed tokens:     61997056 | elapsed time per iteration (ms): 6757.7 | learning rate: 2.838E-05 | global batch size:    32 | lm loss: 4.779322E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      474/  500000 | consumed samples:        15168 | consumed tokens:     62128128 | elapsed time per iteration (ms): 6755.5 | learning rate: 2.844E-05 | global batch size:    32 | lm loss: 4.968825E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration      475/  500000 | consumed samples:        15200 | consumed tokens:     62259200 | elapsed time per iteration (ms): 6755.7 | learning rate: 2.850E-05 | global batch size:    32 | lm loss: 4.702716E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration      476/  500000 | consumed samples:        15232 | consumed tokens:     62390272 | elapsed time per iteration (ms): 6760.5 | learning rate: 2.856E-05 | global batch size:    32 | lm loss: 4.665820E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      477/  500000 | consumed samples:        15264 | consumed tokens:     62521344 | elapsed time per iteration (ms): 6759.7 | learning rate: 2.862E-05 | global batch size:    32 | lm loss: 4.643240E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      478/  500000 | consumed samples:        15296 | consumed tokens:     62652416 | elapsed time per iteration (ms): 6759.8 | learning rate: 2.868E-05 | global batch size:    32 | lm loss: 4.550487E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      479/  500000 | consumed samples:        15328 | consumed tokens:     62783488 | elapsed time per iteration (ms): 6757.7 | learning rate: 2.874E-05 | global batch size:    32 | lm loss: 4.567701E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
[2023-10-10 16:04:00,302] [INFO] [logging.py:96:log_dist] [Rank 0] step=480, skipped=0, lr=[2.88e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:04:00,552] [INFO] [timer.py:208:stop] epoch=0/micro_step=480/global_step=480, RunningAvgSamplesPerSec=4.74278273655892, CurrSamplesPerSec=4.74425625808286, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      480/  500000 | consumed samples:        15360 | consumed tokens:     62914560 | elapsed time per iteration (ms): 6757.1 | learning rate: 2.880E-05 | global batch size:    32 | lm loss: 4.499611E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      481/  500000 | consumed samples:        15392 | consumed tokens:     63045632 | elapsed time per iteration (ms): 6758.4 | learning rate: 2.886E-05 | global batch size:    32 | lm loss: 4.578510E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      482/  500000 | consumed samples:        15424 | consumed tokens:     63176704 | elapsed time per iteration (ms): 6758.7 | learning rate: 2.892E-05 | global batch size:    32 | lm loss: 4.576523E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      483/  500000 | consumed samples:        15456 | consumed tokens:     63307776 | elapsed time per iteration (ms): 6756.5 | learning rate: 2.898E-05 | global batch size:    32 | lm loss: 4.654500E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      484/  500000 | consumed samples:        15488 | consumed tokens:     63438848 | elapsed time per iteration (ms): 6759.4 | learning rate: 2.904E-05 | global batch size:    32 | lm loss: 4.607426E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      485/  500000 | consumed samples:        15520 | consumed tokens:     63569920 | elapsed time per iteration (ms): 6760.6 | learning rate: 2.910E-05 | global batch size:    32 | lm loss: 4.492428E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      486/  500000 | consumed samples:        15552 | consumed tokens:     63700992 | elapsed time per iteration (ms): 6759.7 | learning rate: 2.916E-05 | global batch size:    32 | lm loss: 4.538052E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      487/  500000 | consumed samples:        15584 | consumed tokens:     63832064 | elapsed time per iteration (ms): 6761.4 | learning rate: 2.922E-05 | global batch size:    32 | lm loss: 4.422534E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      488/  500000 | consumed samples:        15616 | consumed tokens:     63963136 | elapsed time per iteration (ms): 6760.5 | learning rate: 2.928E-05 | global batch size:    32 | lm loss: 4.427040E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      489/  500000 | consumed samples:        15648 | consumed tokens:     64094208 | elapsed time per iteration (ms): 6760.8 | learning rate: 2.934E-05 | global batch size:    32 | lm loss: 4.435695E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
[2023-10-10 16:05:07,937] [INFO] [logging.py:96:log_dist] [Rank 0] step=490, skipped=0, lr=[2.94e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:05:08,192] [INFO] [timer.py:208:stop] epoch=0/micro_step=490/global_step=490, RunningAvgSamplesPerSec=4.7427821472925915, CurrSamplesPerSec=4.741333751777898, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      490/  500000 | consumed samples:        15680 | consumed tokens:     64225280 | elapsed time per iteration (ms): 6762.8 | learning rate: 2.940E-05 | global batch size:    32 | lm loss: 4.471767E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration      491/  500000 | consumed samples:        15712 | consumed tokens:     64356352 | elapsed time per iteration (ms): 6762.8 | learning rate: 2.946E-05 | global batch size:    32 | lm loss: 4.390067E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration      492/  500000 | consumed samples:        15744 | consumed tokens:     64487424 | elapsed time per iteration (ms): 6757.0 | learning rate: 2.952E-05 | global batch size:    32 | lm loss: 4.323988E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      493/  500000 | consumed samples:        15776 | consumed tokens:     64618496 | elapsed time per iteration (ms): 6760.5 | learning rate: 2.958E-05 | global batch size:    32 | lm loss: 4.271497E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      494/  500000 | consumed samples:        15808 | consumed tokens:     64749568 | elapsed time per iteration (ms): 6759.7 | learning rate: 2.964E-05 | global batch size:    32 | lm loss: 4.206047E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      495/  500000 | consumed samples:        15840 | consumed tokens:     64880640 | elapsed time per iteration (ms): 6763.1 | learning rate: 2.970E-05 | global batch size:    32 | lm loss: 4.154267E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration      496/  500000 | consumed samples:        15872 | consumed tokens:     65011712 | elapsed time per iteration (ms): 6767.7 | learning rate: 2.976E-05 | global batch size:    32 | lm loss: 4.268830E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.728 | TFLOPs: 147.47 |
time (ms)
 iteration      497/  500000 | consumed samples:        15904 | consumed tokens:     65142784 | elapsed time per iteration (ms): 6759.9 | learning rate: 2.982E-05 | global batch size:    32 | lm loss: 4.363283E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      498/  500000 | consumed samples:        15936 | consumed tokens:     65273856 | elapsed time per iteration (ms): 6763.2 | learning rate: 2.988E-05 | global batch size:    32 | lm loss: 4.248526E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration      499/  500000 | consumed samples:        15968 | consumed tokens:     65404928 | elapsed time per iteration (ms): 6761.4 | learning rate: 2.994E-05 | global batch size:    32 | lm loss: 4.237849E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
[2023-10-10 16:06:15,593] [INFO] [logging.py:96:log_dist] [Rank 0] step=500, skipped=0, lr=[2.9999999999999997e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:06:15,854] [INFO] [timer.py:208:stop] epoch=0/micro_step=500/global_step=500, RunningAvgSamplesPerSec=4.742757278784566, CurrSamplesPerSec=4.73966412085211, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      500/  500000 | consumed samples:        16000 | consumed tokens:     65536000 | elapsed time per iteration (ms): 6766.8 | learning rate: 3.000E-05 | global batch size:    32 | lm loss: 4.240351E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.49 |
time (ms)
 iteration      501/  500000 | consumed samples:        16032 | consumed tokens:     65667072 | elapsed time per iteration (ms): 6758.9 | learning rate: 3.006E-05 | global batch size:    32 | lm loss: 4.337089E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      502/  500000 | consumed samples:        16064 | consumed tokens:     65798144 | elapsed time per iteration (ms): 6762.8 | learning rate: 3.012E-05 | global batch size:    32 | lm loss: 4.234842E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration      503/  500000 | consumed samples:        16096 | consumed tokens:     65929216 | elapsed time per iteration (ms): 6762.0 | learning rate: 3.018E-05 | global batch size:    32 | lm loss: 4.282205E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      504/  500000 | consumed samples:        16128 | consumed tokens:     66060288 | elapsed time per iteration (ms): 6759.9 | learning rate: 3.024E-05 | global batch size:    32 | lm loss: 4.127256E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      505/  500000 | consumed samples:        16160 | consumed tokens:     66191360 | elapsed time per iteration (ms): 6757.6 | learning rate: 3.030E-05 | global batch size:    32 | lm loss: 4.056009E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      506/  500000 | consumed samples:        16192 | consumed tokens:     66322432 | elapsed time per iteration (ms): 6755.9 | learning rate: 3.036E-05 | global batch size:    32 | lm loss: 4.156898E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration      507/  500000 | consumed samples:        16224 | consumed tokens:     66453504 | elapsed time per iteration (ms): 6761.9 | learning rate: 3.042E-05 | global batch size:    32 | lm loss: 4.006587E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      508/  500000 | consumed samples:        16256 | consumed tokens:     66584576 | elapsed time per iteration (ms): 6760.6 | learning rate: 3.048E-05 | global batch size:    32 | lm loss: 4.074727E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      509/  500000 | consumed samples:        16288 | consumed tokens:     66715648 | elapsed time per iteration (ms): 6759.3 | learning rate: 3.054E-05 | global batch size:    32 | lm loss: 4.188159E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
[2023-10-10 16:07:23,243] [INFO] [logging.py:96:log_dist] [Rank 0] step=510, skipped=0, lr=[3.06e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:07:23,498] [INFO] [timer.py:208:stop] epoch=0/micro_step=510/global_step=510, RunningAvgSamplesPerSec=4.742757736756938, CurrSamplesPerSec=4.743105629782147, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      510/  500000 | consumed samples:        16320 | consumed tokens:     66846720 | elapsed time per iteration (ms): 6760.1 | learning rate: 3.060E-05 | global batch size:    32 | lm loss: 4.010792E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      511/  500000 | consumed samples:        16352 | consumed tokens:     66977792 | elapsed time per iteration (ms): 6762.0 | learning rate: 3.066E-05 | global batch size:    32 | lm loss: 3.931184E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      512/  500000 | consumed samples:        16384 | consumed tokens:     67108864 | elapsed time per iteration (ms): 6761.2 | learning rate: 3.072E-05 | global batch size:    32 | lm loss: 4.054518E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      513/  500000 | consumed samples:        16416 | consumed tokens:     67239936 | elapsed time per iteration (ms): 6759.8 | learning rate: 3.078E-05 | global batch size:    32 | lm loss: 3.983842E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      514/  500000 | consumed samples:        16448 | consumed tokens:     67371008 | elapsed time per iteration (ms): 6759.1 | learning rate: 3.084E-05 | global batch size:    32 | lm loss: 3.862477E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      515/  500000 | consumed samples:        16480 | consumed tokens:     67502080 | elapsed time per iteration (ms): 6758.9 | learning rate: 3.090E-05 | global batch size:    32 | lm loss: 4.036661E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.66 |
time (ms)
 iteration      516/  500000 | consumed samples:        16512 | consumed tokens:     67633152 | elapsed time per iteration (ms): 6758.1 | learning rate: 3.096E-05 | global batch size:    32 | lm loss: 4.023572E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      517/  500000 | consumed samples:        16544 | consumed tokens:     67764224 | elapsed time per iteration (ms): 6757.8 | learning rate: 3.102E-05 | global batch size:    32 | lm loss: 3.818558E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      518/  500000 | consumed samples:        16576 | consumed tokens:     67895296 | elapsed time per iteration (ms): 6761.8 | learning rate: 3.108E-05 | global batch size:    32 | lm loss: 3.842481E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      519/  500000 | consumed samples:        16608 | consumed tokens:     68026368 | elapsed time per iteration (ms): 6761.3 | learning rate: 3.114E-05 | global batch size:    32 | lm loss: 3.897780E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
[2023-10-10 16:08:30,879] [INFO] [logging.py:96:log_dist] [Rank 0] step=520, skipped=0, lr=[3.12e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:08:31,139] [INFO] [timer.py:208:stop] epoch=0/micro_step=520/global_step=520, RunningAvgSamplesPerSec=4.742754352210124, CurrSamplesPerSec=4.742853883774719, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      520/  500000 | consumed samples:        16640 | consumed tokens:     68157440 | elapsed time per iteration (ms): 6759.7 | learning rate: 3.120E-05 | global batch size:    32 | lm loss: 3.871568E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      521/  500000 | consumed samples:        16672 | consumed tokens:     68288512 | elapsed time per iteration (ms): 6764.6 | learning rate: 3.126E-05 | global batch size:    32 | lm loss: 3.822942E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.54 |
time (ms)
 iteration      522/  500000 | consumed samples:        16704 | consumed tokens:     68419584 | elapsed time per iteration (ms): 6761.6 | learning rate: 3.132E-05 | global batch size:    32 | lm loss: 3.886604E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      523/  500000 | consumed samples:        16736 | consumed tokens:     68550656 | elapsed time per iteration (ms): 6761.3 | learning rate: 3.138E-05 | global batch size:    32 | lm loss: 3.775949E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      524/  500000 | consumed samples:        16768 | consumed tokens:     68681728 | elapsed time per iteration (ms): 6757.8 | learning rate: 3.144E-05 | global batch size:    32 | lm loss: 3.671257E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      525/  500000 | consumed samples:        16800 | consumed tokens:     68812800 | elapsed time per iteration (ms): 6761.6 | learning rate: 3.150E-05 | global batch size:    32 | lm loss: 3.887390E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration      526/  500000 | consumed samples:        16832 | consumed tokens:     68943872 | elapsed time per iteration (ms): 6759.7 | learning rate: 3.156E-05 | global batch size:    32 | lm loss: 3.924811E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      527/  500000 | consumed samples:        16864 | consumed tokens:     69074944 | elapsed time per iteration (ms): 6759.0 | learning rate: 3.162E-05 | global batch size:    32 | lm loss: 3.822567E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      528/  500000 | consumed samples:        16896 | consumed tokens:     69206016 | elapsed time per iteration (ms): 6761.9 | learning rate: 3.168E-05 | global batch size:    32 | lm loss: 3.692486E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      529/  500000 | consumed samples:        16928 | consumed tokens:     69337088 | elapsed time per iteration (ms): 6763.6 | learning rate: 3.174E-05 | global batch size:    32 | lm loss: 3.857557E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
[2023-10-10 16:09:38,546] [INFO] [logging.py:96:log_dist] [Rank 0] step=530, skipped=0, lr=[3.1799999999999994e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:09:38,798] [INFO] [timer.py:208:stop] epoch=0/micro_step=530/global_step=530, RunningAvgSamplesPerSec=4.7427345250473, CurrSamplesPerSec=4.739506962870974, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      530/  500000 | consumed samples:        16960 | consumed tokens:     69468160 | elapsed time per iteration (ms): 6765.6 | learning rate: 3.180E-05 | global batch size:    32 | lm loss: 3.738023E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration      531/  500000 | consumed samples:        16992 | consumed tokens:     69599232 | elapsed time per iteration (ms): 6762.4 | learning rate: 3.186E-05 | global batch size:    32 | lm loss: 3.717690E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      532/  500000 | consumed samples:        17024 | consumed tokens:     69730304 | elapsed time per iteration (ms): 6760.9 | learning rate: 3.192E-05 | global batch size:    32 | lm loss: 3.761456E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      533/  500000 | consumed samples:        17056 | consumed tokens:     69861376 | elapsed time per iteration (ms): 6765.2 | learning rate: 3.198E-05 | global batch size:    32 | lm loss: 3.777573E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration      534/  500000 | consumed samples:        17088 | consumed tokens:     69992448 | elapsed time per iteration (ms): 6757.6 | learning rate: 3.204E-05 | global batch size:    32 | lm loss: 3.478927E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      535/  500000 | consumed samples:        17120 | consumed tokens:     70123520 | elapsed time per iteration (ms): 6759.4 | learning rate: 3.210E-05 | global batch size:    32 | lm loss: 3.641150E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      536/  500000 | consumed samples:        17152 | consumed tokens:     70254592 | elapsed time per iteration (ms): 6762.1 | learning rate: 3.216E-05 | global batch size:    32 | lm loss: 3.462649E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      537/  500000 | consumed samples:        17184 | consumed tokens:     70385664 | elapsed time per iteration (ms): 6761.9 | learning rate: 3.222E-05 | global batch size:    32 | lm loss: 3.637552E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      538/  500000 | consumed samples:        17216 | consumed tokens:     70516736 | elapsed time per iteration (ms): 6762.5 | learning rate: 3.228E-05 | global batch size:    32 | lm loss: 3.453878E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      539/  500000 | consumed samples:        17248 | consumed tokens:     70647808 | elapsed time per iteration (ms): 6761.8 | learning rate: 3.234E-05 | global batch size:    32 | lm loss: 3.558197E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
[2023-10-10 16:10:46,211] [INFO] [logging.py:96:log_dist] [Rank 0] step=540, skipped=0, lr=[3.2399999999999995e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:10:46,453] [INFO] [timer.py:208:stop] epoch=0/micro_step=540/global_step=540, RunningAvgSamplesPerSec=4.742723478126711, CurrSamplesPerSec=4.744423961436251, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      540/  500000 | consumed samples:        17280 | consumed tokens:     70778880 | elapsed time per iteration (ms): 6758.1 | learning rate: 3.240E-05 | global batch size:    32 | lm loss: 3.483788E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      541/  500000 | consumed samples:        17312 | consumed tokens:     70909952 | elapsed time per iteration (ms): 6759.4 | learning rate: 3.246E-05 | global batch size:    32 | lm loss: 3.462828E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      542/  500000 | consumed samples:        17344 | consumed tokens:     71041024 | elapsed time per iteration (ms): 6762.1 | learning rate: 3.252E-05 | global batch size:    32 | lm loss: 3.468842E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      543/  500000 | consumed samples:        17376 | consumed tokens:     71172096 | elapsed time per iteration (ms): 6756.4 | learning rate: 3.258E-05 | global batch size:    32 | lm loss: 3.414262E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      544/  500000 | consumed samples:        17408 | consumed tokens:     71303168 | elapsed time per iteration (ms): 6759.7 | learning rate: 3.264E-05 | global batch size:    32 | lm loss: 3.555699E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      545/  500000 | consumed samples:        17440 | consumed tokens:     71434240 | elapsed time per iteration (ms): 6758.4 | learning rate: 3.270E-05 | global batch size:    32 | lm loss: 3.304432E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      546/  500000 | consumed samples:        17472 | consumed tokens:     71565312 | elapsed time per iteration (ms): 6758.9 | learning rate: 3.276E-05 | global batch size:    32 | lm loss: 3.369091E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.66 |
time (ms)
 iteration      547/  500000 | consumed samples:        17504 | consumed tokens:     71696384 | elapsed time per iteration (ms): 6757.6 | learning rate: 3.282E-05 | global batch size:    32 | lm loss: 3.454943E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      548/  500000 | consumed samples:        17536 | consumed tokens:     71827456 | elapsed time per iteration (ms): 6757.6 | learning rate: 3.288E-05 | global batch size:    32 | lm loss: 3.350558E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      549/  500000 | consumed samples:        17568 | consumed tokens:     71958528 | elapsed time per iteration (ms): 6757.5 | learning rate: 3.294E-05 | global batch size:    32 | lm loss: 3.503324E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
[2023-10-10 16:11:53,845] [INFO] [logging.py:96:log_dist] [Rank 0] step=550, skipped=0, lr=[3.2999999999999996e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:11:54,079] [INFO] [timer.py:208:stop] epoch=0/micro_step=550/global_step=550, RunningAvgSamplesPerSec=4.742743721341134, CurrSamplesPerSec=4.745212829332431, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      550/  500000 | consumed samples:        17600 | consumed tokens:     72089600 | elapsed time per iteration (ms): 6755.7 | learning rate: 3.300E-05 | global batch size:    32 | lm loss: 3.339377E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration      551/  500000 | consumed samples:        17632 | consumed tokens:     72220672 | elapsed time per iteration (ms): 6756.4 | learning rate: 3.306E-05 | global batch size:    32 | lm loss: 3.587093E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      552/  500000 | consumed samples:        17664 | consumed tokens:     72351744 | elapsed time per iteration (ms): 6758.3 | learning rate: 3.312E-05 | global batch size:    32 | lm loss: 3.387657E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      553/  500000 | consumed samples:        17696 | consumed tokens:     72482816 | elapsed time per iteration (ms): 6755.4 | learning rate: 3.318E-05 | global batch size:    32 | lm loss: 3.341057E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration      554/  500000 | consumed samples:        17728 | consumed tokens:     72613888 | elapsed time per iteration (ms): 6759.8 | learning rate: 3.324E-05 | global batch size:    32 | lm loss: 3.176793E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      555/  500000 | consumed samples:        17760 | consumed tokens:     72744960 | elapsed time per iteration (ms): 6758.0 | learning rate: 3.330E-05 | global batch size:    32 | lm loss: 3.339787E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      556/  500000 | consumed samples:        17792 | consumed tokens:     72876032 | elapsed time per iteration (ms): 6756.8 | learning rate: 3.336E-05 | global batch size:    32 | lm loss: 3.357768E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      557/  500000 | consumed samples:        17824 | consumed tokens:     73007104 | elapsed time per iteration (ms): 6760.4 | learning rate: 3.342E-05 | global batch size:    32 | lm loss: 3.356741E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      558/  500000 | consumed samples:        17856 | consumed tokens:     73138176 | elapsed time per iteration (ms): 6768.1 | learning rate: 3.348E-05 | global batch size:    32 | lm loss: 3.244214E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.728 | TFLOPs: 147.46 |
time (ms)
 iteration      559/  500000 | consumed samples:        17888 | consumed tokens:     73269248 | elapsed time per iteration (ms): 6761.2 | learning rate: 3.354E-05 | global batch size:    32 | lm loss: 3.146399E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
[2023-10-10 16:13:01,463] [INFO] [logging.py:96:log_dist] [Rank 0] step=560, skipped=0, lr=[3.36e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:13:01,722] [INFO] [timer.py:208:stop] epoch=0/micro_step=560/global_step=560, RunningAvgSamplesPerSec=4.742752558951099, CurrSamplesPerSec=4.740039902897816, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      560/  500000 | consumed samples:        17920 | consumed tokens:     73400320 | elapsed time per iteration (ms): 6764.1 | learning rate: 3.360E-05 | global batch size:    32 | lm loss: 3.129714E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration      561/  500000 | consumed samples:        17952 | consumed tokens:     73531392 | elapsed time per iteration (ms): 6762.7 | learning rate: 3.366E-05 | global batch size:    32 | lm loss: 3.191800E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration      562/  500000 | consumed samples:        17984 | consumed tokens:     73662464 | elapsed time per iteration (ms): 6760.3 | learning rate: 3.372E-05 | global batch size:    32 | lm loss: 3.258920E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      563/  500000 | consumed samples:        18016 | consumed tokens:     73793536 | elapsed time per iteration (ms): 6755.3 | learning rate: 3.378E-05 | global batch size:    32 | lm loss: 3.065751E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration      564/  500000 | consumed samples:        18048 | consumed tokens:     73924608 | elapsed time per iteration (ms): 6756.4 | learning rate: 3.384E-05 | global batch size:    32 | lm loss: 3.049888E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      565/  500000 | consumed samples:        18080 | consumed tokens:     74055680 | elapsed time per iteration (ms): 6757.5 | learning rate: 3.390E-05 | global batch size:    32 | lm loss: 3.185379E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      566/  500000 | consumed samples:        18112 | consumed tokens:     74186752 | elapsed time per iteration (ms): 6760.4 | learning rate: 3.396E-05 | global batch size:    32 | lm loss: 3.105824E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      567/  500000 | consumed samples:        18144 | consumed tokens:     74317824 | elapsed time per iteration (ms): 6757.4 | learning rate: 3.402E-05 | global batch size:    32 | lm loss: 3.144417E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      568/  500000 | consumed samples:        18176 | consumed tokens:     74448896 | elapsed time per iteration (ms): 6757.5 | learning rate: 3.408E-05 | global batch size:    32 | lm loss: 3.142483E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      569/  500000 | consumed samples:        18208 | consumed tokens:     74579968 | elapsed time per iteration (ms): 6757.4 | learning rate: 3.414E-05 | global batch size:    32 | lm loss: 3.067041E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
[2023-10-10 16:14:09,104] [INFO] [logging.py:96:log_dist] [Rank 0] step=570, skipped=0, lr=[3.42e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:14:09,345] [INFO] [timer.py:208:stop] epoch=0/micro_step=570/global_step=570, RunningAvgSamplesPerSec=4.74277356040434, CurrSamplesPerSec=4.745745710988882, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      570/  500000 | consumed samples:        18240 | consumed tokens:     74711040 | elapsed time per iteration (ms): 6757.1 | learning rate: 3.420E-05 | global batch size:    32 | lm loss: 2.996931E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      571/  500000 | consumed samples:        18272 | consumed tokens:     74842112 | elapsed time per iteration (ms): 6759.2 | learning rate: 3.426E-05 | global batch size:    32 | lm loss: 3.029177E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      572/  500000 | consumed samples:        18304 | consumed tokens:     74973184 | elapsed time per iteration (ms): 6756.8 | learning rate: 3.432E-05 | global batch size:    32 | lm loss: 2.928761E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      573/  500000 | consumed samples:        18336 | consumed tokens:     75104256 | elapsed time per iteration (ms): 6759.5 | learning rate: 3.438E-05 | global batch size:    32 | lm loss: 2.875087E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      574/  500000 | consumed samples:        18368 | consumed tokens:     75235328 | elapsed time per iteration (ms): 6760.5 | learning rate: 3.444E-05 | global batch size:    32 | lm loss: 2.968306E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      575/  500000 | consumed samples:        18400 | consumed tokens:     75366400 | elapsed time per iteration (ms): 6763.0 | learning rate: 3.450E-05 | global batch size:    32 | lm loss: 2.921184E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration      576/  500000 | consumed samples:        18432 | consumed tokens:     75497472 | elapsed time per iteration (ms): 6760.2 | learning rate: 3.456E-05 | global batch size:    32 | lm loss: 3.009184E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      577/  500000 | consumed samples:        18464 | consumed tokens:     75628544 | elapsed time per iteration (ms): 6759.8 | learning rate: 3.462E-05 | global batch size:    32 | lm loss: 2.954588E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      578/  500000 | consumed samples:        18496 | consumed tokens:     75759616 | elapsed time per iteration (ms): 6757.6 | learning rate: 3.468E-05 | global batch size:    32 | lm loss: 2.947391E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      579/  500000 | consumed samples:        18528 | consumed tokens:     75890688 | elapsed time per iteration (ms): 6756.4 | learning rate: 3.474E-05 | global batch size:    32 | lm loss: 2.985561E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
[2023-10-10 16:15:16,721] [INFO] [logging.py:96:log_dist] [Rank 0] step=580, skipped=0, lr=[3.48e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:15:16,977] [INFO] [timer.py:208:stop] epoch=0/micro_step=580/global_step=580, RunningAvgSamplesPerSec=4.742786091231625, CurrSamplesPerSec=4.745784305932677, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      580/  500000 | consumed samples:        18560 | consumed tokens:     76021760 | elapsed time per iteration (ms): 6755.9 | learning rate: 3.480E-05 | global batch size:    32 | lm loss: 2.956765E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration      581/  500000 | consumed samples:        18592 | consumed tokens:     76152832 | elapsed time per iteration (ms): 6756.3 | learning rate: 3.486E-05 | global batch size:    32 | lm loss: 2.838980E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      582/  500000 | consumed samples:        18624 | consumed tokens:     76283904 | elapsed time per iteration (ms): 6761.6 | learning rate: 3.492E-05 | global batch size:    32 | lm loss: 2.847311E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration      583/  500000 | consumed samples:        18656 | consumed tokens:     76414976 | elapsed time per iteration (ms): 6759.3 | learning rate: 3.498E-05 | global batch size:    32 | lm loss: 2.804090E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      584/  500000 | consumed samples:        18688 | consumed tokens:     76546048 | elapsed time per iteration (ms): 6761.9 | learning rate: 3.504E-05 | global batch size:    32 | lm loss: 2.878889E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      585/  500000 | consumed samples:        18720 | consumed tokens:     76677120 | elapsed time per iteration (ms): 6760.3 | learning rate: 3.510E-05 | global batch size:    32 | lm loss: 2.761328E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration      586/  500000 | consumed samples:        18752 | consumed tokens:     76808192 | elapsed time per iteration (ms): 6757.8 | learning rate: 3.516E-05 | global batch size:    32 | lm loss: 2.687518E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      587/  500000 | consumed samples:        18784 | consumed tokens:     76939264 | elapsed time per iteration (ms): 6759.8 | learning rate: 3.522E-05 | global batch size:    32 | lm loss: 2.807904E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      588/  500000 | consumed samples:        18816 | consumed tokens:     77070336 | elapsed time per iteration (ms): 6760.0 | learning rate: 3.528E-05 | global batch size:    32 | lm loss: 2.754689E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      589/  500000 | consumed samples:        18848 | consumed tokens:     77201408 | elapsed time per iteration (ms): 6755.5 | learning rate: 3.534E-05 | global batch size:    32 | lm loss: 2.774432E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
[2023-10-10 16:16:24,360] [INFO] [logging.py:96:log_dist] [Rank 0] step=590, skipped=0, lr=[3.54e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:16:24,607] [INFO] [timer.py:208:stop] epoch=0/micro_step=590/global_step=590, RunningAvgSamplesPerSec=4.742803077236549, CurrSamplesPerSec=4.745351575091298, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      590/  500000 | consumed samples:        18880 | consumed tokens:     77332480 | elapsed time per iteration (ms): 6756.0 | learning rate: 3.540E-05 | global batch size:    32 | lm loss: 2.761113E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration      591/  500000 | consumed samples:        18912 | consumed tokens:     77463552 | elapsed time per iteration (ms): 6755.0 | learning rate: 3.546E-05 | global batch size:    32 | lm loss: 2.696482E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.75 |
time (ms)
 iteration      592/  500000 | consumed samples:        18944 | consumed tokens:     77594624 | elapsed time per iteration (ms): 6762.5 | learning rate: 3.552E-05 | global batch size:    32 | lm loss: 2.858807E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      593/  500000 | consumed samples:        18976 | consumed tokens:     77725696 | elapsed time per iteration (ms): 6764.7 | learning rate: 3.558E-05 | global batch size:    32 | lm loss: 2.728281E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration      594/  500000 | consumed samples:        19008 | consumed tokens:     77856768 | elapsed time per iteration (ms): 6761.2 | learning rate: 3.564E-05 | global batch size:    32 | lm loss: 2.653652E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      595/  500000 | consumed samples:        19040 | consumed tokens:     77987840 | elapsed time per iteration (ms): 6756.9 | learning rate: 3.570E-05 | global batch size:    32 | lm loss: 2.761894E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      596/  500000 | consumed samples:        19072 | consumed tokens:     78118912 | elapsed time per iteration (ms): 6760.1 | learning rate: 3.576E-05 | global batch size:    32 | lm loss: 2.600939E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      597/  500000 | consumed samples:        19104 | consumed tokens:     78249984 | elapsed time per iteration (ms): 6757.8 | learning rate: 3.582E-05 | global batch size:    32 | lm loss: 2.737401E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      598/  500000 | consumed samples:        19136 | consumed tokens:     78381056 | elapsed time per iteration (ms): 6758.5 | learning rate: 3.588E-05 | global batch size:    32 | lm loss: 2.648672E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      599/  500000 | consumed samples:        19168 | consumed tokens:     78512128 | elapsed time per iteration (ms): 6758.4 | learning rate: 3.594E-05 | global batch size:    32 | lm loss: 2.665472E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
[2023-10-10 16:17:32,002] [INFO] [logging.py:96:log_dist] [Rank 0] step=600, skipped=0, lr=[3.6e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:17:32,242] [INFO] [timer.py:208:stop] epoch=0/micro_step=600/global_step=600, RunningAvgSamplesPerSec=4.742813115978949, CurrSamplesPerSec=4.744317971538205, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      600/  500000 | consumed samples:        19200 | consumed tokens:     78643200 | elapsed time per iteration (ms): 6758.5 | learning rate: 3.600E-05 | global batch size:    32 | lm loss: 2.638091E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      601/  500000 | consumed samples:        19232 | consumed tokens:     78774272 | elapsed time per iteration (ms): 6766.1 | learning rate: 3.606E-05 | global batch size:    32 | lm loss: 2.615812E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.51 |
time (ms)
 iteration      602/  500000 | consumed samples:        19264 | consumed tokens:     78905344 | elapsed time per iteration (ms): 6761.2 | learning rate: 3.612E-05 | global batch size:    32 | lm loss: 2.721825E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      603/  500000 | consumed samples:        19296 | consumed tokens:     79036416 | elapsed time per iteration (ms): 6757.8 | learning rate: 3.618E-05 | global batch size:    32 | lm loss: 2.640899E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      604/  500000 | consumed samples:        19328 | consumed tokens:     79167488 | elapsed time per iteration (ms): 6760.2 | learning rate: 3.624E-05 | global batch size:    32 | lm loss: 2.595353E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      605/  500000 | consumed samples:        19360 | consumed tokens:     79298560 | elapsed time per iteration (ms): 6759.2 | learning rate: 3.630E-05 | global batch size:    32 | lm loss: 2.447487E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      606/  500000 | consumed samples:        19392 | consumed tokens:     79429632 | elapsed time per iteration (ms): 6762.3 | learning rate: 3.636E-05 | global batch size:    32 | lm loss: 2.509775E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      607/  500000 | consumed samples:        19424 | consumed tokens:     79560704 | elapsed time per iteration (ms): 6758.0 | learning rate: 3.642E-05 | global batch size:    32 | lm loss: 2.587623E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      608/  500000 | consumed samples:        19456 | consumed tokens:     79691776 | elapsed time per iteration (ms): 6758.2 | learning rate: 3.648E-05 | global batch size:    32 | lm loss: 2.609593E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      609/  500000 | consumed samples:        19488 | consumed tokens:     79822848 | elapsed time per iteration (ms): 6760.8 | learning rate: 3.654E-05 | global batch size:    32 | lm loss: 2.566206E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
[2023-10-10 16:18:39,633] [INFO] [logging.py:96:log_dist] [Rank 0] step=610, skipped=0, lr=[3.66e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:18:39,886] [INFO] [timer.py:208:stop] epoch=0/micro_step=610/global_step=610, RunningAvgSamplesPerSec=4.742808859249798, CurrSamplesPerSec=4.743868908658054, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      610/  500000 | consumed samples:        19520 | consumed tokens:     79953920 | elapsed time per iteration (ms): 6757.6 | learning rate: 3.660E-05 | global batch size:    32 | lm loss: 2.550925E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      611/  500000 | consumed samples:        19552 | consumed tokens:     80084992 | elapsed time per iteration (ms): 6758.7 | learning rate: 3.666E-05 | global batch size:    32 | lm loss: 2.536261E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      612/  500000 | consumed samples:        19584 | consumed tokens:     80216064 | elapsed time per iteration (ms): 6756.4 | learning rate: 3.672E-05 | global batch size:    32 | lm loss: 2.686969E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      613/  500000 | consumed samples:        19616 | consumed tokens:     80347136 | elapsed time per iteration (ms): 6758.7 | learning rate: 3.678E-05 | global batch size:    32 | lm loss: 2.491662E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      614/  500000 | consumed samples:        19648 | consumed tokens:     80478208 | elapsed time per iteration (ms): 6757.5 | learning rate: 3.684E-05 | global batch size:    32 | lm loss: 2.532984E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      615/  500000 | consumed samples:        19680 | consumed tokens:     80609280 | elapsed time per iteration (ms): 6759.8 | learning rate: 3.690E-05 | global batch size:    32 | lm loss: 2.410339E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      616/  500000 | consumed samples:        19712 | consumed tokens:     80740352 | elapsed time per iteration (ms): 6757.4 | learning rate: 3.696E-05 | global batch size:    32 | lm loss: 2.473317E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      617/  500000 | consumed samples:        19744 | consumed tokens:     80871424 | elapsed time per iteration (ms): 6760.7 | learning rate: 3.702E-05 | global batch size:    32 | lm loss: 2.438505E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      618/  500000 | consumed samples:        19776 | consumed tokens:     81002496 | elapsed time per iteration (ms): 6757.3 | learning rate: 3.708E-05 | global batch size:    32 | lm loss: 2.599260E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      619/  500000 | consumed samples:        19808 | consumed tokens:     81133568 | elapsed time per iteration (ms): 6760.0 | learning rate: 3.714E-05 | global batch size:    32 | lm loss: 2.515889E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
[2023-10-10 16:19:47,254] [INFO] [logging.py:96:log_dist] [Rank 0] step=620, skipped=0, lr=[3.7199999999999996e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:19:47,513] [INFO] [timer.py:208:stop] epoch=0/micro_step=620/global_step=620, RunningAvgSamplesPerSec=4.742827786856258, CurrSamplesPerSec=4.743876453821988, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      620/  500000 | consumed samples:        19840 | consumed tokens:     81264640 | elapsed time per iteration (ms): 6759.0 | learning rate: 3.720E-05 | global batch size:    32 | lm loss: 2.564280E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      621/  500000 | consumed samples:        19872 | consumed tokens:     81395712 | elapsed time per iteration (ms): 6759.3 | learning rate: 3.726E-05 | global batch size:    32 | lm loss: 2.427007E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      622/  500000 | consumed samples:        19904 | consumed tokens:     81526784 | elapsed time per iteration (ms): 6762.3 | learning rate: 3.732E-05 | global batch size:    32 | lm loss: 2.335762E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      623/  500000 | consumed samples:        19936 | consumed tokens:     81657856 | elapsed time per iteration (ms): 6759.5 | learning rate: 3.738E-05 | global batch size:    32 | lm loss: 2.324213E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      624/  500000 | consumed samples:        19968 | consumed tokens:     81788928 | elapsed time per iteration (ms): 6762.4 | learning rate: 3.744E-05 | global batch size:    32 | lm loss: 2.430859E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      625/  500000 | consumed samples:        20000 | consumed tokens:     81920000 | elapsed time per iteration (ms): 6762.4 | learning rate: 3.750E-05 | global batch size:    32 | lm loss: 2.450970E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      626/  500000 | consumed samples:        20032 | consumed tokens:     82051072 | elapsed time per iteration (ms): 6756.8 | learning rate: 3.756E-05 | global batch size:    32 | lm loss: 2.382673E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      627/  500000 | consumed samples:        20064 | consumed tokens:     82182144 | elapsed time per iteration (ms): 6758.9 | learning rate: 3.762E-05 | global batch size:    32 | lm loss: 2.272003E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      628/  500000 | consumed samples:        20096 | consumed tokens:     82313216 | elapsed time per iteration (ms): 6757.2 | learning rate: 3.768E-05 | global batch size:    32 | lm loss: 2.445019E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      629/  500000 | consumed samples:        20128 | consumed tokens:     82444288 | elapsed time per iteration (ms): 6756.0 | learning rate: 3.774E-05 | global batch size:    32 | lm loss: 2.460094E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
[2023-10-10 16:20:54,894] [INFO] [logging.py:96:log_dist] [Rank 0] step=630, skipped=0, lr=[3.78e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:20:55,149] [INFO] [timer.py:208:stop] epoch=0/micro_step=630/global_step=630, RunningAvgSamplesPerSec=4.74283734524288, CurrSamplesPerSec=4.744241668451708, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      630/  500000 | consumed samples:        20160 | consumed tokens:     82575360 | elapsed time per iteration (ms): 6758.3 | learning rate: 3.780E-05 | global batch size:    32 | lm loss: 2.330954E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      631/  500000 | consumed samples:        20192 | consumed tokens:     82706432 | elapsed time per iteration (ms): 6759.5 | learning rate: 3.786E-05 | global batch size:    32 | lm loss: 2.438180E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      632/  500000 | consumed samples:        20224 | consumed tokens:     82837504 | elapsed time per iteration (ms): 6759.5 | learning rate: 3.792E-05 | global batch size:    32 | lm loss: 2.293774E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      633/  500000 | consumed samples:        20256 | consumed tokens:     82968576 | elapsed time per iteration (ms): 6759.5 | learning rate: 3.798E-05 | global batch size:    32 | lm loss: 2.348439E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      634/  500000 | consumed samples:        20288 | consumed tokens:     83099648 | elapsed time per iteration (ms): 6756.6 | learning rate: 3.804E-05 | global batch size:    32 | lm loss: 2.286256E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      635/  500000 | consumed samples:        20320 | consumed tokens:     83230720 | elapsed time per iteration (ms): 6764.1 | learning rate: 3.810E-05 | global batch size:    32 | lm loss: 2.199033E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration      636/  500000 | consumed samples:        20352 | consumed tokens:     83361792 | elapsed time per iteration (ms): 6760.3 | learning rate: 3.816E-05 | global batch size:    32 | lm loss: 2.254526E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration      637/  500000 | consumed samples:        20384 | consumed tokens:     83492864 | elapsed time per iteration (ms): 6756.7 | learning rate: 3.822E-05 | global batch size:    32 | lm loss: 2.295247E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      638/  500000 | consumed samples:        20416 | consumed tokens:     83623936 | elapsed time per iteration (ms): 6760.6 | learning rate: 3.828E-05 | global batch size:    32 | lm loss: 2.173190E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      639/  500000 | consumed samples:        20448 | consumed tokens:     83755008 | elapsed time per iteration (ms): 6762.2 | learning rate: 3.834E-05 | global batch size:    32 | lm loss: 2.138844E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
[2023-10-10 16:22:02,529] [INFO] [logging.py:96:log_dist] [Rank 0] step=640, skipped=0, lr=[3.84e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:22:02,791] [INFO] [timer.py:208:stop] epoch=0/micro_step=640/global_step=640, RunningAvgSamplesPerSec=4.742835173783831, CurrSamplesPerSec=4.742807124310189, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      640/  500000 | consumed samples:        20480 | consumed tokens:     83886080 | elapsed time per iteration (ms): 6760.6 | learning rate: 3.840E-05 | global batch size:    32 | lm loss: 2.177059E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      641/  500000 | consumed samples:        20512 | consumed tokens:     84017152 | elapsed time per iteration (ms): 6764.5 | learning rate: 3.846E-05 | global batch size:    32 | lm loss: 2.301418E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.54 |
time (ms)
 iteration      642/  500000 | consumed samples:        20544 | consumed tokens:     84148224 | elapsed time per iteration (ms): 6758.5 | learning rate: 3.852E-05 | global batch size:    32 | lm loss: 2.095232E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      643/  500000 | consumed samples:        20576 | consumed tokens:     84279296 | elapsed time per iteration (ms): 6761.6 | learning rate: 3.858E-05 | global batch size:    32 | lm loss: 2.150029E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration      644/  500000 | consumed samples:        20608 | consumed tokens:     84410368 | elapsed time per iteration (ms): 6762.0 | learning rate: 3.864E-05 | global batch size:    32 | lm loss: 2.105649E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      645/  500000 | consumed samples:        20640 | consumed tokens:     84541440 | elapsed time per iteration (ms): 6757.8 | learning rate: 3.870E-05 | global batch size:    32 | lm loss: 2.265680E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      646/  500000 | consumed samples:        20672 | consumed tokens:     84672512 | elapsed time per iteration (ms): 6758.3 | learning rate: 3.876E-05 | global batch size:    32 | lm loss: 2.196924E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      647/  500000 | consumed samples:        20704 | consumed tokens:     84803584 | elapsed time per iteration (ms): 6756.7 | learning rate: 3.882E-05 | global batch size:    32 | lm loss: 2.260388E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      648/  500000 | consumed samples:        20736 | consumed tokens:     84934656 | elapsed time per iteration (ms): 6759.6 | learning rate: 3.888E-05 | global batch size:    32 | lm loss: 2.213480E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      649/  500000 | consumed samples:        20768 | consumed tokens:     85065728 | elapsed time per iteration (ms): 6762.1 | learning rate: 3.894E-05 | global batch size:    32 | lm loss: 2.225126E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
[2023-10-10 16:23:10,185] [INFO] [logging.py:96:log_dist] [Rank 0] step=650, skipped=0, lr=[3.899999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:23:10,432] [INFO] [timer.py:208:stop] epoch=0/micro_step=650/global_step=650, RunningAvgSamplesPerSec=4.742834417881144, CurrSamplesPerSec=4.7436878319237215, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      650/  500000 | consumed samples:        20800 | consumed tokens:     85196800 | elapsed time per iteration (ms): 6758.1 | learning rate: 3.900E-05 | global batch size:    32 | lm loss: 2.119398E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      651/  500000 | consumed samples:        20832 | consumed tokens:     85327872 | elapsed time per iteration (ms): 6762.6 | learning rate: 3.906E-05 | global batch size:    32 | lm loss: 2.063577E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration      652/  500000 | consumed samples:        20864 | consumed tokens:     85458944 | elapsed time per iteration (ms): 6761.4 | learning rate: 3.912E-05 | global batch size:    32 | lm loss: 2.139229E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      653/  500000 | consumed samples:        20896 | consumed tokens:     85590016 | elapsed time per iteration (ms): 6764.7 | learning rate: 3.918E-05 | global batch size:    32 | lm loss: 2.144316E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration      654/  500000 | consumed samples:        20928 | consumed tokens:     85721088 | elapsed time per iteration (ms): 6760.6 | learning rate: 3.924E-05 | global batch size:    32 | lm loss: 2.143553E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      655/  500000 | consumed samples:        20960 | consumed tokens:     85852160 | elapsed time per iteration (ms): 6761.4 | learning rate: 3.930E-05 | global batch size:    32 | lm loss: 2.176500E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      656/  500000 | consumed samples:        20992 | consumed tokens:     85983232 | elapsed time per iteration (ms): 6759.0 | learning rate: 3.936E-05 | global batch size:    32 | lm loss: 2.131208E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      657/  500000 | consumed samples:        21024 | consumed tokens:     86114304 | elapsed time per iteration (ms): 6760.9 | learning rate: 3.942E-05 | global batch size:    32 | lm loss: 2.056237E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      658/  500000 | consumed samples:        21056 | consumed tokens:     86245376 | elapsed time per iteration (ms): 6755.8 | learning rate: 3.948E-05 | global batch size:    32 | lm loss: 2.086527E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration      659/  500000 | consumed samples:        21088 | consumed tokens:     86376448 | elapsed time per iteration (ms): 6756.8 | learning rate: 3.954E-05 | global batch size:    32 | lm loss: 2.078478E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
[2023-10-10 16:24:17,817] [INFO] [logging.py:96:log_dist] [Rank 0] step=660, skipped=0, lr=[3.9599999999999994e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:24:18,074] [INFO] [timer.py:208:stop] epoch=0/micro_step=660/global_step=660, RunningAvgSamplesPerSec=4.742835253946963, CurrSamplesPerSec=4.743801506258464, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      660/  500000 | consumed samples:        21120 | consumed tokens:     86507520 | elapsed time per iteration (ms): 6757.8 | learning rate: 3.960E-05 | global batch size:    32 | lm loss: 2.037251E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      661/  500000 | consumed samples:        21152 | consumed tokens:     86638592 | elapsed time per iteration (ms): 6757.8 | learning rate: 3.966E-05 | global batch size:    32 | lm loss: 1.970849E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      662/  500000 | consumed samples:        21184 | consumed tokens:     86769664 | elapsed time per iteration (ms): 6761.4 | learning rate: 3.972E-05 | global batch size:    32 | lm loss: 2.099001E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      663/  500000 | consumed samples:        21216 | consumed tokens:     86900736 | elapsed time per iteration (ms): 6757.8 | learning rate: 3.978E-05 | global batch size:    32 | lm loss: 1.987831E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      664/  500000 | consumed samples:        21248 | consumed tokens:     87031808 | elapsed time per iteration (ms): 6762.4 | learning rate: 3.984E-05 | global batch size:    32 | lm loss: 2.070615E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      665/  500000 | consumed samples:        21280 | consumed tokens:     87162880 | elapsed time per iteration (ms): 6758.8 | learning rate: 3.990E-05 | global batch size:    32 | lm loss: 2.108800E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      666/  500000 | consumed samples:        21312 | consumed tokens:     87293952 | elapsed time per iteration (ms): 6757.3 | learning rate: 3.996E-05 | global batch size:    32 | lm loss: 2.054819E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      667/  500000 | consumed samples:        21344 | consumed tokens:     87425024 | elapsed time per iteration (ms): 6755.9 | learning rate: 4.002E-05 | global batch size:    32 | lm loss: 2.156273E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration      668/  500000 | consumed samples:        21376 | consumed tokens:     87556096 | elapsed time per iteration (ms): 6761.2 | learning rate: 4.008E-05 | global batch size:    32 | lm loss: 2.007383E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      669/  500000 | consumed samples:        21408 | consumed tokens:     87687168 | elapsed time per iteration (ms): 6760.2 | learning rate: 4.014E-05 | global batch size:    32 | lm loss: 1.964549E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
[2023-10-10 16:25:25,456] [INFO] [logging.py:96:log_dist] [Rank 0] step=670, skipped=0, lr=[4.0199999999999995e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:25:25,704] [INFO] [timer.py:208:stop] epoch=0/micro_step=670/global_step=670, RunningAvgSamplesPerSec=4.742846582973212, CurrSamplesPerSec=4.7465328363641355, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      670/  500000 | consumed samples:        21440 | consumed tokens:     87818240 | elapsed time per iteration (ms): 6756.2 | learning rate: 4.020E-05 | global batch size:    32 | lm loss: 1.947749E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      671/  500000 | consumed samples:        21472 | consumed tokens:     87949312 | elapsed time per iteration (ms): 6758.7 | learning rate: 4.026E-05 | global batch size:    32 | lm loss: 2.032362E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      672/  500000 | consumed samples:        21504 | consumed tokens:     88080384 | elapsed time per iteration (ms): 6757.4 | learning rate: 4.032E-05 | global batch size:    32 | lm loss: 1.976227E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      673/  500000 | consumed samples:        21536 | consumed tokens:     88211456 | elapsed time per iteration (ms): 6758.1 | learning rate: 4.038E-05 | global batch size:    32 | lm loss: 1.927061E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      674/  500000 | consumed samples:        21568 | consumed tokens:     88342528 | elapsed time per iteration (ms): 6757.9 | learning rate: 4.044E-05 | global batch size:    32 | lm loss: 2.006955E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      675/  500000 | consumed samples:        21600 | consumed tokens:     88473600 | elapsed time per iteration (ms): 6758.7 | learning rate: 4.050E-05 | global batch size:    32 | lm loss: 1.961238E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      676/  500000 | consumed samples:        21632 | consumed tokens:     88604672 | elapsed time per iteration (ms): 6760.2 | learning rate: 4.056E-05 | global batch size:    32 | lm loss: 1.911592E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      677/  500000 | consumed samples:        21664 | consumed tokens:     88735744 | elapsed time per iteration (ms): 6757.5 | learning rate: 4.062E-05 | global batch size:    32 | lm loss: 1.992281E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      678/  500000 | consumed samples:        21696 | consumed tokens:     88866816 | elapsed time per iteration (ms): 6757.4 | learning rate: 4.068E-05 | global batch size:    32 | lm loss: 1.928887E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      679/  500000 | consumed samples:        21728 | consumed tokens:     88997888 | elapsed time per iteration (ms): 6759.6 | learning rate: 4.074E-05 | global batch size:    32 | lm loss: 1.880152E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
[2023-10-10 16:26:33,072] [INFO] [logging.py:96:log_dist] [Rank 0] step=680, skipped=0, lr=[4.0799999999999996e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:26:33,332] [INFO] [timer.py:208:stop] epoch=0/micro_step=680/global_step=680, RunningAvgSamplesPerSec=4.742856729486785, CurrSamplesPerSec=4.741832927157013, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      680/  500000 | consumed samples:        21760 | consumed tokens:     89128960 | elapsed time per iteration (ms): 6760.9 | learning rate: 4.080E-05 | global batch size:    32 | lm loss: 1.895250E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      681/  500000 | consumed samples:        21792 | consumed tokens:     89260032 | elapsed time per iteration (ms): 6757.9 | learning rate: 4.086E-05 | global batch size:    32 | lm loss: 1.940794E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      682/  500000 | consumed samples:        21824 | consumed tokens:     89391104 | elapsed time per iteration (ms): 6759.5 | learning rate: 4.092E-05 | global batch size:    32 | lm loss: 1.849024E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      683/  500000 | consumed samples:        21856 | consumed tokens:     89522176 | elapsed time per iteration (ms): 6760.0 | learning rate: 4.098E-05 | global batch size:    32 | lm loss: 1.952943E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      684/  500000 | consumed samples:        21888 | consumed tokens:     89653248 | elapsed time per iteration (ms): 6756.7 | learning rate: 4.104E-05 | global batch size:    32 | lm loss: 1.866305E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      685/  500000 | consumed samples:        21920 | consumed tokens:     89784320 | elapsed time per iteration (ms): 6754.7 | learning rate: 4.110E-05 | global batch size:    32 | lm loss: 1.913604E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.75 |
time (ms)
 iteration      686/  500000 | consumed samples:        21952 | consumed tokens:     89915392 | elapsed time per iteration (ms): 6759.5 | learning rate: 4.116E-05 | global batch size:    32 | lm loss: 1.941299E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      687/  500000 | consumed samples:        21984 | consumed tokens:     90046464 | elapsed time per iteration (ms): 6759.4 | learning rate: 4.122E-05 | global batch size:    32 | lm loss: 1.868288E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      688/  500000 | consumed samples:        22016 | consumed tokens:     90177536 | elapsed time per iteration (ms): 6760.0 | learning rate: 4.128E-05 | global batch size:    32 | lm loss: 1.901521E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      689/  500000 | consumed samples:        22048 | consumed tokens:     90308608 | elapsed time per iteration (ms): 6757.7 | learning rate: 4.134E-05 | global batch size:    32 | lm loss: 1.750872E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
[2023-10-10 16:27:40,696] [INFO] [logging.py:96:log_dist] [Rank 0] step=690, skipped=0, lr=[4.14e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:27:40,959] [INFO] [timer.py:208:stop] epoch=0/micro_step=690/global_step=690, RunningAvgSamplesPerSec=4.742870101888871, CurrSamplesPerSec=4.743229166059264, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      690/  500000 | consumed samples:        22080 | consumed tokens:     90439680 | elapsed time per iteration (ms): 6759.7 | learning rate: 4.140E-05 | global batch size:    32 | lm loss: 1.872043E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      691/  500000 | consumed samples:        22112 | consumed tokens:     90570752 | elapsed time per iteration (ms): 6762.7 | learning rate: 4.146E-05 | global batch size:    32 | lm loss: 1.779712E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration      692/  500000 | consumed samples:        22144 | consumed tokens:     90701824 | elapsed time per iteration (ms): 6758.7 | learning rate: 4.152E-05 | global batch size:    32 | lm loss: 1.898174E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      693/  500000 | consumed samples:        22176 | consumed tokens:     90832896 | elapsed time per iteration (ms): 6760.9 | learning rate: 4.158E-05 | global batch size:    32 | lm loss: 1.846836E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      694/  500000 | consumed samples:        22208 | consumed tokens:     90963968 | elapsed time per iteration (ms): 6760.5 | learning rate: 4.164E-05 | global batch size:    32 | lm loss: 1.803371E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      695/  500000 | consumed samples:        22240 | consumed tokens:     91095040 | elapsed time per iteration (ms): 6759.6 | learning rate: 4.170E-05 | global batch size:    32 | lm loss: 1.879548E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      696/  500000 | consumed samples:        22272 | consumed tokens:     91226112 | elapsed time per iteration (ms): 6758.8 | learning rate: 4.176E-05 | global batch size:    32 | lm loss: 1.857556E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      697/  500000 | consumed samples:        22304 | consumed tokens:     91357184 | elapsed time per iteration (ms): 6765.7 | learning rate: 4.182E-05 | global batch size:    32 | lm loss: 1.874572E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.51 |
time (ms)
 iteration      698/  500000 | consumed samples:        22336 | consumed tokens:     91488256 | elapsed time per iteration (ms): 6762.0 | learning rate: 4.188E-05 | global batch size:    32 | lm loss: 1.881245E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      699/  500000 | consumed samples:        22368 | consumed tokens:     91619328 | elapsed time per iteration (ms): 6759.8 | learning rate: 4.194E-05 | global batch size:    32 | lm loss: 1.760467E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
[2023-10-10 16:28:48,353] [INFO] [logging.py:96:log_dist] [Rank 0] step=700, skipped=0, lr=[4.2e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:28:48,611] [INFO] [timer.py:208:stop] epoch=0/micro_step=700/global_step=700, RunningAvgSamplesPerSec=4.74285888027427, CurrSamplesPerSec=4.741207801979903, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      700/  500000 | consumed samples:        22400 | consumed tokens:     91750400 | elapsed time per iteration (ms): 6762.3 | learning rate: 4.200E-05 | global batch size:    32 | lm loss: 1.778479E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      701/  500000 | consumed samples:        22432 | consumed tokens:     91881472 | elapsed time per iteration (ms): 6762.7 | learning rate: 4.206E-05 | global batch size:    32 | lm loss: 1.736536E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration      702/  500000 | consumed samples:        22464 | consumed tokens:     92012544 | elapsed time per iteration (ms): 6763.5 | learning rate: 4.212E-05 | global batch size:    32 | lm loss: 1.844339E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration      703/  500000 | consumed samples:        22496 | consumed tokens:     92143616 | elapsed time per iteration (ms): 6759.0 | learning rate: 4.218E-05 | global batch size:    32 | lm loss: 1.788664E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      704/  500000 | consumed samples:        22528 | consumed tokens:     92274688 | elapsed time per iteration (ms): 6760.7 | learning rate: 4.224E-05 | global batch size:    32 | lm loss: 1.796986E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      705/  500000 | consumed samples:        22560 | consumed tokens:     92405760 | elapsed time per iteration (ms): 6758.3 | learning rate: 4.230E-05 | global batch size:    32 | lm loss: 1.811254E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      706/  500000 | consumed samples:        22592 | consumed tokens:     92536832 | elapsed time per iteration (ms): 6757.6 | learning rate: 4.236E-05 | global batch size:    32 | lm loss: 1.663260E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      707/  500000 | consumed samples:        22624 | consumed tokens:     92667904 | elapsed time per iteration (ms): 6756.2 | learning rate: 4.242E-05 | global batch size:    32 | lm loss: 1.792129E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      708/  500000 | consumed samples:        22656 | consumed tokens:     92798976 | elapsed time per iteration (ms): 6758.0 | learning rate: 4.248E-05 | global batch size:    32 | lm loss: 1.881075E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      709/  500000 | consumed samples:        22688 | consumed tokens:     92930048 | elapsed time per iteration (ms): 6760.7 | learning rate: 4.254E-05 | global batch size:    32 | lm loss: 1.757167E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
[2023-10-10 16:29:56,000] [INFO] [logging.py:96:log_dist] [Rank 0] step=710, skipped=0, lr=[4.26e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:29:56,250] [INFO] [timer.py:208:stop] epoch=0/micro_step=710/global_step=710, RunningAvgSamplesPerSec=4.742860906106518, CurrSamplesPerSec=4.7428109789982, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      710/  500000 | consumed samples:        22720 | consumed tokens:     93061120 | elapsed time per iteration (ms): 6760.2 | learning rate: 4.260E-05 | global batch size:    32 | lm loss: 1.767431E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      711/  500000 | consumed samples:        22752 | consumed tokens:     93192192 | elapsed time per iteration (ms): 6762.8 | learning rate: 4.266E-05 | global batch size:    32 | lm loss: 1.803457E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration      712/  500000 | consumed samples:        22784 | consumed tokens:     93323264 | elapsed time per iteration (ms): 6756.1 | learning rate: 4.272E-05 | global batch size:    32 | lm loss: 1.753961E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.73 |
time (ms)
 iteration      713/  500000 | consumed samples:        22816 | consumed tokens:     93454336 | elapsed time per iteration (ms): 6757.3 | learning rate: 4.278E-05 | global batch size:    32 | lm loss: 1.679564E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      714/  500000 | consumed samples:        22848 | consumed tokens:     93585408 | elapsed time per iteration (ms): 6759.2 | learning rate: 4.284E-05 | global batch size:    32 | lm loss: 1.751995E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      715/  500000 | consumed samples:        22880 | consumed tokens:     93716480 | elapsed time per iteration (ms): 6765.3 | learning rate: 4.290E-05 | global batch size:    32 | lm loss: 1.735357E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration      716/  500000 | consumed samples:        22912 | consumed tokens:     93847552 | elapsed time per iteration (ms): 6762.1 | learning rate: 4.296E-05 | global batch size:    32 | lm loss: 1.672484E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      717/  500000 | consumed samples:        22944 | consumed tokens:     93978624 | elapsed time per iteration (ms): 6757.9 | learning rate: 4.302E-05 | global batch size:    32 | lm loss: 1.753799E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      718/  500000 | consumed samples:        22976 | consumed tokens:     94109696 | elapsed time per iteration (ms): 6760.3 | learning rate: 4.308E-05 | global batch size:    32 | lm loss: 1.769392E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      719/  500000 | consumed samples:        23008 | consumed tokens:     94240768 | elapsed time per iteration (ms): 6758.8 | learning rate: 4.314E-05 | global batch size:    32 | lm loss: 1.690960E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
[2023-10-10 16:31:03,632] [INFO] [logging.py:96:log_dist] [Rank 0] step=720, skipped=0, lr=[4.319999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:31:03,889] [INFO] [timer.py:208:stop] epoch=0/micro_step=720/global_step=720, RunningAvgSamplesPerSec=4.742860901905536, CurrSamplesPerSec=4.744290636304201, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      720/  500000 | consumed samples:        23040 | consumed tokens:     94371840 | elapsed time per iteration (ms): 6757.2 | learning rate: 4.320E-05 | global batch size:    32 | lm loss: 1.751997E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      721/  500000 | consumed samples:        23072 | consumed tokens:     94502912 | elapsed time per iteration (ms): 6760.5 | learning rate: 4.326E-05 | global batch size:    32 | lm loss: 1.688910E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      722/  500000 | consumed samples:        23104 | consumed tokens:     94633984 | elapsed time per iteration (ms): 6763.8 | learning rate: 4.332E-05 | global batch size:    32 | lm loss: 1.688876E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration      723/  500000 | consumed samples:        23136 | consumed tokens:     94765056 | elapsed time per iteration (ms): 6761.2 | learning rate: 4.338E-05 | global batch size:    32 | lm loss: 1.694839E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      724/  500000 | consumed samples:        23168 | consumed tokens:     94896128 | elapsed time per iteration (ms): 6764.2 | learning rate: 4.344E-05 | global batch size:    32 | lm loss: 1.718156E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration      725/  500000 | consumed samples:        23200 | consumed tokens:     95027200 | elapsed time per iteration (ms): 6762.3 | learning rate: 4.350E-05 | global batch size:    32 | lm loss: 1.723429E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      726/  500000 | consumed samples:        23232 | consumed tokens:     95158272 | elapsed time per iteration (ms): 6758.2 | learning rate: 4.356E-05 | global batch size:    32 | lm loss: 1.681827E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      727/  500000 | consumed samples:        23264 | consumed tokens:     95289344 | elapsed time per iteration (ms): 6759.6 | learning rate: 4.362E-05 | global batch size:    32 | lm loss: 1.645598E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      728/  500000 | consumed samples:        23296 | consumed tokens:     95420416 | elapsed time per iteration (ms): 6755.3 | learning rate: 4.368E-05 | global batch size:    32 | lm loss: 1.715002E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration      729/  500000 | consumed samples:        23328 | consumed tokens:     95551488 | elapsed time per iteration (ms): 6760.4 | learning rate: 4.374E-05 | global batch size:    32 | lm loss: 1.621795E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
[2023-10-10 16:32:11,293] [INFO] [logging.py:96:log_dist] [Rank 0] step=730, skipped=0, lr=[4.3799999999999994e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:32:11,534] [INFO] [timer.py:208:stop] epoch=0/micro_step=730/global_step=730, RunningAvgSamplesPerSec=4.7428591757890155, CurrSamplesPerSec=4.746078654979136, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      730/  500000 | consumed samples:        23360 | consumed tokens:     95682560 | elapsed time per iteration (ms): 6757.0 | learning rate: 4.380E-05 | global batch size:    32 | lm loss: 1.667535E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      731/  500000 | consumed samples:        23392 | consumed tokens:     95813632 | elapsed time per iteration (ms): 6758.1 | learning rate: 4.386E-05 | global batch size:    32 | lm loss: 1.709815E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      732/  500000 | consumed samples:        23424 | consumed tokens:     95944704 | elapsed time per iteration (ms): 6759.1 | learning rate: 4.392E-05 | global batch size:    32 | lm loss: 1.619605E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      733/  500000 | consumed samples:        23456 | consumed tokens:     96075776 | elapsed time per iteration (ms): 6759.1 | learning rate: 4.398E-05 | global batch size:    32 | lm loss: 1.605510E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      734/  500000 | consumed samples:        23488 | consumed tokens:     96206848 | elapsed time per iteration (ms): 6756.9 | learning rate: 4.404E-05 | global batch size:    32 | lm loss: 1.652841E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      735/  500000 | consumed samples:        23520 | consumed tokens:     96337920 | elapsed time per iteration (ms): 6761.6 | learning rate: 4.410E-05 | global batch size:    32 | lm loss: 1.616393E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      736/  500000 | consumed samples:        23552 | consumed tokens:     96468992 | elapsed time per iteration (ms): 6756.1 | learning rate: 4.416E-05 | global batch size:    32 | lm loss: 1.756142E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.73 |
time (ms)
 iteration      737/  500000 | consumed samples:        23584 | consumed tokens:     96600064 | elapsed time per iteration (ms): 6758.8 | learning rate: 4.422E-05 | global batch size:    32 | lm loss: 1.615542E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      738/  500000 | consumed samples:        23616 | consumed tokens:     96731136 | elapsed time per iteration (ms): 6758.3 | learning rate: 4.428E-05 | global batch size:    32 | lm loss: 1.647348E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      739/  500000 | consumed samples:        23648 | consumed tokens:     96862208 | elapsed time per iteration (ms): 6756.7 | learning rate: 4.434E-05 | global batch size:    32 | lm loss: 1.626959E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
[2023-10-10 16:33:18,901] [INFO] [logging.py:96:log_dist] [Rank 0] step=740, skipped=0, lr=[4.4399999999999995e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:33:19,158] [INFO] [timer.py:208:stop] epoch=0/micro_step=740/global_step=740, RunningAvgSamplesPerSec=4.7428759155592015, CurrSamplesPerSec=4.744557797218155, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      740/  500000 | consumed samples:        23680 | consumed tokens:     96993280 | elapsed time per iteration (ms): 6757.3 | learning rate: 4.440E-05 | global batch size:    32 | lm loss: 1.643623E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      741/  500000 | consumed samples:        23712 | consumed tokens:     97124352 | elapsed time per iteration (ms): 6759.4 | learning rate: 4.446E-05 | global batch size:    32 | lm loss: 1.596374E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      742/  500000 | consumed samples:        23744 | consumed tokens:     97255424 | elapsed time per iteration (ms): 6757.2 | learning rate: 4.452E-05 | global batch size:    32 | lm loss: 1.635959E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      743/  500000 | consumed samples:        23776 | consumed tokens:     97386496 | elapsed time per iteration (ms): 6758.8 | learning rate: 4.458E-05 | global batch size:    32 | lm loss: 1.654706E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      744/  500000 | consumed samples:        23808 | consumed tokens:     97517568 | elapsed time per iteration (ms): 6766.6 | learning rate: 4.464E-05 | global batch size:    32 | lm loss: 1.630745E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.50 |
time (ms)
 iteration      745/  500000 | consumed samples:        23840 | consumed tokens:     97648640 | elapsed time per iteration (ms): 6761.5 | learning rate: 4.470E-05 | global batch size:    32 | lm loss: 1.634620E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      746/  500000 | consumed samples:        23872 | consumed tokens:     97779712 | elapsed time per iteration (ms): 6760.4 | learning rate: 4.476E-05 | global batch size:    32 | lm loss: 1.588643E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      747/  500000 | consumed samples:        23904 | consumed tokens:     97910784 | elapsed time per iteration (ms): 6762.7 | learning rate: 4.482E-05 | global batch size:    32 | lm loss: 1.636570E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration      748/  500000 | consumed samples:        23936 | consumed tokens:     98041856 | elapsed time per iteration (ms): 6758.8 | learning rate: 4.488E-05 | global batch size:    32 | lm loss: 1.535263E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      749/  500000 | consumed samples:        23968 | consumed tokens:     98172928 | elapsed time per iteration (ms): 6759.0 | learning rate: 4.494E-05 | global batch size:    32 | lm loss: 1.514729E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
[2023-10-10 16:34:26,544] [INFO] [logging.py:96:log_dist] [Rank 0] step=750, skipped=0, lr=[4.4999999999999996e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:34:26,806] [INFO] [timer.py:208:stop] epoch=0/micro_step=750/global_step=750, RunningAvgSamplesPerSec=4.742872279551925, CurrSamplesPerSec=4.743248442992271, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      750/  500000 | consumed samples:        24000 | consumed tokens:     98304000 | elapsed time per iteration (ms): 6758.7 | learning rate: 4.500E-05 | global batch size:    32 | lm loss: 1.663489E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      751/  500000 | consumed samples:        24032 | consumed tokens:     98435072 | elapsed time per iteration (ms): 6761.5 | learning rate: 4.506E-05 | global batch size:    32 | lm loss: 1.565977E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      752/  500000 | consumed samples:        24064 | consumed tokens:     98566144 | elapsed time per iteration (ms): 6761.1 | learning rate: 4.512E-05 | global batch size:    32 | lm loss: 1.599687E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      753/  500000 | consumed samples:        24096 | consumed tokens:     98697216 | elapsed time per iteration (ms): 6756.9 | learning rate: 4.518E-05 | global batch size:    32 | lm loss: 1.624165E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      754/  500000 | consumed samples:        24128 | consumed tokens:     98828288 | elapsed time per iteration (ms): 6755.8 | learning rate: 4.524E-05 | global batch size:    32 | lm loss: 1.658823E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration      755/  500000 | consumed samples:        24160 | consumed tokens:     98959360 | elapsed time per iteration (ms): 6757.5 | learning rate: 4.530E-05 | global batch size:    32 | lm loss: 1.572708E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      756/  500000 | consumed samples:        24192 | consumed tokens:     99090432 | elapsed time per iteration (ms): 6759.3 | learning rate: 4.536E-05 | global batch size:    32 | lm loss: 1.603185E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      757/  500000 | consumed samples:        24224 | consumed tokens:     99221504 | elapsed time per iteration (ms): 6758.2 | learning rate: 4.542E-05 | global batch size:    32 | lm loss: 1.596767E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      758/  500000 | consumed samples:        24256 | consumed tokens:     99352576 | elapsed time per iteration (ms): 6759.0 | learning rate: 4.548E-05 | global batch size:    32 | lm loss: 1.631191E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      759/  500000 | consumed samples:        24288 | consumed tokens:     99483648 | elapsed time per iteration (ms): 6757.3 | learning rate: 4.554E-05 | global batch size:    32 | lm loss: 1.585799E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
[2023-10-10 16:35:34,184] [INFO] [logging.py:96:log_dist] [Rank 0] step=760, skipped=0, lr=[4.56e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:35:34,434] [INFO] [timer.py:208:stop] epoch=0/micro_step=760/global_step=760, RunningAvgSamplesPerSec=4.742884087701227, CurrSamplesPerSec=4.74424938249838, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      760/  500000 | consumed samples:        24320 | consumed tokens:     99614720 | elapsed time per iteration (ms): 6758.0 | learning rate: 4.560E-05 | global batch size:    32 | lm loss: 1.573950E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      761/  500000 | consumed samples:        24352 | consumed tokens:     99745792 | elapsed time per iteration (ms): 6765.6 | learning rate: 4.566E-05 | global batch size:    32 | lm loss: 1.528083E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration      762/  500000 | consumed samples:        24384 | consumed tokens:     99876864 | elapsed time per iteration (ms): 6763.2 | learning rate: 4.572E-05 | global batch size:    32 | lm loss: 1.624320E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration      763/  500000 | consumed samples:        24416 | consumed tokens:    100007936 | elapsed time per iteration (ms): 6760.8 | learning rate: 4.578E-05 | global batch size:    32 | lm loss: 1.533747E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      764/  500000 | consumed samples:        24448 | consumed tokens:    100139008 | elapsed time per iteration (ms): 6756.4 | learning rate: 4.584E-05 | global batch size:    32 | lm loss: 1.610628E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      765/  500000 | consumed samples:        24480 | consumed tokens:    100270080 | elapsed time per iteration (ms): 6761.0 | learning rate: 4.590E-05 | global batch size:    32 | lm loss: 1.546714E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      766/  500000 | consumed samples:        24512 | consumed tokens:    100401152 | elapsed time per iteration (ms): 6754.9 | learning rate: 4.596E-05 | global batch size:    32 | lm loss: 1.539537E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.75 |
time (ms)
 iteration      767/  500000 | consumed samples:        24544 | consumed tokens:    100532224 | elapsed time per iteration (ms): 6756.4 | learning rate: 4.602E-05 | global batch size:    32 | lm loss: 1.561061E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      768/  500000 | consumed samples:        24576 | consumed tokens:    100663296 | elapsed time per iteration (ms): 6758.2 | learning rate: 4.608E-05 | global batch size:    32 | lm loss: 1.571831E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      769/  500000 | consumed samples:        24608 | consumed tokens:    100794368 | elapsed time per iteration (ms): 6762.0 | learning rate: 4.614E-05 | global batch size:    32 | lm loss: 1.500362E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
[2023-10-10 16:36:41,813] [INFO] [logging.py:96:log_dist] [Rank 0] step=770, skipped=0, lr=[4.62e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:36:42,072] [INFO] [timer.py:208:stop] epoch=0/micro_step=770/global_step=770, RunningAvgSamplesPerSec=4.742885144991693, CurrSamplesPerSec=4.744181130825925, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      770/  500000 | consumed samples:        24640 | consumed tokens:    100925440 | elapsed time per iteration (ms): 6757.8 | learning rate: 4.620E-05 | global batch size:    32 | lm loss: 1.521242E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      771/  500000 | consumed samples:        24672 | consumed tokens:    101056512 | elapsed time per iteration (ms): 6754.7 | learning rate: 4.626E-05 | global batch size:    32 | lm loss: 1.541482E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.76 |
time (ms)
 iteration      772/  500000 | consumed samples:        24704 | consumed tokens:    101187584 | elapsed time per iteration (ms): 6762.2 | learning rate: 4.632E-05 | global batch size:    32 | lm loss: 1.504460E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      773/  500000 | consumed samples:        24736 | consumed tokens:    101318656 | elapsed time per iteration (ms): 6758.3 | learning rate: 4.638E-05 | global batch size:    32 | lm loss: 1.522693E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      774/  500000 | consumed samples:        24768 | consumed tokens:    101449728 | elapsed time per iteration (ms): 6758.3 | learning rate: 4.644E-05 | global batch size:    32 | lm loss: 1.544448E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      775/  500000 | consumed samples:        24800 | consumed tokens:    101580800 | elapsed time per iteration (ms): 6757.7 | learning rate: 4.650E-05 | global batch size:    32 | lm loss: 1.563819E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      776/  500000 | consumed samples:        24832 | consumed tokens:    101711872 | elapsed time per iteration (ms): 6757.8 | learning rate: 4.656E-05 | global batch size:    32 | lm loss: 1.554157E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      777/  500000 | consumed samples:        24864 | consumed tokens:    101842944 | elapsed time per iteration (ms): 6760.1 | learning rate: 4.662E-05 | global batch size:    32 | lm loss: 1.552153E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      778/  500000 | consumed samples:        24896 | consumed tokens:    101974016 | elapsed time per iteration (ms): 6756.1 | learning rate: 4.668E-05 | global batch size:    32 | lm loss: 1.504925E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      779/  500000 | consumed samples:        24928 | consumed tokens:    102105088 | elapsed time per iteration (ms): 6758.4 | learning rate: 4.674E-05 | global batch size:    32 | lm loss: 1.525995E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
[2023-10-10 16:37:49,438] [INFO] [logging.py:96:log_dist] [Rank 0] step=780, skipped=0, lr=[4.68e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:37:49,695] [INFO] [timer.py:208:stop] epoch=0/micro_step=780/global_step=780, RunningAvgSamplesPerSec=4.742900771262743, CurrSamplesPerSec=4.744308747957778, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      780/  500000 | consumed samples:        24960 | consumed tokens:    102236160 | elapsed time per iteration (ms): 6757.3 | learning rate: 4.680E-05 | global batch size:    32 | lm loss: 1.492617E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      781/  500000 | consumed samples:        24992 | consumed tokens:    102367232 | elapsed time per iteration (ms): 6761.4 | learning rate: 4.686E-05 | global batch size:    32 | lm loss: 1.498341E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      782/  500000 | consumed samples:        25024 | consumed tokens:    102498304 | elapsed time per iteration (ms): 6759.5 | learning rate: 4.692E-05 | global batch size:    32 | lm loss: 1.528661E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      783/  500000 | consumed samples:        25056 | consumed tokens:    102629376 | elapsed time per iteration (ms): 6754.8 | learning rate: 4.698E-05 | global batch size:    32 | lm loss: 1.573078E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.75 |
time (ms)
 iteration      784/  500000 | consumed samples:        25088 | consumed tokens:    102760448 | elapsed time per iteration (ms): 6758.9 | learning rate: 4.704E-05 | global batch size:    32 | lm loss: 1.490990E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.66 |
time (ms)
 iteration      785/  500000 | consumed samples:        25120 | consumed tokens:    102891520 | elapsed time per iteration (ms): 6756.6 | learning rate: 4.710E-05 | global batch size:    32 | lm loss: 1.515593E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      786/  500000 | consumed samples:        25152 | consumed tokens:    103022592 | elapsed time per iteration (ms): 6757.9 | learning rate: 4.716E-05 | global batch size:    32 | lm loss: 1.514055E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      787/  500000 | consumed samples:        25184 | consumed tokens:    103153664 | elapsed time per iteration (ms): 6760.9 | learning rate: 4.722E-05 | global batch size:    32 | lm loss: 1.510878E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      788/  500000 | consumed samples:        25216 | consumed tokens:    103284736 | elapsed time per iteration (ms): 6763.0 | learning rate: 4.728E-05 | global batch size:    32 | lm loss: 1.452465E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration      789/  500000 | consumed samples:        25248 | consumed tokens:    103415808 | elapsed time per iteration (ms): 6759.1 | learning rate: 4.734E-05 | global batch size:    32 | lm loss: 1.486251E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
[2023-10-10 16:38:57,083] [INFO] [logging.py:96:log_dist] [Rank 0] step=790, skipped=0, lr=[4.74e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:38:57,330] [INFO] [timer.py:208:stop] epoch=0/micro_step=790/global_step=790, RunningAvgSamplesPerSec=4.742903853478926, CurrSamplesPerSec=4.742210226070027, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      790/  500000 | consumed samples:        25280 | consumed tokens:    103546880 | elapsed time per iteration (ms): 6759.8 | learning rate: 4.740E-05 | global batch size:    32 | lm loss: 1.462218E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      791/  500000 | consumed samples:        25312 | consumed tokens:    103677952 | elapsed time per iteration (ms): 6754.4 | learning rate: 4.746E-05 | global batch size:    32 | lm loss: 1.502833E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.738 | TFLOPs: 147.76 |
time (ms)
 iteration      792/  500000 | consumed samples:        25344 | consumed tokens:    103809024 | elapsed time per iteration (ms): 6759.8 | learning rate: 4.752E-05 | global batch size:    32 | lm loss: 1.528415E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      793/  500000 | consumed samples:        25376 | consumed tokens:    103940096 | elapsed time per iteration (ms): 6761.0 | learning rate: 4.758E-05 | global batch size:    32 | lm loss: 1.547193E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      794/  500000 | consumed samples:        25408 | consumed tokens:    104071168 | elapsed time per iteration (ms): 6763.0 | learning rate: 4.764E-05 | global batch size:    32 | lm loss: 1.497177E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration      795/  500000 | consumed samples:        25440 | consumed tokens:    104202240 | elapsed time per iteration (ms): 6761.0 | learning rate: 4.770E-05 | global batch size:    32 | lm loss: 1.484264E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      796/  500000 | consumed samples:        25472 | consumed tokens:    104333312 | elapsed time per iteration (ms): 6763.5 | learning rate: 4.776E-05 | global batch size:    32 | lm loss: 1.498302E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration      797/  500000 | consumed samples:        25504 | consumed tokens:    104464384 | elapsed time per iteration (ms): 6761.6 | learning rate: 4.782E-05 | global batch size:    32 | lm loss: 1.453511E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      798/  500000 | consumed samples:        25536 | consumed tokens:    104595456 | elapsed time per iteration (ms): 6760.8 | learning rate: 4.788E-05 | global batch size:    32 | lm loss: 1.522301E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      799/  500000 | consumed samples:        25568 | consumed tokens:    104726528 | elapsed time per iteration (ms): 6763.9 | learning rate: 4.794E-05 | global batch size:    32 | lm loss: 1.472253E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
[2023-10-10 16:40:04,736] [INFO] [logging.py:96:log_dist] [Rank 0] step=800, skipped=0, lr=[4.8e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:40:04,984] [INFO] [timer.py:208:stop] epoch=0/micro_step=800/global_step=800, RunningAvgSamplesPerSec=4.7428931741401295, CurrSamplesPerSec=4.740392639856046, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      800/  500000 | consumed samples:        25600 | consumed tokens:    104857600 | elapsed time per iteration (ms): 6762.8 | learning rate: 4.800E-05 | global batch size:    32 | lm loss: 1.507007E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration      801/  500000 | consumed samples:        25632 | consumed tokens:    104988672 | elapsed time per iteration (ms): 6758.2 | learning rate: 4.806E-05 | global batch size:    32 | lm loss: 1.571214E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      802/  500000 | consumed samples:        25664 | consumed tokens:    105119744 | elapsed time per iteration (ms): 6762.6 | learning rate: 4.812E-05 | global batch size:    32 | lm loss: 1.484258E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration      803/  500000 | consumed samples:        25696 | consumed tokens:    105250816 | elapsed time per iteration (ms): 6761.1 | learning rate: 4.818E-05 | global batch size:    32 | lm loss: 1.420565E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      804/  500000 | consumed samples:        25728 | consumed tokens:    105381888 | elapsed time per iteration (ms): 6762.6 | learning rate: 4.824E-05 | global batch size:    32 | lm loss: 1.456018E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration      805/  500000 | consumed samples:        25760 | consumed tokens:    105512960 | elapsed time per iteration (ms): 6757.9 | learning rate: 4.830E-05 | global batch size:    32 | lm loss: 1.496161E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      806/  500000 | consumed samples:        25792 | consumed tokens:    105644032 | elapsed time per iteration (ms): 6761.2 | learning rate: 4.836E-05 | global batch size:    32 | lm loss: 1.520994E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      807/  500000 | consumed samples:        25824 | consumed tokens:    105775104 | elapsed time per iteration (ms): 6756.6 | learning rate: 4.842E-05 | global batch size:    32 | lm loss: 1.444101E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      808/  500000 | consumed samples:        25856 | consumed tokens:    105906176 | elapsed time per iteration (ms): 6757.2 | learning rate: 4.848E-05 | global batch size:    32 | lm loss: 1.472268E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      809/  500000 | consumed samples:        25888 | consumed tokens:    106037248 | elapsed time per iteration (ms): 6764.9 | learning rate: 4.854E-05 | global batch size:    32 | lm loss: 1.459052E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
[2023-10-10 16:41:12,376] [INFO] [logging.py:96:log_dist] [Rank 0] step=810, skipped=0, lr=[4.8599999999999995e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:41:12,629] [INFO] [timer.py:208:stop] epoch=0/micro_step=810/global_step=810, RunningAvgSamplesPerSec=4.742888948377668, CurrSamplesPerSec=4.742514856650981, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      810/  500000 | consumed samples:        25920 | consumed tokens:    106168320 | elapsed time per iteration (ms): 6760.0 | learning rate: 4.860E-05 | global batch size:    32 | lm loss: 1.589165E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      811/  500000 | consumed samples:        25952 | consumed tokens:    106299392 | elapsed time per iteration (ms): 6757.1 | learning rate: 4.866E-05 | global batch size:    32 | lm loss: 1.525433E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      812/  500000 | consumed samples:        25984 | consumed tokens:    106430464 | elapsed time per iteration (ms): 6760.1 | learning rate: 4.872E-05 | global batch size:    32 | lm loss: 1.483520E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      813/  500000 | consumed samples:        26016 | consumed tokens:    106561536 | elapsed time per iteration (ms): 6760.0 | learning rate: 4.878E-05 | global batch size:    32 | lm loss: 1.516861E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      814/  500000 | consumed samples:        26048 | consumed tokens:    106692608 | elapsed time per iteration (ms): 6761.5 | learning rate: 4.884E-05 | global batch size:    32 | lm loss: 1.416834E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      815/  500000 | consumed samples:        26080 | consumed tokens:    106823680 | elapsed time per iteration (ms): 6757.4 | learning rate: 4.890E-05 | global batch size:    32 | lm loss: 1.445328E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      816/  500000 | consumed samples:        26112 | consumed tokens:    106954752 | elapsed time per iteration (ms): 6757.9 | learning rate: 4.896E-05 | global batch size:    32 | lm loss: 1.407727E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      817/  500000 | consumed samples:        26144 | consumed tokens:    107085824 | elapsed time per iteration (ms): 6758.3 | learning rate: 4.902E-05 | global batch size:    32 | lm loss: 1.376167E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      818/  500000 | consumed samples:        26176 | consumed tokens:    107216896 | elapsed time per iteration (ms): 6757.6 | learning rate: 4.908E-05 | global batch size:    32 | lm loss: 1.420416E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      819/  500000 | consumed samples:        26208 | consumed tokens:    107347968 | elapsed time per iteration (ms): 6760.4 | learning rate: 4.914E-05 | global batch size:    32 | lm loss: 1.449394E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
[2023-10-10 16:42:20,011] [INFO] [logging.py:96:log_dist] [Rank 0] step=820, skipped=0, lr=[4.9199999999999997e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:42:20,265] [INFO] [timer.py:208:stop] epoch=0/micro_step=820/global_step=820, RunningAvgSamplesPerSec=4.742891960651997, CurrSamplesPerSec=4.740130467748467, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      820/  500000 | consumed samples:        26240 | consumed tokens:    107479040 | elapsed time per iteration (ms): 6764.5 | learning rate: 4.920E-05 | global batch size:    32 | lm loss: 1.420538E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.54 |
time (ms)
 iteration      821/  500000 | consumed samples:        26272 | consumed tokens:    107610112 | elapsed time per iteration (ms): 6758.7 | learning rate: 4.926E-05 | global batch size:    32 | lm loss: 1.402904E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      822/  500000 | consumed samples:        26304 | consumed tokens:    107741184 | elapsed time per iteration (ms): 6757.1 | learning rate: 4.932E-05 | global batch size:    32 | lm loss: 1.420756E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      823/  500000 | consumed samples:        26336 | consumed tokens:    107872256 | elapsed time per iteration (ms): 6761.4 | learning rate: 4.938E-05 | global batch size:    32 | lm loss: 1.416498E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      824/  500000 | consumed samples:        26368 | consumed tokens:    108003328 | elapsed time per iteration (ms): 6757.8 | learning rate: 4.944E-05 | global batch size:    32 | lm loss: 1.443285E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      825/  500000 | consumed samples:        26400 | consumed tokens:    108134400 | elapsed time per iteration (ms): 6760.8 | learning rate: 4.950E-05 | global batch size:    32 | lm loss: 1.404129E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      826/  500000 | consumed samples:        26432 | consumed tokens:    108265472 | elapsed time per iteration (ms): 6760.3 | learning rate: 4.956E-05 | global batch size:    32 | lm loss: 1.419937E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration      827/  500000 | consumed samples:        26464 | consumed tokens:    108396544 | elapsed time per iteration (ms): 6759.7 | learning rate: 4.962E-05 | global batch size:    32 | lm loss: 1.496914E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      828/  500000 | consumed samples:        26496 | consumed tokens:    108527616 | elapsed time per iteration (ms): 6759.3 | learning rate: 4.968E-05 | global batch size:    32 | lm loss: 1.406541E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      829/  500000 | consumed samples:        26528 | consumed tokens:    108658688 | elapsed time per iteration (ms): 6757.3 | learning rate: 4.974E-05 | global batch size:    32 | lm loss: 1.372840E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
[2023-10-10 16:43:27,647] [INFO] [logging.py:96:log_dist] [Rank 0] step=830, skipped=0, lr=[4.98e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:43:27,906] [INFO] [timer.py:208:stop] epoch=0/micro_step=830/global_step=830, RunningAvgSamplesPerSec=4.742894283405533, CurrSamplesPerSec=4.738558880362179, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      830/  500000 | consumed samples:        26560 | consumed tokens:    108789760 | elapsed time per iteration (ms): 6767.3 | learning rate: 4.980E-05 | global batch size:    32 | lm loss: 1.408942E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.48 |
time (ms)
 iteration      831/  500000 | consumed samples:        26592 | consumed tokens:    108920832 | elapsed time per iteration (ms): 6766.1 | learning rate: 4.986E-05 | global batch size:    32 | lm loss: 1.367636E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.51 |
time (ms)
 iteration      832/  500000 | consumed samples:        26624 | consumed tokens:    109051904 | elapsed time per iteration (ms): 6762.0 | learning rate: 4.992E-05 | global batch size:    32 | lm loss: 1.448027E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      833/  500000 | consumed samples:        26656 | consumed tokens:    109182976 | elapsed time per iteration (ms): 6761.4 | learning rate: 4.998E-05 | global batch size:    32 | lm loss: 1.386710E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      834/  500000 | consumed samples:        26688 | consumed tokens:    109314048 | elapsed time per iteration (ms): 6762.9 | learning rate: 5.004E-05 | global batch size:    32 | lm loss: 1.404173E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration      835/  500000 | consumed samples:        26720 | consumed tokens:    109445120 | elapsed time per iteration (ms): 6759.9 | learning rate: 5.010E-05 | global batch size:    32 | lm loss: 1.354587E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      836/  500000 | consumed samples:        26752 | consumed tokens:    109576192 | elapsed time per iteration (ms): 6757.4 | learning rate: 5.016E-05 | global batch size:    32 | lm loss: 1.392856E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      837/  500000 | consumed samples:        26784 | consumed tokens:    109707264 | elapsed time per iteration (ms): 6757.1 | learning rate: 5.022E-05 | global batch size:    32 | lm loss: 1.417755E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      838/  500000 | consumed samples:        26816 | consumed tokens:    109838336 | elapsed time per iteration (ms): 6762.6 | learning rate: 5.028E-05 | global batch size:    32 | lm loss: 1.438267E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration      839/  500000 | consumed samples:        26848 | consumed tokens:    109969408 | elapsed time per iteration (ms): 6757.1 | learning rate: 5.034E-05 | global batch size:    32 | lm loss: 1.350234E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
[2023-10-10 16:44:35,301] [INFO] [logging.py:96:log_dist] [Rank 0] step=840, skipped=0, lr=[5.04e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:44:35,557] [INFO] [timer.py:208:stop] epoch=0/micro_step=840/global_step=840, RunningAvgSamplesPerSec=4.742887446271669, CurrSamplesPerSec=4.741800762354001, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      840/  500000 | consumed samples:        26880 | consumed tokens:    110100480 | elapsed time per iteration (ms): 6761.4 | learning rate: 5.040E-05 | global batch size:    32 | lm loss: 1.383079E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      841/  500000 | consumed samples:        26912 | consumed tokens:    110231552 | elapsed time per iteration (ms): 6755.8 | learning rate: 5.046E-05 | global batch size:    32 | lm loss: 1.341859E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration      842/  500000 | consumed samples:        26944 | consumed tokens:    110362624 | elapsed time per iteration (ms): 6759.4 | learning rate: 5.052E-05 | global batch size:    32 | lm loss: 1.370811E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      843/  500000 | consumed samples:        26976 | consumed tokens:    110493696 | elapsed time per iteration (ms): 6758.3 | learning rate: 5.058E-05 | global batch size:    32 | lm loss: 1.361888E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      844/  500000 | consumed samples:        27008 | consumed tokens:    110624768 | elapsed time per iteration (ms): 6759.9 | learning rate: 5.064E-05 | global batch size:    32 | lm loss: 1.349366E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      845/  500000 | consumed samples:        27040 | consumed tokens:    110755840 | elapsed time per iteration (ms): 6756.3 | learning rate: 5.070E-05 | global batch size:    32 | lm loss: 1.377982E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      846/  500000 | consumed samples:        27072 | consumed tokens:    110886912 | elapsed time per iteration (ms): 6758.3 | learning rate: 5.076E-05 | global batch size:    32 | lm loss: 1.370546E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      847/  500000 | consumed samples:        27104 | consumed tokens:    111017984 | elapsed time per iteration (ms): 6761.2 | learning rate: 5.082E-05 | global batch size:    32 | lm loss: 1.392941E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      848/  500000 | consumed samples:        27136 | consumed tokens:    111149056 | elapsed time per iteration (ms): 6759.4 | learning rate: 5.088E-05 | global batch size:    32 | lm loss: 1.387625E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      849/  500000 | consumed samples:        27168 | consumed tokens:    111280128 | elapsed time per iteration (ms): 6761.4 | learning rate: 5.094E-05 | global batch size:    32 | lm loss: 1.341132E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
[2023-10-10 16:45:42,932] [INFO] [logging.py:96:log_dist] [Rank 0] step=850, skipped=0, lr=[5.1e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:45:43,193] [INFO] [timer.py:208:stop] epoch=0/micro_step=850/global_step=850, RunningAvgSamplesPerSec=4.742893027392104, CurrSamplesPerSec=4.7401369965867755, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      850/  500000 | consumed samples:        27200 | consumed tokens:    111411200 | elapsed time per iteration (ms): 6764.0 | learning rate: 5.100E-05 | global batch size:    32 | lm loss: 1.363526E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration      851/  500000 | consumed samples:        27232 | consumed tokens:    111542272 | elapsed time per iteration (ms): 6763.4 | learning rate: 5.106E-05 | global batch size:    32 | lm loss: 1.369818E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration      852/  500000 | consumed samples:        27264 | consumed tokens:    111673344 | elapsed time per iteration (ms): 6759.5 | learning rate: 5.112E-05 | global batch size:    32 | lm loss: 1.388029E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      853/  500000 | consumed samples:        27296 | consumed tokens:    111804416 | elapsed time per iteration (ms): 6760.9 | learning rate: 5.118E-05 | global batch size:    32 | lm loss: 1.386864E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      854/  500000 | consumed samples:        27328 | consumed tokens:    111935488 | elapsed time per iteration (ms): 6761.9 | learning rate: 5.124E-05 | global batch size:    32 | lm loss: 1.364907E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      855/  500000 | consumed samples:        27360 | consumed tokens:    112066560 | elapsed time per iteration (ms): 6755.6 | learning rate: 5.130E-05 | global batch size:    32 | lm loss: 1.424316E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration      856/  500000 | consumed samples:        27392 | consumed tokens:    112197632 | elapsed time per iteration (ms): 6759.3 | learning rate: 5.136E-05 | global batch size:    32 | lm loss: 1.347273E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      857/  500000 | consumed samples:        27424 | consumed tokens:    112328704 | elapsed time per iteration (ms): 6758.2 | learning rate: 5.142E-05 | global batch size:    32 | lm loss: 1.370973E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      858/  500000 | consumed samples:        27456 | consumed tokens:    112459776 | elapsed time per iteration (ms): 6755.4 | learning rate: 5.148E-05 | global batch size:    32 | lm loss: 1.376478E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration      859/  500000 | consumed samples:        27488 | consumed tokens:    112590848 | elapsed time per iteration (ms): 6756.3 | learning rate: 5.154E-05 | global batch size:    32 | lm loss: 1.355270E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
[2023-10-10 16:46:50,565] [INFO] [logging.py:96:log_dist] [Rank 0] step=860, skipped=0, lr=[5.159999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:46:50,823] [INFO] [timer.py:208:stop] epoch=0/micro_step=860/global_step=860, RunningAvgSamplesPerSec=4.742899444970138, CurrSamplesPerSec=4.74534805182169, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      860/  500000 | consumed samples:        27520 | consumed tokens:    112721920 | elapsed time per iteration (ms): 6756.7 | learning rate: 5.160E-05 | global batch size:    32 | lm loss: 1.403564E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      861/  500000 | consumed samples:        27552 | consumed tokens:    112852992 | elapsed time per iteration (ms): 6757.5 | learning rate: 5.166E-05 | global batch size:    32 | lm loss: 1.398738E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.70 |
time (ms)
 iteration      862/  500000 | consumed samples:        27584 | consumed tokens:    112984064 | elapsed time per iteration (ms): 6761.9 | learning rate: 5.172E-05 | global batch size:    32 | lm loss: 1.357694E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      863/  500000 | consumed samples:        27616 | consumed tokens:    113115136 | elapsed time per iteration (ms): 6756.5 | learning rate: 5.178E-05 | global batch size:    32 | lm loss: 1.393309E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      864/  500000 | consumed samples:        27648 | consumed tokens:    113246208 | elapsed time per iteration (ms): 6763.8 | learning rate: 5.184E-05 | global batch size:    32 | lm loss: 1.320936E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration      865/  500000 | consumed samples:        27680 | consumed tokens:    113377280 | elapsed time per iteration (ms): 6757.3 | learning rate: 5.190E-05 | global batch size:    32 | lm loss: 1.332618E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      866/  500000 | consumed samples:        27712 | consumed tokens:    113508352 | elapsed time per iteration (ms): 6757.2 | learning rate: 5.196E-05 | global batch size:    32 | lm loss: 1.381390E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      867/  500000 | consumed samples:        27744 | consumed tokens:    113639424 | elapsed time per iteration (ms): 6758.2 | learning rate: 5.202E-05 | global batch size:    32 | lm loss: 1.363727E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      868/  500000 | consumed samples:        27776 | consumed tokens:    113770496 | elapsed time per iteration (ms): 6758.1 | learning rate: 5.208E-05 | global batch size:    32 | lm loss: 1.350072E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      869/  500000 | consumed samples:        27808 | consumed tokens:    113901568 | elapsed time per iteration (ms): 6760.0 | learning rate: 5.214E-05 | global batch size:    32 | lm loss: 1.399895E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
[2023-10-10 16:47:58,196] [INFO] [logging.py:96:log_dist] [Rank 0] step=870, skipped=0, lr=[5.219999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:47:58,455] [INFO] [timer.py:208:stop] epoch=0/micro_step=870/global_step=870, RunningAvgSamplesPerSec=4.742906322155128, CurrSamplesPerSec=4.743289847021542, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      870/  500000 | consumed samples:        27840 | consumed tokens:    114032640 | elapsed time per iteration (ms): 6759.2 | learning rate: 5.220E-05 | global batch size:    32 | lm loss: 1.390172E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      871/  500000 | consumed samples:        27872 | consumed tokens:    114163712 | elapsed time per iteration (ms): 6759.6 | learning rate: 5.226E-05 | global batch size:    32 | lm loss: 1.317888E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      872/  500000 | consumed samples:        27904 | consumed tokens:    114294784 | elapsed time per iteration (ms): 6754.4 | learning rate: 5.232E-05 | global batch size:    32 | lm loss: 1.354262E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.738 | TFLOPs: 147.76 |
time (ms)
 iteration      873/  500000 | consumed samples:        27936 | consumed tokens:    114425856 | elapsed time per iteration (ms): 6757.5 | learning rate: 5.238E-05 | global batch size:    32 | lm loss: 1.413396E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      874/  500000 | consumed samples:        27968 | consumed tokens:    114556928 | elapsed time per iteration (ms): 6758.4 | learning rate: 5.244E-05 | global batch size:    32 | lm loss: 1.349695E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      875/  500000 | consumed samples:        28000 | consumed tokens:    114688000 | elapsed time per iteration (ms): 6761.6 | learning rate: 5.250E-05 | global batch size:    32 | lm loss: 1.329420E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      876/  500000 | consumed samples:        28032 | consumed tokens:    114819072 | elapsed time per iteration (ms): 6757.6 | learning rate: 5.256E-05 | global batch size:    32 | lm loss: 1.382308E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      877/  500000 | consumed samples:        28064 | consumed tokens:    114950144 | elapsed time per iteration (ms): 6758.9 | learning rate: 5.262E-05 | global batch size:    32 | lm loss: 1.377531E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.66 |
time (ms)
 iteration      878/  500000 | consumed samples:        28096 | consumed tokens:    115081216 | elapsed time per iteration (ms): 6758.5 | learning rate: 5.268E-05 | global batch size:    32 | lm loss: 1.340920E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      879/  500000 | consumed samples:        28128 | consumed tokens:    115212288 | elapsed time per iteration (ms): 6759.5 | learning rate: 5.274E-05 | global batch size:    32 | lm loss: 1.367108E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
[2023-10-10 16:49:05,818] [INFO] [logging.py:96:log_dist] [Rank 0] step=880, skipped=0, lr=[5.279999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:49:06,079] [INFO] [timer.py:208:stop] epoch=0/micro_step=880/global_step=880, RunningAvgSamplesPerSec=4.742918229796153, CurrSamplesPerSec=4.744707910242832, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      880/  500000 | consumed samples:        28160 | consumed tokens:    115343360 | elapsed time per iteration (ms): 6757.3 | learning rate: 5.280E-05 | global batch size:    32 | lm loss: 1.380875E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      881/  500000 | consumed samples:        28192 | consumed tokens:    115474432 | elapsed time per iteration (ms): 6759.0 | learning rate: 5.286E-05 | global batch size:    32 | lm loss: 1.358469E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      882/  500000 | consumed samples:        28224 | consumed tokens:    115605504 | elapsed time per iteration (ms): 6764.8 | learning rate: 5.292E-05 | global batch size:    32 | lm loss: 1.394794E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration      883/  500000 | consumed samples:        28256 | consumed tokens:    115736576 | elapsed time per iteration (ms): 6761.2 | learning rate: 5.298E-05 | global batch size:    32 | lm loss: 1.349475E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      884/  500000 | consumed samples:        28288 | consumed tokens:    115867648 | elapsed time per iteration (ms): 6759.1 | learning rate: 5.304E-05 | global batch size:    32 | lm loss: 1.342272E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      885/  500000 | consumed samples:        28320 | consumed tokens:    115998720 | elapsed time per iteration (ms): 6760.1 | learning rate: 5.310E-05 | global batch size:    32 | lm loss: 1.306655E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      886/  500000 | consumed samples:        28352 | consumed tokens:    116129792 | elapsed time per iteration (ms): 6764.7 | learning rate: 5.316E-05 | global batch size:    32 | lm loss: 1.322152E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration      887/  500000 | consumed samples:        28384 | consumed tokens:    116260864 | elapsed time per iteration (ms): 6753.6 | learning rate: 5.322E-05 | global batch size:    32 | lm loss: 1.292553E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.738 | TFLOPs: 147.78 |
time (ms)
 iteration      888/  500000 | consumed samples:        28416 | consumed tokens:    116391936 | elapsed time per iteration (ms): 6761.6 | learning rate: 5.328E-05 | global batch size:    32 | lm loss: 1.332332E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      889/  500000 | consumed samples:        28448 | consumed tokens:    116523008 | elapsed time per iteration (ms): 6756.0 | learning rate: 5.334E-05 | global batch size:    32 | lm loss: 1.299229E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.73 |
time (ms)
[2023-10-10 16:50:13,457] [INFO] [logging.py:96:log_dist] [Rank 0] step=890, skipped=0, lr=[5.339999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:50:13,718] [INFO] [timer.py:208:stop] epoch=0/micro_step=890/global_step=890, RunningAvgSamplesPerSec=4.7429172745265, CurrSamplesPerSec=4.744484672973028, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      890/  500000 | consumed samples:        28480 | consumed tokens:    116654080 | elapsed time per iteration (ms): 6756.8 | learning rate: 5.340E-05 | global batch size:    32 | lm loss: 1.382230E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      891/  500000 | consumed samples:        28512 | consumed tokens:    116785152 | elapsed time per iteration (ms): 6755.2 | learning rate: 5.346E-05 | global batch size:    32 | lm loss: 1.357234E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration      892/  500000 | consumed samples:        28544 | consumed tokens:    116916224 | elapsed time per iteration (ms): 6757.9 | learning rate: 5.352E-05 | global batch size:    32 | lm loss: 1.330897E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      893/  500000 | consumed samples:        28576 | consumed tokens:    117047296 | elapsed time per iteration (ms): 6759.6 | learning rate: 5.358E-05 | global batch size:    32 | lm loss: 1.335486E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      894/  500000 | consumed samples:        28608 | consumed tokens:    117178368 | elapsed time per iteration (ms): 6758.3 | learning rate: 5.364E-05 | global batch size:    32 | lm loss: 1.372739E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      895/  500000 | consumed samples:        28640 | consumed tokens:    117309440 | elapsed time per iteration (ms): 6760.6 | learning rate: 5.370E-05 | global batch size:    32 | lm loss: 1.324804E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      896/  500000 | consumed samples:        28672 | consumed tokens:    117440512 | elapsed time per iteration (ms): 6761.3 | learning rate: 5.376E-05 | global batch size:    32 | lm loss: 1.299733E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      897/  500000 | consumed samples:        28704 | consumed tokens:    117571584 | elapsed time per iteration (ms): 6760.7 | learning rate: 5.382E-05 | global batch size:    32 | lm loss: 1.331919E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      898/  500000 | consumed samples:        28736 | consumed tokens:    117702656 | elapsed time per iteration (ms): 6763.3 | learning rate: 5.388E-05 | global batch size:    32 | lm loss: 1.374439E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration      899/  500000 | consumed samples:        28768 | consumed tokens:    117833728 | elapsed time per iteration (ms): 6755.6 | learning rate: 5.394E-05 | global batch size:    32 | lm loss: 1.295083E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
[2023-10-10 16:51:21,089] [INFO] [logging.py:96:log_dist] [Rank 0] step=900, skipped=0, lr=[5.399999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:51:21,347] [INFO] [timer.py:208:stop] epoch=0/micro_step=900/global_step=900, RunningAvgSamplesPerSec=4.742923655711871, CurrSamplesPerSec=4.746100975979945, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      900/  500000 | consumed samples:        28800 | consumed tokens:    117964800 | elapsed time per iteration (ms): 6754.7 | learning rate: 5.400E-05 | global batch size:    32 | lm loss: 1.327831E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.76 |
time (ms)
 iteration      901/  500000 | consumed samples:        28832 | consumed tokens:    118095872 | elapsed time per iteration (ms): 6760.0 | learning rate: 5.406E-05 | global batch size:    32 | lm loss: 1.314873E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      902/  500000 | consumed samples:        28864 | consumed tokens:    118226944 | elapsed time per iteration (ms): 6758.2 | learning rate: 5.412E-05 | global batch size:    32 | lm loss: 1.344469E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      903/  500000 | consumed samples:        28896 | consumed tokens:    118358016 | elapsed time per iteration (ms): 6758.2 | learning rate: 5.418E-05 | global batch size:    32 | lm loss: 1.314019E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      904/  500000 | consumed samples:        28928 | consumed tokens:    118489088 | elapsed time per iteration (ms): 6758.9 | learning rate: 5.424E-05 | global batch size:    32 | lm loss: 1.309859E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      905/  500000 | consumed samples:        28960 | consumed tokens:    118620160 | elapsed time per iteration (ms): 6758.0 | learning rate: 5.430E-05 | global batch size:    32 | lm loss: 1.321107E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      906/  500000 | consumed samples:        28992 | consumed tokens:    118751232 | elapsed time per iteration (ms): 6759.1 | learning rate: 5.436E-05 | global batch size:    32 | lm loss: 1.357740E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      907/  500000 | consumed samples:        29024 | consumed tokens:    118882304 | elapsed time per iteration (ms): 6760.6 | learning rate: 5.442E-05 | global batch size:    32 | lm loss: 1.316001E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      908/  500000 | consumed samples:        29056 | consumed tokens:    119013376 | elapsed time per iteration (ms): 6761.7 | learning rate: 5.448E-05 | global batch size:    32 | lm loss: 1.322230E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration      909/  500000 | consumed samples:        29088 | consumed tokens:    119144448 | elapsed time per iteration (ms): 6762.0 | learning rate: 5.454E-05 | global batch size:    32 | lm loss: 1.335615E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
[2023-10-10 16:52:28,729] [INFO] [logging.py:96:log_dist] [Rank 0] step=910, skipped=0, lr=[5.459999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:52:28,987] [INFO] [timer.py:208:stop] epoch=0/micro_step=910/global_step=910, RunningAvgSamplesPerSec=4.742925238162957, CurrSamplesPerSec=4.7420291083972295, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      910/  500000 | consumed samples:        29120 | consumed tokens:    119275520 | elapsed time per iteration (ms): 6761.3 | learning rate: 5.460E-05 | global batch size:    32 | lm loss: 1.300468E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      911/  500000 | consumed samples:        29152 | consumed tokens:    119406592 | elapsed time per iteration (ms): 6762.2 | learning rate: 5.466E-05 | global batch size:    32 | lm loss: 1.313276E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      912/  500000 | consumed samples:        29184 | consumed tokens:    119537664 | elapsed time per iteration (ms): 6761.4 | learning rate: 5.472E-05 | global batch size:    32 | lm loss: 1.285803E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      913/  500000 | consumed samples:        29216 | consumed tokens:    119668736 | elapsed time per iteration (ms): 6764.4 | learning rate: 5.478E-05 | global batch size:    32 | lm loss: 1.325681E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.54 |
time (ms)
 iteration      914/  500000 | consumed samples:        29248 | consumed tokens:    119799808 | elapsed time per iteration (ms): 6758.1 | learning rate: 5.484E-05 | global batch size:    32 | lm loss: 1.361988E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      915/  500000 | consumed samples:        29280 | consumed tokens:    119930880 | elapsed time per iteration (ms): 6764.3 | learning rate: 5.490E-05 | global batch size:    32 | lm loss: 1.343808E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration      916/  500000 | consumed samples:        29312 | consumed tokens:    120061952 | elapsed time per iteration (ms): 6761.9 | learning rate: 5.496E-05 | global batch size:    32 | lm loss: 1.334035E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      917/  500000 | consumed samples:        29344 | consumed tokens:    120193024 | elapsed time per iteration (ms): 6761.3 | learning rate: 5.502E-05 | global batch size:    32 | lm loss: 1.333497E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      918/  500000 | consumed samples:        29376 | consumed tokens:    120324096 | elapsed time per iteration (ms): 6758.2 | learning rate: 5.508E-05 | global batch size:    32 | lm loss: 1.351815E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      919/  500000 | consumed samples:        29408 | consumed tokens:    120455168 | elapsed time per iteration (ms): 6760.8 | learning rate: 5.514E-05 | global batch size:    32 | lm loss: 1.323102E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
[2023-10-10 16:53:36,381] [INFO] [logging.py:96:log_dist] [Rank 0] step=920, skipped=0, lr=[5.519999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:53:36,644] [INFO] [timer.py:208:stop] epoch=0/micro_step=920/global_step=920, RunningAvgSamplesPerSec=4.742914399765064, CurrSamplesPerSec=4.742107350874858, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      920/  500000 | consumed samples:        29440 | consumed tokens:    120586240 | elapsed time per iteration (ms): 6761.3 | learning rate: 5.520E-05 | global batch size:    32 | lm loss: 1.306281E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration      921/  500000 | consumed samples:        29472 | consumed tokens:    120717312 | elapsed time per iteration (ms): 6756.8 | learning rate: 5.526E-05 | global batch size:    32 | lm loss: 1.289172E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      922/  500000 | consumed samples:        29504 | consumed tokens:    120848384 | elapsed time per iteration (ms): 6756.2 | learning rate: 5.532E-05 | global batch size:    32 | lm loss: 1.313351E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      923/  500000 | consumed samples:        29536 | consumed tokens:    120979456 | elapsed time per iteration (ms): 6757.6 | learning rate: 5.538E-05 | global batch size:    32 | lm loss: 1.351172E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      924/  500000 | consumed samples:        29568 | consumed tokens:    121110528 | elapsed time per iteration (ms): 6763.7 | learning rate: 5.544E-05 | global batch size:    32 | lm loss: 1.320471E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration      925/  500000 | consumed samples:        29600 | consumed tokens:    121241600 | elapsed time per iteration (ms): 6758.1 | learning rate: 5.550E-05 | global batch size:    32 | lm loss: 1.316131E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      926/  500000 | consumed samples:        29632 | consumed tokens:    121372672 | elapsed time per iteration (ms): 6760.1 | learning rate: 5.556E-05 | global batch size:    32 | lm loss: 1.319409E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      927/  500000 | consumed samples:        29664 | consumed tokens:    121503744 | elapsed time per iteration (ms): 6759.5 | learning rate: 5.562E-05 | global batch size:    32 | lm loss: 1.314149E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      928/  500000 | consumed samples:        29696 | consumed tokens:    121634816 | elapsed time per iteration (ms): 6757.2 | learning rate: 5.568E-05 | global batch size:    32 | lm loss: 1.290623E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      929/  500000 | consumed samples:        29728 | consumed tokens:    121765888 | elapsed time per iteration (ms): 6758.5 | learning rate: 5.574E-05 | global batch size:    32 | lm loss: 1.318181E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
[2023-10-10 16:54:44,014] [INFO] [logging.py:96:log_dist] [Rank 0] step=930, skipped=0, lr=[5.5799999999999994e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:54:44,269] [INFO] [timer.py:208:stop] epoch=0/micro_step=930/global_step=930, RunningAvgSamplesPerSec=4.742925238921189, CurrSamplesPerSec=4.7458873407270294, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      930/  500000 | consumed samples:        29760 | consumed tokens:    121896960 | elapsed time per iteration (ms): 6755.8 | learning rate: 5.580E-05 | global batch size:    32 | lm loss: 1.278459E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration      931/  500000 | consumed samples:        29792 | consumed tokens:    122028032 | elapsed time per iteration (ms): 6757.4 | learning rate: 5.586E-05 | global batch size:    32 | lm loss: 1.284752E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      932/  500000 | consumed samples:        29824 | consumed tokens:    122159104 | elapsed time per iteration (ms): 6758.9 | learning rate: 5.592E-05 | global batch size:    32 | lm loss: 1.310470E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.66 |
time (ms)
 iteration      933/  500000 | consumed samples:        29856 | consumed tokens:    122290176 | elapsed time per iteration (ms): 6762.4 | learning rate: 5.598E-05 | global batch size:    32 | lm loss: 1.333063E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      934/  500000 | consumed samples:        29888 | consumed tokens:    122421248 | elapsed time per iteration (ms): 6761.7 | learning rate: 5.604E-05 | global batch size:    32 | lm loss: 1.266752E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration      935/  500000 | consumed samples:        29920 | consumed tokens:    122552320 | elapsed time per iteration (ms): 6760.0 | learning rate: 5.610E-05 | global batch size:    32 | lm loss: 1.322767E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      936/  500000 | consumed samples:        29952 | consumed tokens:    122683392 | elapsed time per iteration (ms): 6760.9 | learning rate: 5.616E-05 | global batch size:    32 | lm loss: 1.291937E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      937/  500000 | consumed samples:        29984 | consumed tokens:    122814464 | elapsed time per iteration (ms): 6764.6 | learning rate: 5.622E-05 | global batch size:    32 | lm loss: 1.311735E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration      938/  500000 | consumed samples:        30016 | consumed tokens:    122945536 | elapsed time per iteration (ms): 6756.3 | learning rate: 5.628E-05 | global batch size:    32 | lm loss: 1.292603E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      939/  500000 | consumed samples:        30048 | consumed tokens:    123076608 | elapsed time per iteration (ms): 6756.4 | learning rate: 5.634E-05 | global batch size:    32 | lm loss: 1.326715E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
[2023-10-10 16:55:51,654] [INFO] [logging.py:96:log_dist] [Rank 0] step=940, skipped=0, lr=[5.6399999999999995e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:55:51,910] [INFO] [timer.py:208:stop] epoch=0/micro_step=940/global_step=940, RunningAvgSamplesPerSec=4.742924986900431, CurrSamplesPerSec=4.741732078558356, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      940/  500000 | consumed samples:        30080 | consumed tokens:    123207680 | elapsed time per iteration (ms): 6761.7 | learning rate: 5.640E-05 | global batch size:    32 | lm loss: 1.316747E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration      941/  500000 | consumed samples:        30112 | consumed tokens:    123338752 | elapsed time per iteration (ms): 6761.0 | learning rate: 5.646E-05 | global batch size:    32 | lm loss: 1.302954E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      942/  500000 | consumed samples:        30144 | consumed tokens:    123469824 | elapsed time per iteration (ms): 6757.9 | learning rate: 5.652E-05 | global batch size:    32 | lm loss: 1.314263E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      943/  500000 | consumed samples:        30176 | consumed tokens:    123600896 | elapsed time per iteration (ms): 6758.7 | learning rate: 5.658E-05 | global batch size:    32 | lm loss: 1.251593E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      944/  500000 | consumed samples:        30208 | consumed tokens:    123731968 | elapsed time per iteration (ms): 6764.2 | learning rate: 5.664E-05 | global batch size:    32 | lm loss: 1.304217E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration      945/  500000 | consumed samples:        30240 | consumed tokens:    123863040 | elapsed time per iteration (ms): 6763.2 | learning rate: 5.670E-05 | global batch size:    32 | lm loss: 1.338840E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration      946/  500000 | consumed samples:        30272 | consumed tokens:    123994112 | elapsed time per iteration (ms): 6762.8 | learning rate: 5.676E-05 | global batch size:    32 | lm loss: 1.330266E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration      947/  500000 | consumed samples:        30304 | consumed tokens:    124125184 | elapsed time per iteration (ms): 6764.8 | learning rate: 5.682E-05 | global batch size:    32 | lm loss: 1.278888E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration      948/  500000 | consumed samples:        30336 | consumed tokens:    124256256 | elapsed time per iteration (ms): 6760.1 | learning rate: 5.688E-05 | global batch size:    32 | lm loss: 1.240334E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      949/  500000 | consumed samples:        30368 | consumed tokens:    124387328 | elapsed time per iteration (ms): 6758.2 | learning rate: 5.694E-05 | global batch size:    32 | lm loss: 1.292067E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
[2023-10-10 16:56:59,332] [INFO] [logging.py:96:log_dist] [Rank 0] step=950, skipped=0, lr=[5.6999999999999996e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:56:59,560] [INFO] [timer.py:208:stop] epoch=0/micro_step=950/global_step=950, RunningAvgSamplesPerSec=4.742915290253004, CurrSamplesPerSec=4.744527272603229, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      950/  500000 | consumed samples:        30400 | consumed tokens:    124518400 | elapsed time per iteration (ms): 6757.0 | learning rate: 5.700E-05 | global batch size:    32 | lm loss: 1.293924E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      951/  500000 | consumed samples:        30432 | consumed tokens:    124649472 | elapsed time per iteration (ms): 6756.0 | learning rate: 5.706E-05 | global batch size:    32 | lm loss: 1.366217E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration      952/  500000 | consumed samples:        30464 | consumed tokens:    124780544 | elapsed time per iteration (ms): 6758.2 | learning rate: 5.712E-05 | global batch size:    32 | lm loss: 1.268642E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      953/  500000 | consumed samples:        30496 | consumed tokens:    124911616 | elapsed time per iteration (ms): 6757.9 | learning rate: 5.718E-05 | global batch size:    32 | lm loss: 1.262962E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      954/  500000 | consumed samples:        30528 | consumed tokens:    125042688 | elapsed time per iteration (ms): 6759.4 | learning rate: 5.724E-05 | global batch size:    32 | lm loss: 1.321846E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      955/  500000 | consumed samples:        30560 | consumed tokens:    125173760 | elapsed time per iteration (ms): 6756.7 | learning rate: 5.730E-05 | global batch size:    32 | lm loss: 1.271876E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration      956/  500000 | consumed samples:        30592 | consumed tokens:    125304832 | elapsed time per iteration (ms): 6759.9 | learning rate: 5.736E-05 | global batch size:    32 | lm loss: 1.266194E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      957/  500000 | consumed samples:        30624 | consumed tokens:    125435904 | elapsed time per iteration (ms): 6760.0 | learning rate: 5.742E-05 | global batch size:    32 | lm loss: 1.259880E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      958/  500000 | consumed samples:        30656 | consumed tokens:    125566976 | elapsed time per iteration (ms): 6758.2 | learning rate: 5.748E-05 | global batch size:    32 | lm loss: 1.246110E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      959/  500000 | consumed samples:        30688 | consumed tokens:    125698048 | elapsed time per iteration (ms): 6764.4 | learning rate: 5.754E-05 | global batch size:    32 | lm loss: 1.286353E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.54 |
time (ms)
[2023-10-10 16:58:06,934] [INFO] [logging.py:96:log_dist] [Rank 0] step=960, skipped=0, lr=[5.76e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:58:07,191] [INFO] [timer.py:208:stop] epoch=0/micro_step=960/global_step=960, RunningAvgSamplesPerSec=4.742920302966191, CurrSamplesPerSec=4.7431850811405125, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      960/  500000 | consumed samples:        30720 | consumed tokens:    125829120 | elapsed time per iteration (ms): 6759.0 | learning rate: 5.760E-05 | global batch size:    32 | lm loss: 1.298972E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      961/  500000 | consumed samples:        30752 | consumed tokens:    125960192 | elapsed time per iteration (ms): 6757.7 | learning rate: 5.766E-05 | global batch size:    32 | lm loss: 1.263771E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      962/  500000 | consumed samples:        30784 | consumed tokens:    126091264 | elapsed time per iteration (ms): 6759.1 | learning rate: 5.772E-05 | global batch size:    32 | lm loss: 1.250932E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      963/  500000 | consumed samples:        30816 | consumed tokens:    126222336 | elapsed time per iteration (ms): 6760.7 | learning rate: 5.778E-05 | global batch size:    32 | lm loss: 1.262825E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      964/  500000 | consumed samples:        30848 | consumed tokens:    126353408 | elapsed time per iteration (ms): 6760.9 | learning rate: 5.784E-05 | global batch size:    32 | lm loss: 1.309506E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      965/  500000 | consumed samples:        30880 | consumed tokens:    126484480 | elapsed time per iteration (ms): 6759.3 | learning rate: 5.790E-05 | global batch size:    32 | lm loss: 1.317397E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration      966/  500000 | consumed samples:        30912 | consumed tokens:    126615552 | elapsed time per iteration (ms): 6757.8 | learning rate: 5.796E-05 | global batch size:    32 | lm loss: 1.306278E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      967/  500000 | consumed samples:        30944 | consumed tokens:    126746624 | elapsed time per iteration (ms): 6761.9 | learning rate: 5.802E-05 | global batch size:    32 | lm loss: 1.279226E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      968/  500000 | consumed samples:        30976 | consumed tokens:    126877696 | elapsed time per iteration (ms): 6762.7 | learning rate: 5.808E-05 | global batch size:    32 | lm loss: 1.267381E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration      969/  500000 | consumed samples:        31008 | consumed tokens:    127008768 | elapsed time per iteration (ms): 6759.8 | learning rate: 5.814E-05 | global batch size:    32 | lm loss: 1.241418E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
[2023-10-10 16:59:14,573] [INFO] [logging.py:96:log_dist] [Rank 0] step=970, skipped=0, lr=[5.82e-05], mom=[(0.9, 0.95)]
[2023-10-10 16:59:14,832] [INFO] [timer.py:208:stop] epoch=0/micro_step=970/global_step=970, RunningAvgSamplesPerSec=4.742920252244879, CurrSamplesPerSec=4.74360635190316, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      970/  500000 | consumed samples:        31040 | consumed tokens:    127139840 | elapsed time per iteration (ms): 6758.4 | learning rate: 5.820E-05 | global batch size:    32 | lm loss: 1.313222E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      971/  500000 | consumed samples:        31072 | consumed tokens:    127270912 | elapsed time per iteration (ms): 6761.9 | learning rate: 5.826E-05 | global batch size:    32 | lm loss: 1.295783E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration      972/  500000 | consumed samples:        31104 | consumed tokens:    127401984 | elapsed time per iteration (ms): 6762.3 | learning rate: 5.832E-05 | global batch size:    32 | lm loss: 1.261758E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration      973/  500000 | consumed samples:        31136 | consumed tokens:    127533056 | elapsed time per iteration (ms): 6760.0 | learning rate: 5.838E-05 | global batch size:    32 | lm loss: 1.308305E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      974/  500000 | consumed samples:        31168 | consumed tokens:    127664128 | elapsed time per iteration (ms): 6763.2 | learning rate: 5.844E-05 | global batch size:    32 | lm loss: 1.272176E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration      975/  500000 | consumed samples:        31200 | consumed tokens:    127795200 | elapsed time per iteration (ms): 6760.9 | learning rate: 5.850E-05 | global batch size:    32 | lm loss: 1.285005E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      976/  500000 | consumed samples:        31232 | consumed tokens:    127926272 | elapsed time per iteration (ms): 6757.7 | learning rate: 5.856E-05 | global batch size:    32 | lm loss: 1.276439E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration      977/  500000 | consumed samples:        31264 | consumed tokens:    128057344 | elapsed time per iteration (ms): 6757.4 | learning rate: 5.862E-05 | global batch size:    32 | lm loss: 1.284469E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      978/  500000 | consumed samples:        31296 | consumed tokens:    128188416 | elapsed time per iteration (ms): 6755.3 | learning rate: 5.868E-05 | global batch size:    32 | lm loss: 1.305717E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration      979/  500000 | consumed samples:        31328 | consumed tokens:    128319488 | elapsed time per iteration (ms): 6761.6 | learning rate: 5.874E-05 | global batch size:    32 | lm loss: 1.263415E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
[2023-10-10 17:00:22,215] [INFO] [logging.py:96:log_dist] [Rank 0] step=980, skipped=0, lr=[5.88e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:00:22,475] [INFO] [timer.py:208:stop] epoch=0/micro_step=980/global_step=980, RunningAvgSamplesPerSec=4.742919948071631, CurrSamplesPerSec=4.742867459275828, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      980/  500000 | consumed samples:        31360 | consumed tokens:    128450560 | elapsed time per iteration (ms): 6760.0 | learning rate: 5.880E-05 | global batch size:    32 | lm loss: 1.327983E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      981/  500000 | consumed samples:        31392 | consumed tokens:    128581632 | elapsed time per iteration (ms): 6759.7 | learning rate: 5.886E-05 | global batch size:    32 | lm loss: 1.261193E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      982/  500000 | consumed samples:        31424 | consumed tokens:    128712704 | elapsed time per iteration (ms): 6758.0 | learning rate: 5.892E-05 | global batch size:    32 | lm loss: 1.254357E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration      983/  500000 | consumed samples:        31456 | consumed tokens:    128843776 | elapsed time per iteration (ms): 6756.6 | learning rate: 5.898E-05 | global batch size:    32 | lm loss: 1.286895E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration      984/  500000 | consumed samples:        31488 | consumed tokens:    128974848 | elapsed time per iteration (ms): 6761.0 | learning rate: 5.904E-05 | global batch size:    32 | lm loss: 1.300909E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      985/  500000 | consumed samples:        31520 | consumed tokens:    129105920 | elapsed time per iteration (ms): 6758.7 | learning rate: 5.910E-05 | global batch size:    32 | lm loss: 1.292077E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      986/  500000 | consumed samples:        31552 | consumed tokens:    129236992 | elapsed time per iteration (ms): 6760.7 | learning rate: 5.916E-05 | global batch size:    32 | lm loss: 1.243201E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration      987/  500000 | consumed samples:        31584 | consumed tokens:    129368064 | elapsed time per iteration (ms): 6757.2 | learning rate: 5.922E-05 | global batch size:    32 | lm loss: 1.243705E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      988/  500000 | consumed samples:        31616 | consumed tokens:    129499136 | elapsed time per iteration (ms): 6761.7 | learning rate: 5.928E-05 | global batch size:    32 | lm loss: 1.309294E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration      989/  500000 | consumed samples:        31648 | consumed tokens:    129630208 | elapsed time per iteration (ms): 6759.4 | learning rate: 5.934E-05 | global batch size:    32 | lm loss: 1.251278E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
[2023-10-10 17:01:29,851] [INFO] [logging.py:96:log_dist] [Rank 0] step=990, skipped=0, lr=[5.94e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:01:30,110] [INFO] [timer.py:208:stop] epoch=0/micro_step=990/global_step=990, RunningAvgSamplesPerSec=4.7429218670638145, CurrSamplesPerSec=4.742694167974004, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration      990/  500000 | consumed samples:        31680 | consumed tokens:    129761280 | elapsed time per iteration (ms): 6760.0 | learning rate: 5.940E-05 | global batch size:    32 | lm loss: 1.262560E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      991/  500000 | consumed samples:        31712 | consumed tokens:    129892352 | elapsed time per iteration (ms): 6758.7 | learning rate: 5.946E-05 | global batch size:    32 | lm loss: 1.274279E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration      992/  500000 | consumed samples:        31744 | consumed tokens:    130023424 | elapsed time per iteration (ms): 6758.9 | learning rate: 5.952E-05 | global batch size:    32 | lm loss: 1.234172E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.66 |
time (ms)
 iteration      993/  500000 | consumed samples:        31776 | consumed tokens:    130154496 | elapsed time per iteration (ms): 6760.2 | learning rate: 5.958E-05 | global batch size:    32 | lm loss: 1.279138E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration      994/  500000 | consumed samples:        31808 | consumed tokens:    130285568 | elapsed time per iteration (ms): 6759.4 | learning rate: 5.964E-05 | global batch size:    32 | lm loss: 1.263579E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      995/  500000 | consumed samples:        31840 | consumed tokens:    130416640 | elapsed time per iteration (ms): 6755.6 | learning rate: 5.970E-05 | global batch size:    32 | lm loss: 1.266292E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration      996/  500000 | consumed samples:        31872 | consumed tokens:    130547712 | elapsed time per iteration (ms): 6759.7 | learning rate: 5.976E-05 | global batch size:    32 | lm loss: 1.260507E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration      997/  500000 | consumed samples:        31904 | consumed tokens:    130678784 | elapsed time per iteration (ms): 6757.1 | learning rate: 5.982E-05 | global batch size:    32 | lm loss: 1.264741E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration      998/  500000 | consumed samples:        31936 | consumed tokens:    130809856 | elapsed time per iteration (ms): 6761.0 | learning rate: 5.988E-05 | global batch size:    32 | lm loss: 1.260261E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration      999/  500000 | consumed samples:        31968 | consumed tokens:    130940928 | elapsed time per iteration (ms): 6760.4 | learning rate: 5.994E-05 | global batch size:    32 | lm loss: 1.299992E-01 | loss scale: 256.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
[2023-10-10 17:02:37,483] [INFO] [logging.py:96:log_dist] [Rank 0] step=1000, skipped=0, lr=[5.9999999999999995e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:02:37,743] [INFO] [timer.py:208:stop] epoch=0/micro_step=1000/global_step=1000, RunningAvgSamplesPerSec=4.742927146522936, CurrSamplesPerSec=4.74249122878678, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1000/  500000 | consumed samples:        32000 | consumed tokens:    131072000 | elapsed time per iteration (ms): 6760.1 | learning rate: 6.000E-05 | global batch size:    32 | lm loss: 1.250373E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
------------------------------------------------------------------------------------------------
 validation loss at iteration 1000 | lm loss value: 1.586414E+00 | lm loss PPL: 4.886196E+00 | 
------------------------------------------------------------------------------------------------
 iteration     1001/  500000 | consumed samples:        32032 | consumed tokens:    131203072 | elapsed time per iteration (ms): 21487.6 | learning rate: 6.006E-05 | global batch size:    32 | lm loss: 1.274156E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.489 | TFLOPs: 46.45 |
time (ms)
 iteration     1002/  500000 | consumed samples:        32064 | consumed tokens:    131334144 | elapsed time per iteration (ms): 6758.2 | learning rate: 6.012E-05 | global batch size:    32 | lm loss: 1.270498E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1003/  500000 | consumed samples:        32096 | consumed tokens:    131465216 | elapsed time per iteration (ms): 6762.3 | learning rate: 6.018E-05 | global batch size:    32 | lm loss: 1.294403E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1004/  500000 | consumed samples:        32128 | consumed tokens:    131596288 | elapsed time per iteration (ms): 6757.8 | learning rate: 6.024E-05 | global batch size:    32 | lm loss: 1.255923E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1005/  500000 | consumed samples:        32160 | consumed tokens:    131727360 | elapsed time per iteration (ms): 6759.7 | learning rate: 6.030E-05 | global batch size:    32 | lm loss: 1.273699E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1006/  500000 | consumed samples:        32192 | consumed tokens:    131858432 | elapsed time per iteration (ms): 6760.8 | learning rate: 6.036E-05 | global batch size:    32 | lm loss: 1.284476E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1007/  500000 | consumed samples:        32224 | consumed tokens:    131989504 | elapsed time per iteration (ms): 6762.7 | learning rate: 6.042E-05 | global batch size:    32 | lm loss: 1.304180E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1008/  500000 | consumed samples:        32256 | consumed tokens:    132120576 | elapsed time per iteration (ms): 6758.5 | learning rate: 6.048E-05 | global batch size:    32 | lm loss: 1.219170E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1009/  500000 | consumed samples:        32288 | consumed tokens:    132251648 | elapsed time per iteration (ms): 6761.5 | learning rate: 6.054E-05 | global batch size:    32 | lm loss: 1.260735E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
[2023-10-10 17:03:59,856] [INFO] [logging.py:96:log_dist] [Rank 0] step=1010, skipped=0, lr=[6.0599999999999996e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:04:00,115] [INFO] [timer.py:208:stop] epoch=0/micro_step=1010/global_step=1010, RunningAvgSamplesPerSec=4.742921387444574, CurrSamplesPerSec=4.741558367692138, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1010/  500000 | consumed samples:        32320 | consumed tokens:    132382720 | elapsed time per iteration (ms): 6762.0 | learning rate: 6.060E-05 | global batch size:    32 | lm loss: 1.226314E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1011/  500000 | consumed samples:        32352 | consumed tokens:    132513792 | elapsed time per iteration (ms): 6758.9 | learning rate: 6.066E-05 | global batch size:    32 | lm loss: 1.243896E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1012/  500000 | consumed samples:        32384 | consumed tokens:    132644864 | elapsed time per iteration (ms): 6759.4 | learning rate: 6.072E-05 | global batch size:    32 | lm loss: 1.263102E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1013/  500000 | consumed samples:        32416 | consumed tokens:    132775936 | elapsed time per iteration (ms): 6761.7 | learning rate: 6.078E-05 | global batch size:    32 | lm loss: 1.297728E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     1014/  500000 | consumed samples:        32448 | consumed tokens:    132907008 | elapsed time per iteration (ms): 6764.7 | learning rate: 6.084E-05 | global batch size:    32 | lm loss: 1.232585E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration     1015/  500000 | consumed samples:        32480 | consumed tokens:    133038080 | elapsed time per iteration (ms): 6761.4 | learning rate: 6.090E-05 | global batch size:    32 | lm loss: 1.296989E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1016/  500000 | consumed samples:        32512 | consumed tokens:    133169152 | elapsed time per iteration (ms): 6760.6 | learning rate: 6.096E-05 | global batch size:    32 | lm loss: 1.261495E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1017/  500000 | consumed samples:        32544 | consumed tokens:    133300224 | elapsed time per iteration (ms): 6759.7 | learning rate: 6.102E-05 | global batch size:    32 | lm loss: 1.245964E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1018/  500000 | consumed samples:        32576 | consumed tokens:    133431296 | elapsed time per iteration (ms): 6758.9 | learning rate: 6.108E-05 | global batch size:    32 | lm loss: 1.264773E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1019/  500000 | consumed samples:        32608 | consumed tokens:    133562368 | elapsed time per iteration (ms): 6761.0 | learning rate: 6.114E-05 | global batch size:    32 | lm loss: 1.249391E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
[2023-10-10 17:05:07,527] [INFO] [logging.py:96:log_dist] [Rank 0] step=1020, skipped=0, lr=[6.12e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:05:07,768] [INFO] [timer.py:208:stop] epoch=0/micro_step=1020/global_step=1020, RunningAvgSamplesPerSec=4.742912236853407, CurrSamplesPerSec=4.739596168411981, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1020/  500000 | consumed samples:        32640 | consumed tokens:    133693440 | elapsed time per iteration (ms): 6764.2 | learning rate: 6.120E-05 | global batch size:    32 | lm loss: 1.260479E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     1021/  500000 | consumed samples:        32672 | consumed tokens:    133824512 | elapsed time per iteration (ms): 6761.3 | learning rate: 6.126E-05 | global batch size:    32 | lm loss: 1.276525E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1022/  500000 | consumed samples:        32704 | consumed tokens:    133955584 | elapsed time per iteration (ms): 6760.8 | learning rate: 6.132E-05 | global batch size:    32 | lm loss: 1.239576E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1023/  500000 | consumed samples:        32736 | consumed tokens:    134086656 | elapsed time per iteration (ms): 6758.7 | learning rate: 6.138E-05 | global batch size:    32 | lm loss: 1.231375E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1024/  500000 | consumed samples:        32768 | consumed tokens:    134217728 | elapsed time per iteration (ms): 6760.7 | learning rate: 6.144E-05 | global batch size:    32 | lm loss: 1.234542E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1025/  500000 | consumed samples:        32800 | consumed tokens:    134348800 | elapsed time per iteration (ms): 6759.8 | learning rate: 6.150E-05 | global batch size:    32 | lm loss: 1.273793E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1026/  500000 | consumed samples:        32832 | consumed tokens:    134479872 | elapsed time per iteration (ms): 6756.2 | learning rate: 6.156E-05 | global batch size:    32 | lm loss: 1.263960E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1027/  500000 | consumed samples:        32864 | consumed tokens:    134610944 | elapsed time per iteration (ms): 6757.1 | learning rate: 6.162E-05 | global batch size:    32 | lm loss: 1.259708E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1028/  500000 | consumed samples:        32896 | consumed tokens:    134742016 | elapsed time per iteration (ms): 6760.2 | learning rate: 6.168E-05 | global batch size:    32 | lm loss: 1.276758E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1029/  500000 | consumed samples:        32928 | consumed tokens:    134873088 | elapsed time per iteration (ms): 6761.3 | learning rate: 6.174E-05 | global batch size:    32 | lm loss: 1.255294E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
[2023-10-10 17:06:15,143] [INFO] [logging.py:96:log_dist] [Rank 0] step=1030, skipped=0, lr=[6.18e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:06:15,404] [INFO] [timer.py:208:stop] epoch=0/micro_step=1030/global_step=1030, RunningAvgSamplesPerSec=4.742915266631128, CurrSamplesPerSec=4.744556455468587, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1030/  500000 | consumed samples:        32960 | consumed tokens:    135004160 | elapsed time per iteration (ms): 6758.0 | learning rate: 6.180E-05 | global batch size:    32 | lm loss: 1.242616E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1031/  500000 | consumed samples:        32992 | consumed tokens:    135135232 | elapsed time per iteration (ms): 6757.7 | learning rate: 6.186E-05 | global batch size:    32 | lm loss: 1.248461E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1032/  500000 | consumed samples:        33024 | consumed tokens:    135266304 | elapsed time per iteration (ms): 6753.8 | learning rate: 6.192E-05 | global batch size:    32 | lm loss: 1.268995E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.738 | TFLOPs: 147.78 |
time (ms)
 iteration     1033/  500000 | consumed samples:        33056 | consumed tokens:    135397376 | elapsed time per iteration (ms): 6763.5 | learning rate: 6.198E-05 | global batch size:    32 | lm loss: 1.250758E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     1034/  500000 | consumed samples:        33088 | consumed tokens:    135528448 | elapsed time per iteration (ms): 6758.9 | learning rate: 6.204E-05 | global batch size:    32 | lm loss: 1.233197E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1035/  500000 | consumed samples:        33120 | consumed tokens:    135659520 | elapsed time per iteration (ms): 6758.2 | learning rate: 6.210E-05 | global batch size:    32 | lm loss: 1.262897E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1036/  500000 | consumed samples:        33152 | consumed tokens:    135790592 | elapsed time per iteration (ms): 6758.4 | learning rate: 6.216E-05 | global batch size:    32 | lm loss: 1.290593E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1037/  500000 | consumed samples:        33184 | consumed tokens:    135921664 | elapsed time per iteration (ms): 6761.2 | learning rate: 6.222E-05 | global batch size:    32 | lm loss: 1.255614E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1038/  500000 | consumed samples:        33216 | consumed tokens:    136052736 | elapsed time per iteration (ms): 6758.2 | learning rate: 6.228E-05 | global batch size:    32 | lm loss: 1.207196E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1039/  500000 | consumed samples:        33248 | consumed tokens:    136183808 | elapsed time per iteration (ms): 6758.4 | learning rate: 6.234E-05 | global batch size:    32 | lm loss: 1.270283E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
[2023-10-10 17:07:22,784] [INFO] [logging.py:96:log_dist] [Rank 0] step=1040, skipped=0, lr=[6.24e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:07:23,036] [INFO] [timer.py:208:stop] epoch=0/micro_step=1040/global_step=1040, RunningAvgSamplesPerSec=4.742920839917631, CurrSamplesPerSec=4.741103128050667, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1040/  500000 | consumed samples:        33280 | consumed tokens:    136314880 | elapsed time per iteration (ms): 6762.0 | learning rate: 6.240E-05 | global batch size:    32 | lm loss: 1.224199E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1041/  500000 | consumed samples:        33312 | consumed tokens:    136445952 | elapsed time per iteration (ms): 6760.5 | learning rate: 6.246E-05 | global batch size:    32 | lm loss: 1.248728E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1042/  500000 | consumed samples:        33344 | consumed tokens:    136577024 | elapsed time per iteration (ms): 6759.2 | learning rate: 6.252E-05 | global batch size:    32 | lm loss: 1.275606E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1043/  500000 | consumed samples:        33376 | consumed tokens:    136708096 | elapsed time per iteration (ms): 6760.6 | learning rate: 6.258E-05 | global batch size:    32 | lm loss: 1.220538E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1044/  500000 | consumed samples:        33408 | consumed tokens:    136839168 | elapsed time per iteration (ms): 6756.0 | learning rate: 6.264E-05 | global batch size:    32 | lm loss: 1.270415E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration     1045/  500000 | consumed samples:        33440 | consumed tokens:    136970240 | elapsed time per iteration (ms): 6758.3 | learning rate: 6.270E-05 | global batch size:    32 | lm loss: 1.231033E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1046/  500000 | consumed samples:        33472 | consumed tokens:    137101312 | elapsed time per iteration (ms): 6764.6 | learning rate: 6.276E-05 | global batch size:    32 | lm loss: 1.249447E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration     1047/  500000 | consumed samples:        33504 | consumed tokens:    137232384 | elapsed time per iteration (ms): 6756.6 | learning rate: 6.282E-05 | global batch size:    32 | lm loss: 1.213110E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1048/  500000 | consumed samples:        33536 | consumed tokens:    137363456 | elapsed time per iteration (ms): 6759.0 | learning rate: 6.288E-05 | global batch size:    32 | lm loss: 1.304882E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1049/  500000 | consumed samples:        33568 | consumed tokens:    137494528 | elapsed time per iteration (ms): 6763.4 | learning rate: 6.294E-05 | global batch size:    32 | lm loss: 1.249619E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
[2023-10-10 17:08:30,450] [INFO] [logging.py:96:log_dist] [Rank 0] step=1050, skipped=0, lr=[6.299999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:08:30,679] [INFO] [timer.py:208:stop] epoch=0/micro_step=1050/global_step=1050, RunningAvgSamplesPerSec=4.742916424512517, CurrSamplesPerSec=4.740443872275686, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1050/  500000 | consumed samples:        33600 | consumed tokens:    137625600 | elapsed time per iteration (ms): 6762.9 | learning rate: 6.300E-05 | global batch size:    32 | lm loss: 1.244380E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1051/  500000 | consumed samples:        33632 | consumed tokens:    137756672 | elapsed time per iteration (ms): 6759.5 | learning rate: 6.306E-05 | global batch size:    32 | lm loss: 1.256361E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1052/  500000 | consumed samples:        33664 | consumed tokens:    137887744 | elapsed time per iteration (ms): 6758.7 | learning rate: 6.312E-05 | global batch size:    32 | lm loss: 1.264241E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1053/  500000 | consumed samples:        33696 | consumed tokens:    138018816 | elapsed time per iteration (ms): 6759.5 | learning rate: 6.318E-05 | global batch size:    32 | lm loss: 1.246356E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1054/  500000 | consumed samples:        33728 | consumed tokens:    138149888 | elapsed time per iteration (ms): 6763.9 | learning rate: 6.324E-05 | global batch size:    32 | lm loss: 1.230258E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     1055/  500000 | consumed samples:        33760 | consumed tokens:    138280960 | elapsed time per iteration (ms): 6759.9 | learning rate: 6.330E-05 | global batch size:    32 | lm loss: 1.261193E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1056/  500000 | consumed samples:        33792 | consumed tokens:    138412032 | elapsed time per iteration (ms): 6759.0 | learning rate: 6.336E-05 | global batch size:    32 | lm loss: 1.227180E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1057/  500000 | consumed samples:        33824 | consumed tokens:    138543104 | elapsed time per iteration (ms): 6759.2 | learning rate: 6.342E-05 | global batch size:    32 | lm loss: 1.260472E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1058/  500000 | consumed samples:        33856 | consumed tokens:    138674176 | elapsed time per iteration (ms): 6764.6 | learning rate: 6.348E-05 | global batch size:    32 | lm loss: 1.229980E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.54 |
time (ms)
 iteration     1059/  500000 | consumed samples:        33888 | consumed tokens:    138805248 | elapsed time per iteration (ms): 6757.4 | learning rate: 6.354E-05 | global batch size:    32 | lm loss: 1.231379E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
[2023-10-10 17:09:38,083] [INFO] [logging.py:96:log_dist] [Rank 0] step=1060, skipped=0, lr=[6.359999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:09:38,321] [INFO] [timer.py:208:stop] epoch=0/micro_step=1060/global_step=1060, RunningAvgSamplesPerSec=4.742914277592948, CurrSamplesPerSec=4.744027697503628, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1060/  500000 | consumed samples:        33920 | consumed tokens:    138936320 | elapsed time per iteration (ms): 6758.7 | learning rate: 6.360E-05 | global batch size:    32 | lm loss: 1.259853E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1061/  500000 | consumed samples:        33952 | consumed tokens:    139067392 | elapsed time per iteration (ms): 6757.5 | learning rate: 6.366E-05 | global batch size:    32 | lm loss: 1.239138E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1062/  500000 | consumed samples:        33984 | consumed tokens:    139198464 | elapsed time per iteration (ms): 6760.3 | learning rate: 6.372E-05 | global batch size:    32 | lm loss: 1.210763E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration     1063/  500000 | consumed samples:        34016 | consumed tokens:    139329536 | elapsed time per iteration (ms): 6757.6 | learning rate: 6.378E-05 | global batch size:    32 | lm loss: 1.276119E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1064/  500000 | consumed samples:        34048 | consumed tokens:    139460608 | elapsed time per iteration (ms): 6758.0 | learning rate: 6.384E-05 | global batch size:    32 | lm loss: 1.229474E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1065/  500000 | consumed samples:        34080 | consumed tokens:    139591680 | elapsed time per iteration (ms): 6759.1 | learning rate: 6.390E-05 | global batch size:    32 | lm loss: 1.202493E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1066/  500000 | consumed samples:        34112 | consumed tokens:    139722752 | elapsed time per iteration (ms): 6758.0 | learning rate: 6.396E-05 | global batch size:    32 | lm loss: 1.231875E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1067/  500000 | consumed samples:        34144 | consumed tokens:    139853824 | elapsed time per iteration (ms): 6758.7 | learning rate: 6.402E-05 | global batch size:    32 | lm loss: 1.215186E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1068/  500000 | consumed samples:        34176 | consumed tokens:    139984896 | elapsed time per iteration (ms): 6756.7 | learning rate: 6.408E-05 | global batch size:    32 | lm loss: 1.199814E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1069/  500000 | consumed samples:        34208 | consumed tokens:    140115968 | elapsed time per iteration (ms): 6756.1 | learning rate: 6.414E-05 | global batch size:    32 | lm loss: 1.234593E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.73 |
time (ms)
[2023-10-10 17:10:45,697] [INFO] [logging.py:96:log_dist] [Rank 0] step=1070, skipped=0, lr=[6.419999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:10:45,945] [INFO] [timer.py:208:stop] epoch=0/micro_step=1070/global_step=1070, RunningAvgSamplesPerSec=4.742925017922431, CurrSamplesPerSec=4.742986792950562, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1070/  500000 | consumed samples:        34240 | consumed tokens:    140247040 | elapsed time per iteration (ms): 6760.0 | learning rate: 6.420E-05 | global batch size:    32 | lm loss: 1.267163E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1071/  500000 | consumed samples:        34272 | consumed tokens:    140378112 | elapsed time per iteration (ms): 6759.1 | learning rate: 6.426E-05 | global batch size:    32 | lm loss: 1.238978E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1072/  500000 | consumed samples:        34304 | consumed tokens:    140509184 | elapsed time per iteration (ms): 6758.4 | learning rate: 6.432E-05 | global batch size:    32 | lm loss: 1.224679E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1073/  500000 | consumed samples:        34336 | consumed tokens:    140640256 | elapsed time per iteration (ms): 6758.9 | learning rate: 6.438E-05 | global batch size:    32 | lm loss: 1.224488E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1074/  500000 | consumed samples:        34368 | consumed tokens:    140771328 | elapsed time per iteration (ms): 6760.1 | learning rate: 6.444E-05 | global batch size:    32 | lm loss: 1.232839E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1075/  500000 | consumed samples:        34400 | consumed tokens:    140902400 | elapsed time per iteration (ms): 6758.2 | learning rate: 6.450E-05 | global batch size:    32 | lm loss: 1.247712E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1076/  500000 | consumed samples:        34432 | consumed tokens:    141033472 | elapsed time per iteration (ms): 6758.2 | learning rate: 6.456E-05 | global batch size:    32 | lm loss: 1.261655E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1077/  500000 | consumed samples:        34464 | consumed tokens:    141164544 | elapsed time per iteration (ms): 6757.6 | learning rate: 6.462E-05 | global batch size:    32 | lm loss: 1.231310E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1078/  500000 | consumed samples:        34496 | consumed tokens:    141295616 | elapsed time per iteration (ms): 6755.7 | learning rate: 6.468E-05 | global batch size:    32 | lm loss: 1.265413E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration     1079/  500000 | consumed samples:        34528 | consumed tokens:    141426688 | elapsed time per iteration (ms): 6759.2 | learning rate: 6.474E-05 | global batch size:    32 | lm loss: 1.294528E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
[2023-10-10 17:11:53,309] [INFO] [logging.py:96:log_dist] [Rank 0] step=1080, skipped=0, lr=[6.479999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:11:53,568] [INFO] [timer.py:208:stop] epoch=0/micro_step=1080/global_step=1080, RunningAvgSamplesPerSec=4.742936627317066, CurrSamplesPerSec=4.745882977599421, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1080/  500000 | consumed samples:        34560 | consumed tokens:    141557760 | elapsed time per iteration (ms): 6755.2 | learning rate: 6.480E-05 | global batch size:    32 | lm loss: 1.246661E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.75 |
time (ms)
 iteration     1081/  500000 | consumed samples:        34592 | consumed tokens:    141688832 | elapsed time per iteration (ms): 6757.9 | learning rate: 6.486E-05 | global batch size:    32 | lm loss: 1.235117E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1082/  500000 | consumed samples:        34624 | consumed tokens:    141819904 | elapsed time per iteration (ms): 6758.4 | learning rate: 6.492E-05 | global batch size:    32 | lm loss: 1.249139E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1083/  500000 | consumed samples:        34656 | consumed tokens:    141950976 | elapsed time per iteration (ms): 6756.8 | learning rate: 6.498E-05 | global batch size:    32 | lm loss: 1.199969E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1084/  500000 | consumed samples:        34688 | consumed tokens:    142082048 | elapsed time per iteration (ms): 6756.1 | learning rate: 6.504E-05 | global batch size:    32 | lm loss: 1.257730E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.73 |
time (ms)
 iteration     1085/  500000 | consumed samples:        34720 | consumed tokens:    142213120 | elapsed time per iteration (ms): 6757.4 | learning rate: 6.510E-05 | global batch size:    32 | lm loss: 1.265067E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1086/  500000 | consumed samples:        34752 | consumed tokens:    142344192 | elapsed time per iteration (ms): 6755.9 | learning rate: 6.516E-05 | global batch size:    32 | lm loss: 1.278312E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration     1087/  500000 | consumed samples:        34784 | consumed tokens:    142475264 | elapsed time per iteration (ms): 6758.2 | learning rate: 6.522E-05 | global batch size:    32 | lm loss: 1.212409E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1088/  500000 | consumed samples:        34816 | consumed tokens:    142606336 | elapsed time per iteration (ms): 6764.7 | learning rate: 6.528E-05 | global batch size:    32 | lm loss: 1.259031E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration     1089/  500000 | consumed samples:        34848 | consumed tokens:    142737408 | elapsed time per iteration (ms): 6762.3 | learning rate: 6.534E-05 | global batch size:    32 | lm loss: 1.266335E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
[2023-10-10 17:13:00,939] [INFO] [logging.py:96:log_dist] [Rank 0] step=1090, skipped=0, lr=[6.539999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:13:01,200] [INFO] [timer.py:208:stop] epoch=0/micro_step=1090/global_step=1090, RunningAvgSamplesPerSec=4.742940666622125, CurrSamplesPerSec=4.740471163199645, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1090/  500000 | consumed samples:        34880 | consumed tokens:    142868480 | elapsed time per iteration (ms): 6762.5 | learning rate: 6.540E-05 | global batch size:    32 | lm loss: 1.208062E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1091/  500000 | consumed samples:        34912 | consumed tokens:    142999552 | elapsed time per iteration (ms): 6759.2 | learning rate: 6.546E-05 | global batch size:    32 | lm loss: 1.223102E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1092/  500000 | consumed samples:        34944 | consumed tokens:    143130624 | elapsed time per iteration (ms): 6754.7 | learning rate: 6.552E-05 | global batch size:    32 | lm loss: 1.262969E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.76 |
time (ms)
 iteration     1093/  500000 | consumed samples:        34976 | consumed tokens:    143261696 | elapsed time per iteration (ms): 6758.9 | learning rate: 6.558E-05 | global batch size:    32 | lm loss: 1.243827E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.66 |
time (ms)
 iteration     1094/  500000 | consumed samples:        35008 | consumed tokens:    143392768 | elapsed time per iteration (ms): 6758.4 | learning rate: 6.564E-05 | global batch size:    32 | lm loss: 1.254943E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1095/  500000 | consumed samples:        35040 | consumed tokens:    143523840 | elapsed time per iteration (ms): 6763.1 | learning rate: 6.570E-05 | global batch size:    32 | lm loss: 1.226864E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration     1096/  500000 | consumed samples:        35072 | consumed tokens:    143654912 | elapsed time per iteration (ms): 6760.7 | learning rate: 6.576E-05 | global batch size:    32 | lm loss: 1.225783E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1097/  500000 | consumed samples:        35104 | consumed tokens:    143785984 | elapsed time per iteration (ms): 6762.4 | learning rate: 6.582E-05 | global batch size:    32 | lm loss: 1.232710E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1098/  500000 | consumed samples:        35136 | consumed tokens:    143917056 | elapsed time per iteration (ms): 6758.3 | learning rate: 6.588E-05 | global batch size:    32 | lm loss: 1.254774E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1099/  500000 | consumed samples:        35168 | consumed tokens:    144048128 | elapsed time per iteration (ms): 6762.1 | learning rate: 6.594E-05 | global batch size:    32 | lm loss: 1.173543E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
[2023-10-10 17:14:08,578] [INFO] [logging.py:96:log_dist] [Rank 0] step=1100, skipped=0, lr=[6.599999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:14:08,836] [INFO] [timer.py:208:stop] epoch=0/micro_step=1100/global_step=1100, RunningAvgSamplesPerSec=4.742941847954027, CurrSamplesPerSec=4.74411774405359, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1100/  500000 | consumed samples:        35200 | consumed tokens:    144179200 | elapsed time per iteration (ms): 6757.4 | learning rate: 6.600E-05 | global batch size:    32 | lm loss: 1.226214E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1101/  500000 | consumed samples:        35232 | consumed tokens:    144310272 | elapsed time per iteration (ms): 6758.2 | learning rate: 6.606E-05 | global batch size:    32 | lm loss: 1.209425E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1102/  500000 | consumed samples:        35264 | consumed tokens:    144441344 | elapsed time per iteration (ms): 6760.4 | learning rate: 6.612E-05 | global batch size:    32 | lm loss: 1.200215E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1103/  500000 | consumed samples:        35296 | consumed tokens:    144572416 | elapsed time per iteration (ms): 6758.6 | learning rate: 6.618E-05 | global batch size:    32 | lm loss: 1.230332E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1104/  500000 | consumed samples:        35328 | consumed tokens:    144703488 | elapsed time per iteration (ms): 6756.2 | learning rate: 6.624E-05 | global batch size:    32 | lm loss: 1.231805E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1105/  500000 | consumed samples:        35360 | consumed tokens:    144834560 | elapsed time per iteration (ms): 6756.8 | learning rate: 6.630E-05 | global batch size:    32 | lm loss: 1.193228E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1106/  500000 | consumed samples:        35392 | consumed tokens:    144965632 | elapsed time per iteration (ms): 6757.1 | learning rate: 6.636E-05 | global batch size:    32 | lm loss: 1.237122E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1107/  500000 | consumed samples:        35424 | consumed tokens:    145096704 | elapsed time per iteration (ms): 6762.3 | learning rate: 6.642E-05 | global batch size:    32 | lm loss: 1.206332E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1108/  500000 | consumed samples:        35456 | consumed tokens:    145227776 | elapsed time per iteration (ms): 6757.1 | learning rate: 6.648E-05 | global batch size:    32 | lm loss: 1.238757E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1109/  500000 | consumed samples:        35488 | consumed tokens:    145358848 | elapsed time per iteration (ms): 6757.3 | learning rate: 6.654E-05 | global batch size:    32 | lm loss: 1.249126E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
[2023-10-10 17:15:16,210] [INFO] [logging.py:96:log_dist] [Rank 0] step=1110, skipped=0, lr=[6.659999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:15:16,460] [INFO] [timer.py:208:stop] epoch=0/micro_step=1110/global_step=1110, RunningAvgSamplesPerSec=4.742950530214336, CurrSamplesPerSec=4.743515654184716, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1110/  500000 | consumed samples:        35520 | consumed tokens:    145489920 | elapsed time per iteration (ms): 6758.7 | learning rate: 6.660E-05 | global batch size:    32 | lm loss: 1.266028E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1111/  500000 | consumed samples:        35552 | consumed tokens:    145620992 | elapsed time per iteration (ms): 6756.7 | learning rate: 6.666E-05 | global batch size:    32 | lm loss: 1.208193E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1112/  500000 | consumed samples:        35584 | consumed tokens:    145752064 | elapsed time per iteration (ms): 6756.0 | learning rate: 6.672E-05 | global batch size:    32 | lm loss: 1.227164E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration     1113/  500000 | consumed samples:        35616 | consumed tokens:    145883136 | elapsed time per iteration (ms): 6756.8 | learning rate: 6.678E-05 | global batch size:    32 | lm loss: 1.226231E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1114/  500000 | consumed samples:        35648 | consumed tokens:    146014208 | elapsed time per iteration (ms): 6764.0 | learning rate: 6.684E-05 | global batch size:    32 | lm loss: 1.211617E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     1115/  500000 | consumed samples:        35680 | consumed tokens:    146145280 | elapsed time per iteration (ms): 6763.0 | learning rate: 6.690E-05 | global batch size:    32 | lm loss: 1.232528E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1116/  500000 | consumed samples:        35712 | consumed tokens:    146276352 | elapsed time per iteration (ms): 6759.0 | learning rate: 6.696E-05 | global batch size:    32 | lm loss: 1.250186E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1117/  500000 | consumed samples:        35744 | consumed tokens:    146407424 | elapsed time per iteration (ms): 6759.3 | learning rate: 6.702E-05 | global batch size:    32 | lm loss: 1.223412E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1118/  500000 | consumed samples:        35776 | consumed tokens:    146538496 | elapsed time per iteration (ms): 6764.5 | learning rate: 6.708E-05 | global batch size:    32 | lm loss: 1.190768E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.54 |
time (ms)
 iteration     1119/  500000 | consumed samples:        35808 | consumed tokens:    146669568 | elapsed time per iteration (ms): 6763.9 | learning rate: 6.714E-05 | global batch size:    32 | lm loss: 1.200370E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
[2023-10-10 17:16:23,856] [INFO] [logging.py:96:log_dist] [Rank 0] step=1120, skipped=0, lr=[6.72e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:16:24,105] [INFO] [timer.py:208:stop] epoch=0/micro_step=1120/global_step=1120, RunningAvgSamplesPerSec=4.742951009577796, CurrSamplesPerSec=4.741854705656805, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1120/  500000 | consumed samples:        35840 | consumed tokens:    146800640 | elapsed time per iteration (ms): 6760.8 | learning rate: 6.720E-05 | global batch size:    32 | lm loss: 1.185494E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1121/  500000 | consumed samples:        35872 | consumed tokens:    146931712 | elapsed time per iteration (ms): 6760.9 | learning rate: 6.726E-05 | global batch size:    32 | lm loss: 1.257391E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1122/  500000 | consumed samples:        35904 | consumed tokens:    147062784 | elapsed time per iteration (ms): 6756.0 | learning rate: 6.732E-05 | global batch size:    32 | lm loss: 1.227269E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration     1123/  500000 | consumed samples:        35936 | consumed tokens:    147193856 | elapsed time per iteration (ms): 6761.1 | learning rate: 6.738E-05 | global batch size:    32 | lm loss: 1.194675E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1124/  500000 | consumed samples:        35968 | consumed tokens:    147324928 | elapsed time per iteration (ms): 6754.9 | learning rate: 6.744E-05 | global batch size:    32 | lm loss: 1.198620E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.75 |
time (ms)
 iteration     1125/  500000 | consumed samples:        36000 | consumed tokens:    147456000 | elapsed time per iteration (ms): 6757.3 | learning rate: 6.750E-05 | global batch size:    32 | lm loss: 1.221818E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1126/  500000 | consumed samples:        36032 | consumed tokens:    147587072 | elapsed time per iteration (ms): 6755.4 | learning rate: 6.756E-05 | global batch size:    32 | lm loss: 1.240807E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration     1127/  500000 | consumed samples:        36064 | consumed tokens:    147718144 | elapsed time per iteration (ms): 6762.0 | learning rate: 6.762E-05 | global batch size:    32 | lm loss: 1.193650E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1128/  500000 | consumed samples:        36096 | consumed tokens:    147849216 | elapsed time per iteration (ms): 6757.8 | learning rate: 6.768E-05 | global batch size:    32 | lm loss: 1.210341E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1129/  500000 | consumed samples:        36128 | consumed tokens:    147980288 | elapsed time per iteration (ms): 6760.5 | learning rate: 6.774E-05 | global batch size:    32 | lm loss: 1.222127E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
[2023-10-10 17:17:31,470] [INFO] [logging.py:96:log_dist] [Rank 0] step=1130, skipped=0, lr=[6.78e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:17:31,727] [INFO] [timer.py:208:stop] epoch=0/micro_step=1130/global_step=1130, RunningAvgSamplesPerSec=4.742959952246061, CurrSamplesPerSec=4.745989037435462, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1130/  500000 | consumed samples:        36160 | consumed tokens:    148111360 | elapsed time per iteration (ms): 6754.9 | learning rate: 6.780E-05 | global batch size:    32 | lm loss: 1.200813E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.75 |
time (ms)
 iteration     1131/  500000 | consumed samples:        36192 | consumed tokens:    148242432 | elapsed time per iteration (ms): 6760.2 | learning rate: 6.786E-05 | global batch size:    32 | lm loss: 1.216681E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1132/  500000 | consumed samples:        36224 | consumed tokens:    148373504 | elapsed time per iteration (ms): 6759.0 | learning rate: 6.792E-05 | global batch size:    32 | lm loss: 1.201747E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1133/  500000 | consumed samples:        36256 | consumed tokens:    148504576 | elapsed time per iteration (ms): 6758.9 | learning rate: 6.798E-05 | global batch size:    32 | lm loss: 1.254277E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1134/  500000 | consumed samples:        36288 | consumed tokens:    148635648 | elapsed time per iteration (ms): 6756.1 | learning rate: 6.804E-05 | global batch size:    32 | lm loss: 1.194740E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1135/  500000 | consumed samples:        36320 | consumed tokens:    148766720 | elapsed time per iteration (ms): 6757.7 | learning rate: 6.810E-05 | global batch size:    32 | lm loss: 1.226578E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1136/  500000 | consumed samples:        36352 | consumed tokens:    148897792 | elapsed time per iteration (ms): 6758.1 | learning rate: 6.816E-05 | global batch size:    32 | lm loss: 1.197889E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1137/  500000 | consumed samples:        36384 | consumed tokens:    149028864 | elapsed time per iteration (ms): 6758.1 | learning rate: 6.822E-05 | global batch size:    32 | lm loss: 1.187120E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1138/  500000 | consumed samples:        36416 | consumed tokens:    149159936 | elapsed time per iteration (ms): 6761.2 | learning rate: 6.828E-05 | global batch size:    32 | lm loss: 1.229587E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1139/  500000 | consumed samples:        36448 | consumed tokens:    149291008 | elapsed time per iteration (ms): 6757.4 | learning rate: 6.834E-05 | global batch size:    32 | lm loss: 1.225477E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
[2023-10-10 17:18:39,113] [INFO] [logging.py:96:log_dist] [Rank 0] step=1140, skipped=0, lr=[6.84e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:18:39,355] [INFO] [timer.py:208:stop] epoch=0/micro_step=1140/global_step=1140, RunningAvgSamplesPerSec=4.742965988331928, CurrSamplesPerSec=4.742500612874874, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1140/  500000 | consumed samples:        36480 | consumed tokens:    149422080 | elapsed time per iteration (ms): 6759.9 | learning rate: 6.840E-05 | global batch size:    32 | lm loss: 1.234816E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1141/  500000 | consumed samples:        36512 | consumed tokens:    149553152 | elapsed time per iteration (ms): 6760.9 | learning rate: 6.846E-05 | global batch size:    32 | lm loss: 1.206113E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1142/  500000 | consumed samples:        36544 | consumed tokens:    149684224 | elapsed time per iteration (ms): 6762.2 | learning rate: 6.852E-05 | global batch size:    32 | lm loss: 1.212941E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1143/  500000 | consumed samples:        36576 | consumed tokens:    149815296 | elapsed time per iteration (ms): 6759.4 | learning rate: 6.858E-05 | global batch size:    32 | lm loss: 1.218805E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1144/  500000 | consumed samples:        36608 | consumed tokens:    149946368 | elapsed time per iteration (ms): 6758.2 | learning rate: 6.864E-05 | global batch size:    32 | lm loss: 1.211290E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1145/  500000 | consumed samples:        36640 | consumed tokens:    150077440 | elapsed time per iteration (ms): 6756.9 | learning rate: 6.870E-05 | global batch size:    32 | lm loss: 1.194098E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1146/  500000 | consumed samples:        36672 | consumed tokens:    150208512 | elapsed time per iteration (ms): 6760.1 | learning rate: 6.876E-05 | global batch size:    32 | lm loss: 1.284518E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1147/  500000 | consumed samples:        36704 | consumed tokens:    150339584 | elapsed time per iteration (ms): 6760.4 | learning rate: 6.882E-05 | global batch size:    32 | lm loss: 1.195309E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1148/  500000 | consumed samples:        36736 | consumed tokens:    150470656 | elapsed time per iteration (ms): 6760.6 | learning rate: 6.888E-05 | global batch size:    32 | lm loss: 1.233209E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1149/  500000 | consumed samples:        36768 | consumed tokens:    150601728 | elapsed time per iteration (ms): 6757.3 | learning rate: 6.894E-05 | global batch size:    32 | lm loss: 1.222311E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
[2023-10-10 17:19:46,733] [INFO] [logging.py:96:log_dist] [Rank 0] step=1150, skipped=0, lr=[6.9e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:19:46,990] [INFO] [timer.py:208:stop] epoch=0/micro_step=1150/global_step=1150, RunningAvgSamplesPerSec=4.742967499602409, CurrSamplesPerSec=4.744696504674005, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1150/  500000 | consumed samples:        36800 | consumed tokens:    150732800 | elapsed time per iteration (ms): 6756.7 | learning rate: 6.900E-05 | global batch size:    32 | lm loss: 1.206395E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1151/  500000 | consumed samples:        36832 | consumed tokens:    150863872 | elapsed time per iteration (ms): 6759.9 | learning rate: 6.906E-05 | global batch size:    32 | lm loss: 1.231890E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1152/  500000 | consumed samples:        36864 | consumed tokens:    150994944 | elapsed time per iteration (ms): 6759.7 | learning rate: 6.912E-05 | global batch size:    32 | lm loss: 1.217251E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1153/  500000 | consumed samples:        36896 | consumed tokens:    151126016 | elapsed time per iteration (ms): 6756.4 | learning rate: 6.918E-05 | global batch size:    32 | lm loss: 1.185708E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1154/  500000 | consumed samples:        36928 | consumed tokens:    151257088 | elapsed time per iteration (ms): 6756.4 | learning rate: 6.924E-05 | global batch size:    32 | lm loss: 1.194405E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1155/  500000 | consumed samples:        36960 | consumed tokens:    151388160 | elapsed time per iteration (ms): 6759.7 | learning rate: 6.930E-05 | global batch size:    32 | lm loss: 1.193563E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1156/  500000 | consumed samples:        36992 | consumed tokens:    151519232 | elapsed time per iteration (ms): 6760.1 | learning rate: 6.936E-05 | global batch size:    32 | lm loss: 1.198134E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1157/  500000 | consumed samples:        37024 | consumed tokens:    151650304 | elapsed time per iteration (ms): 6758.7 | learning rate: 6.942E-05 | global batch size:    32 | lm loss: 1.209352E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1158/  500000 | consumed samples:        37056 | consumed tokens:    151781376 | elapsed time per iteration (ms): 6752.7 | learning rate: 6.948E-05 | global batch size:    32 | lm loss: 1.179922E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.739 | TFLOPs: 147.80 |
time (ms)
 iteration     1159/  500000 | consumed samples:        37088 | consumed tokens:    151912448 | elapsed time per iteration (ms): 6753.5 | learning rate: 6.954E-05 | global batch size:    32 | lm loss: 1.226309E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.738 | TFLOPs: 147.78 |
time (ms)
[2023-10-10 17:20:54,356] [INFO] [logging.py:96:log_dist] [Rank 0] step=1160, skipped=0, lr=[6.96e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:20:54,613] [INFO] [timer.py:208:stop] epoch=0/micro_step=1160/global_step=1160, RunningAvgSamplesPerSec=4.742978642859583, CurrSamplesPerSec=4.74213181265033, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1160/  500000 | consumed samples:        37120 | consumed tokens:    152043520 | elapsed time per iteration (ms): 6760.5 | learning rate: 6.960E-05 | global batch size:    32 | lm loss: 1.198336E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1161/  500000 | consumed samples:        37152 | consumed tokens:    152174592 | elapsed time per iteration (ms): 6765.6 | learning rate: 6.966E-05 | global batch size:    32 | lm loss: 1.217959E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration     1162/  500000 | consumed samples:        37184 | consumed tokens:    152305664 | elapsed time per iteration (ms): 6763.8 | learning rate: 6.972E-05 | global batch size:    32 | lm loss: 1.249768E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     1163/  500000 | consumed samples:        37216 | consumed tokens:    152436736 | elapsed time per iteration (ms): 6759.1 | learning rate: 6.978E-05 | global batch size:    32 | lm loss: 1.191982E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1164/  500000 | consumed samples:        37248 | consumed tokens:    152567808 | elapsed time per iteration (ms): 6762.0 | learning rate: 6.984E-05 | global batch size:    32 | lm loss: 1.222798E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1165/  500000 | consumed samples:        37280 | consumed tokens:    152698880 | elapsed time per iteration (ms): 6756.8 | learning rate: 6.990E-05 | global batch size:    32 | lm loss: 1.211481E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1166/  500000 | consumed samples:        37312 | consumed tokens:    152829952 | elapsed time per iteration (ms): 6757.3 | learning rate: 6.996E-05 | global batch size:    32 | lm loss: 1.204199E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1167/  500000 | consumed samples:        37344 | consumed tokens:    152961024 | elapsed time per iteration (ms): 6758.1 | learning rate: 7.002E-05 | global batch size:    32 | lm loss: 1.210632E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1168/  500000 | consumed samples:        37376 | consumed tokens:    153092096 | elapsed time per iteration (ms): 6761.6 | learning rate: 7.008E-05 | global batch size:    32 | lm loss: 1.206946E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     1169/  500000 | consumed samples:        37408 | consumed tokens:    153223168 | elapsed time per iteration (ms): 6759.4 | learning rate: 7.014E-05 | global batch size:    32 | lm loss: 1.229625E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
[2023-10-10 17:22:02,006] [INFO] [logging.py:96:log_dist] [Rank 0] step=1170, skipped=0, lr=[7.02e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:22:02,254] [INFO] [timer.py:208:stop] epoch=0/micro_step=1170/global_step=1170, RunningAvgSamplesPerSec=4.7429770032752145, CurrSamplesPerSec=4.746010015021507, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1170/  500000 | consumed samples:        37440 | consumed tokens:    153354240 | elapsed time per iteration (ms): 6755.8 | learning rate: 7.020E-05 | global batch size:    32 | lm loss: 1.206193E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration     1171/  500000 | consumed samples:        37472 | consumed tokens:    153485312 | elapsed time per iteration (ms): 6760.2 | learning rate: 7.026E-05 | global batch size:    32 | lm loss: 1.253633E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration     1172/  500000 | consumed samples:        37504 | consumed tokens:    153616384 | elapsed time per iteration (ms): 6759.9 | learning rate: 7.032E-05 | global batch size:    32 | lm loss: 1.225030E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1173/  500000 | consumed samples:        37536 | consumed tokens:    153747456 | elapsed time per iteration (ms): 6753.5 | learning rate: 7.038E-05 | global batch size:    32 | lm loss: 1.185060E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.738 | TFLOPs: 147.78 |
time (ms)
 iteration     1174/  500000 | consumed samples:        37568 | consumed tokens:    153878528 | elapsed time per iteration (ms): 6760.2 | learning rate: 7.044E-05 | global batch size:    32 | lm loss: 1.213215E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1175/  500000 | consumed samples:        37600 | consumed tokens:    154009600 | elapsed time per iteration (ms): 6758.0 | learning rate: 7.050E-05 | global batch size:    32 | lm loss: 1.180807E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1176/  500000 | consumed samples:        37632 | consumed tokens:    154140672 | elapsed time per iteration (ms): 6759.4 | learning rate: 7.056E-05 | global batch size:    32 | lm loss: 1.201623E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1177/  500000 | consumed samples:        37664 | consumed tokens:    154271744 | elapsed time per iteration (ms): 6755.4 | learning rate: 7.062E-05 | global batch size:    32 | lm loss: 1.189043E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration     1178/  500000 | consumed samples:        37696 | consumed tokens:    154402816 | elapsed time per iteration (ms): 6759.0 | learning rate: 7.068E-05 | global batch size:    32 | lm loss: 1.209808E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1179/  500000 | consumed samples:        37728 | consumed tokens:    154533888 | elapsed time per iteration (ms): 6757.3 | learning rate: 7.074E-05 | global batch size:    32 | lm loss: 1.204436E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
[2023-10-10 17:23:09,619] [INFO] [logging.py:96:log_dist] [Rank 0] step=1180, skipped=0, lr=[7.08e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:23:09,880] [INFO] [timer.py:208:stop] epoch=0/micro_step=1180/global_step=1180, RunningAvgSamplesPerSec=4.74298215941339, CurrSamplesPerSec=4.74103948856098, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1180/  500000 | consumed samples:        37760 | consumed tokens:    154664960 | elapsed time per iteration (ms): 6762.4 | learning rate: 7.080E-05 | global batch size:    32 | lm loss: 1.231022E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1181/  500000 | consumed samples:        37792 | consumed tokens:    154796032 | elapsed time per iteration (ms): 6759.7 | learning rate: 7.086E-05 | global batch size:    32 | lm loss: 1.237801E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1182/  500000 | consumed samples:        37824 | consumed tokens:    154927104 | elapsed time per iteration (ms): 6763.6 | learning rate: 7.092E-05 | global batch size:    32 | lm loss: 1.219582E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     1183/  500000 | consumed samples:        37856 | consumed tokens:    155058176 | elapsed time per iteration (ms): 6756.4 | learning rate: 7.098E-05 | global batch size:    32 | lm loss: 1.234803E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1184/  500000 | consumed samples:        37888 | consumed tokens:    155189248 | elapsed time per iteration (ms): 6762.6 | learning rate: 7.104E-05 | global batch size:    32 | lm loss: 1.212150E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1185/  500000 | consumed samples:        37920 | consumed tokens:    155320320 | elapsed time per iteration (ms): 6759.6 | learning rate: 7.110E-05 | global batch size:    32 | lm loss: 1.194662E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1186/  500000 | consumed samples:        37952 | consumed tokens:    155451392 | elapsed time per iteration (ms): 6762.1 | learning rate: 7.116E-05 | global batch size:    32 | lm loss: 1.196698E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1187/  500000 | consumed samples:        37984 | consumed tokens:    155582464 | elapsed time per iteration (ms): 6759.2 | learning rate: 7.122E-05 | global batch size:    32 | lm loss: 1.197169E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1188/  500000 | consumed samples:        38016 | consumed tokens:    155713536 | elapsed time per iteration (ms): 6761.0 | learning rate: 7.128E-05 | global batch size:    32 | lm loss: 1.228990E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1189/  500000 | consumed samples:        38048 | consumed tokens:    155844608 | elapsed time per iteration (ms): 6757.9 | learning rate: 7.134E-05 | global batch size:    32 | lm loss: 1.212719E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
[2023-10-10 17:24:17,269] [INFO] [logging.py:96:log_dist] [Rank 0] step=1190, skipped=0, lr=[7.14e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:24:17,523] [INFO] [timer.py:208:stop] epoch=0/micro_step=1190/global_step=1190, RunningAvgSamplesPerSec=4.742983122232065, CurrSamplesPerSec=4.74560593542437, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1190/  500000 | consumed samples:        38080 | consumed tokens:    155975680 | elapsed time per iteration (ms): 6756.1 | learning rate: 7.140E-05 | global batch size:    32 | lm loss: 1.162670E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1191/  500000 | consumed samples:        38112 | consumed tokens:    156106752 | elapsed time per iteration (ms): 6758.7 | learning rate: 7.146E-05 | global batch size:    32 | lm loss: 1.223317E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1192/  500000 | consumed samples:        38144 | consumed tokens:    156237824 | elapsed time per iteration (ms): 6757.3 | learning rate: 7.152E-05 | global batch size:    32 | lm loss: 1.163122E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1193/  500000 | consumed samples:        38176 | consumed tokens:    156368896 | elapsed time per iteration (ms): 6760.2 | learning rate: 7.158E-05 | global batch size:    32 | lm loss: 1.178449E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1194/  500000 | consumed samples:        38208 | consumed tokens:    156499968 | elapsed time per iteration (ms): 6758.6 | learning rate: 7.164E-05 | global batch size:    32 | lm loss: 1.184442E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1195/  500000 | consumed samples:        38240 | consumed tokens:    156631040 | elapsed time per iteration (ms): 6761.1 | learning rate: 7.170E-05 | global batch size:    32 | lm loss: 1.217789E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1196/  500000 | consumed samples:        38272 | consumed tokens:    156762112 | elapsed time per iteration (ms): 6761.0 | learning rate: 7.176E-05 | global batch size:    32 | lm loss: 1.151562E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1197/  500000 | consumed samples:        38304 | consumed tokens:    156893184 | elapsed time per iteration (ms): 6757.4 | learning rate: 7.182E-05 | global batch size:    32 | lm loss: 1.232467E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1198/  500000 | consumed samples:        38336 | consumed tokens:    157024256 | elapsed time per iteration (ms): 6757.9 | learning rate: 7.188E-05 | global batch size:    32 | lm loss: 1.220652E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1199/  500000 | consumed samples:        38368 | consumed tokens:    157155328 | elapsed time per iteration (ms): 6759.8 | learning rate: 7.194E-05 | global batch size:    32 | lm loss: 1.200592E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
[2023-10-10 17:25:24,894] [INFO] [logging.py:96:log_dist] [Rank 0] step=1200, skipped=0, lr=[7.2e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:25:25,154] [INFO] [timer.py:208:stop] epoch=0/micro_step=1200/global_step=1200, RunningAvgSamplesPerSec=4.742985492662191, CurrSamplesPerSec=4.743916192081456, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1200/  500000 | consumed samples:        38400 | consumed tokens:    157286400 | elapsed time per iteration (ms): 6757.6 | learning rate: 7.200E-05 | global batch size:    32 | lm loss: 1.206314E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1201/  500000 | consumed samples:        38432 | consumed tokens:    157417472 | elapsed time per iteration (ms): 6759.6 | learning rate: 7.206E-05 | global batch size:    32 | lm loss: 1.251727E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1202/  500000 | consumed samples:        38464 | consumed tokens:    157548544 | elapsed time per iteration (ms): 6760.5 | learning rate: 7.212E-05 | global batch size:    32 | lm loss: 1.156019E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1203/  500000 | consumed samples:        38496 | consumed tokens:    157679616 | elapsed time per iteration (ms): 6762.0 | learning rate: 7.218E-05 | global batch size:    32 | lm loss: 1.201790E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1204/  500000 | consumed samples:        38528 | consumed tokens:    157810688 | elapsed time per iteration (ms): 6759.7 | learning rate: 7.224E-05 | global batch size:    32 | lm loss: 1.173319E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1205/  500000 | consumed samples:        38560 | consumed tokens:    157941760 | elapsed time per iteration (ms): 6758.5 | learning rate: 7.230E-05 | global batch size:    32 | lm loss: 1.199423E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1206/  500000 | consumed samples:        38592 | consumed tokens:    158072832 | elapsed time per iteration (ms): 6759.4 | learning rate: 7.236E-05 | global batch size:    32 | lm loss: 1.209819E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1207/  500000 | consumed samples:        38624 | consumed tokens:    158203904 | elapsed time per iteration (ms): 6755.5 | learning rate: 7.242E-05 | global batch size:    32 | lm loss: 1.215563E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration     1208/  500000 | consumed samples:        38656 | consumed tokens:    158334976 | elapsed time per iteration (ms): 6762.1 | learning rate: 7.248E-05 | global batch size:    32 | lm loss: 1.201616E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1209/  500000 | consumed samples:        38688 | consumed tokens:    158466048 | elapsed time per iteration (ms): 6759.7 | learning rate: 7.254E-05 | global batch size:    32 | lm loss: 1.212868E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
[2023-10-10 17:26:32,535] [INFO] [logging.py:96:log_dist] [Rank 0] step=1210, skipped=0, lr=[7.26e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:26:32,791] [INFO] [timer.py:208:stop] epoch=0/micro_step=1210/global_step=1210, RunningAvgSamplesPerSec=4.742986446357859, CurrSamplesPerSec=4.7451601516893085, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1210/  500000 | consumed samples:        38720 | consumed tokens:    158597120 | elapsed time per iteration (ms): 6756.8 | learning rate: 7.260E-05 | global batch size:    32 | lm loss: 1.211455E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1211/  500000 | consumed samples:        38752 | consumed tokens:    158728192 | elapsed time per iteration (ms): 6760.5 | learning rate: 7.266E-05 | global batch size:    32 | lm loss: 1.212507E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1212/  500000 | consumed samples:        38784 | consumed tokens:    158859264 | elapsed time per iteration (ms): 6761.1 | learning rate: 7.272E-05 | global batch size:    32 | lm loss: 1.182950E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1213/  500000 | consumed samples:        38816 | consumed tokens:    158990336 | elapsed time per iteration (ms): 6764.5 | learning rate: 7.278E-05 | global batch size:    32 | lm loss: 1.198977E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.54 |
time (ms)
 iteration     1214/  500000 | consumed samples:        38848 | consumed tokens:    159121408 | elapsed time per iteration (ms): 6764.7 | learning rate: 7.284E-05 | global batch size:    32 | lm loss: 1.163954E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration     1215/  500000 | consumed samples:        38880 | consumed tokens:    159252480 | elapsed time per iteration (ms): 6762.8 | learning rate: 7.290E-05 | global batch size:    32 | lm loss: 1.227182E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1216/  500000 | consumed samples:        38912 | consumed tokens:    159383552 | elapsed time per iteration (ms): 6763.5 | learning rate: 7.296E-05 | global batch size:    32 | lm loss: 1.196180E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     1217/  500000 | consumed samples:        38944 | consumed tokens:    159514624 | elapsed time per iteration (ms): 6759.7 | learning rate: 7.302E-05 | global batch size:    32 | lm loss: 1.180292E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1218/  500000 | consumed samples:        38976 | consumed tokens:    159645696 | elapsed time per iteration (ms): 6759.7 | learning rate: 7.308E-05 | global batch size:    32 | lm loss: 1.171540E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1219/  500000 | consumed samples:        39008 | consumed tokens:    159776768 | elapsed time per iteration (ms): 6759.4 | learning rate: 7.314E-05 | global batch size:    32 | lm loss: 1.195819E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
[2023-10-10 17:27:40,193] [INFO] [logging.py:96:log_dist] [Rank 0] step=1220, skipped=0, lr=[7.32e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:27:40,447] [INFO] [timer.py:208:stop] epoch=0/micro_step=1220/global_step=1220, RunningAvgSamplesPerSec=4.742976066220094, CurrSamplesPerSec=4.744015456802662, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1220/  500000 | consumed samples:        39040 | consumed tokens:    159907840 | elapsed time per iteration (ms): 6758.6 | learning rate: 7.320E-05 | global batch size:    32 | lm loss: 1.190376E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1221/  500000 | consumed samples:        39072 | consumed tokens:    160038912 | elapsed time per iteration (ms): 6762.5 | learning rate: 7.326E-05 | global batch size:    32 | lm loss: 1.166522E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1222/  500000 | consumed samples:        39104 | consumed tokens:    160169984 | elapsed time per iteration (ms): 6761.6 | learning rate: 7.332E-05 | global batch size:    32 | lm loss: 1.179335E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     1223/  500000 | consumed samples:        39136 | consumed tokens:    160301056 | elapsed time per iteration (ms): 6760.0 | learning rate: 7.338E-05 | global batch size:    32 | lm loss: 1.195443E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1224/  500000 | consumed samples:        39168 | consumed tokens:    160432128 | elapsed time per iteration (ms): 6757.6 | learning rate: 7.344E-05 | global batch size:    32 | lm loss: 1.204343E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1225/  500000 | consumed samples:        39200 | consumed tokens:    160563200 | elapsed time per iteration (ms): 6760.2 | learning rate: 7.350E-05 | global batch size:    32 | lm loss: 1.213165E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1226/  500000 | consumed samples:        39232 | consumed tokens:    160694272 | elapsed time per iteration (ms): 6760.9 | learning rate: 7.356E-05 | global batch size:    32 | lm loss: 1.179922E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1227/  500000 | consumed samples:        39264 | consumed tokens:    160825344 | elapsed time per iteration (ms): 6761.0 | learning rate: 7.362E-05 | global batch size:    32 | lm loss: 1.202285E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1228/  500000 | consumed samples:        39296 | consumed tokens:    160956416 | elapsed time per iteration (ms): 6756.3 | learning rate: 7.368E-05 | global batch size:    32 | lm loss: 1.204932E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1229/  500000 | consumed samples:        39328 | consumed tokens:    161087488 | elapsed time per iteration (ms): 6756.0 | learning rate: 7.374E-05 | global batch size:    32 | lm loss: 1.206573E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
[2023-10-10 17:28:47,846] [INFO] [logging.py:96:log_dist] [Rank 0] step=1230, skipped=0, lr=[7.38e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:28:48,084] [INFO] [timer.py:208:stop] epoch=0/micro_step=1230/global_step=1230, RunningAvgSamplesPerSec=4.742977812307169, CurrSamplesPerSec=4.7430731124832715, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1230/  500000 | consumed samples:        39360 | consumed tokens:    161218560 | elapsed time per iteration (ms): 6759.6 | learning rate: 7.380E-05 | global batch size:    32 | lm loss: 1.218941E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1231/  500000 | consumed samples:        39392 | consumed tokens:    161349632 | elapsed time per iteration (ms): 6755.0 | learning rate: 7.386E-05 | global batch size:    32 | lm loss: 1.160364E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.75 |
time (ms)
 iteration     1232/  500000 | consumed samples:        39424 | consumed tokens:    161480704 | elapsed time per iteration (ms): 6757.9 | learning rate: 7.392E-05 | global batch size:    32 | lm loss: 1.236475E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1233/  500000 | consumed samples:        39456 | consumed tokens:    161611776 | elapsed time per iteration (ms): 6759.2 | learning rate: 7.398E-05 | global batch size:    32 | lm loss: 1.179425E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1234/  500000 | consumed samples:        39488 | consumed tokens:    161742848 | elapsed time per iteration (ms): 6759.4 | learning rate: 7.404E-05 | global batch size:    32 | lm loss: 1.189303E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1235/  500000 | consumed samples:        39520 | consumed tokens:    161873920 | elapsed time per iteration (ms): 6757.1 | learning rate: 7.410E-05 | global batch size:    32 | lm loss: 1.218804E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1236/  500000 | consumed samples:        39552 | consumed tokens:    162004992 | elapsed time per iteration (ms): 6757.7 | learning rate: 7.416E-05 | global batch size:    32 | lm loss: 1.201687E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1237/  500000 | consumed samples:        39584 | consumed tokens:    162136064 | elapsed time per iteration (ms): 6760.6 | learning rate: 7.422E-05 | global batch size:    32 | lm loss: 1.222700E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1238/  500000 | consumed samples:        39616 | consumed tokens:    162267136 | elapsed time per iteration (ms): 6760.3 | learning rate: 7.428E-05 | global batch size:    32 | lm loss: 1.234979E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration     1239/  500000 | consumed samples:        39648 | consumed tokens:    162398208 | elapsed time per iteration (ms): 6757.5 | learning rate: 7.434E-05 | global batch size:    32 | lm loss: 1.180285E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
[2023-10-10 17:29:55,454] [INFO] [logging.py:96:log_dist] [Rank 0] step=1240, skipped=0, lr=[7.439999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:29:55,709] [INFO] [timer.py:208:stop] epoch=0/micro_step=1240/global_step=1240, RunningAvgSamplesPerSec=4.742986373660596, CurrSamplesPerSec=4.744286276111955, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1240/  500000 | consumed samples:        39680 | consumed tokens:    162529280 | elapsed time per iteration (ms): 6757.5 | learning rate: 7.440E-05 | global batch size:    32 | lm loss: 1.208443E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1241/  500000 | consumed samples:        39712 | consumed tokens:    162660352 | elapsed time per iteration (ms): 6760.9 | learning rate: 7.446E-05 | global batch size:    32 | lm loss: 1.182292E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1242/  500000 | consumed samples:        39744 | consumed tokens:    162791424 | elapsed time per iteration (ms): 6756.3 | learning rate: 7.452E-05 | global batch size:    32 | lm loss: 1.177173E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1243/  500000 | consumed samples:        39776 | consumed tokens:    162922496 | elapsed time per iteration (ms): 6762.4 | learning rate: 7.458E-05 | global batch size:    32 | lm loss: 1.213756E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1244/  500000 | consumed samples:        39808 | consumed tokens:    163053568 | elapsed time per iteration (ms): 6764.7 | learning rate: 7.464E-05 | global batch size:    32 | lm loss: 1.212557E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration     1245/  500000 | consumed samples:        39840 | consumed tokens:    163184640 | elapsed time per iteration (ms): 6756.5 | learning rate: 7.470E-05 | global batch size:    32 | lm loss: 1.226516E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1246/  500000 | consumed samples:        39872 | consumed tokens:    163315712 | elapsed time per iteration (ms): 6760.4 | learning rate: 7.476E-05 | global batch size:    32 | lm loss: 1.207697E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1247/  500000 | consumed samples:        39904 | consumed tokens:    163446784 | elapsed time per iteration (ms): 6763.5 | learning rate: 7.482E-05 | global batch size:    32 | lm loss: 1.185971E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     1248/  500000 | consumed samples:        39936 | consumed tokens:    163577856 | elapsed time per iteration (ms): 6758.6 | learning rate: 7.488E-05 | global batch size:    32 | lm loss: 1.181605E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1249/  500000 | consumed samples:        39968 | consumed tokens:    163708928 | elapsed time per iteration (ms): 6760.0 | learning rate: 7.494E-05 | global batch size:    32 | lm loss: 1.221537E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
[2023-10-10 17:31:03,105] [INFO] [logging.py:96:log_dist] [Rank 0] step=1250, skipped=0, lr=[7.5e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:31:03,357] [INFO] [timer.py:208:stop] epoch=0/micro_step=1250/global_step=1250, RunningAvgSamplesPerSec=4.742981475978513, CurrSamplesPerSec=4.741014535648409, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1250/  500000 | consumed samples:        40000 | consumed tokens:    163840000 | elapsed time per iteration (ms): 6762.2 | learning rate: 7.500E-05 | global batch size:    32 | lm loss: 1.175985E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1251/  500000 | consumed samples:        40032 | consumed tokens:    163971072 | elapsed time per iteration (ms): 6756.7 | learning rate: 7.506E-05 | global batch size:    32 | lm loss: 1.197200E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1252/  500000 | consumed samples:        40064 | consumed tokens:    164102144 | elapsed time per iteration (ms): 6761.7 | learning rate: 7.512E-05 | global batch size:    32 | lm loss: 1.196382E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     1253/  500000 | consumed samples:        40096 | consumed tokens:    164233216 | elapsed time per iteration (ms): 6760.3 | learning rate: 7.518E-05 | global batch size:    32 | lm loss: 1.214369E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration     1254/  500000 | consumed samples:        40128 | consumed tokens:    164364288 | elapsed time per iteration (ms): 6763.6 | learning rate: 7.524E-05 | global batch size:    32 | lm loss: 1.171303E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     1255/  500000 | consumed samples:        40160 | consumed tokens:    164495360 | elapsed time per iteration (ms): 6757.8 | learning rate: 7.530E-05 | global batch size:    32 | lm loss: 1.175659E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1256/  500000 | consumed samples:        40192 | consumed tokens:    164626432 | elapsed time per iteration (ms): 6761.3 | learning rate: 7.536E-05 | global batch size:    32 | lm loss: 1.202692E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1257/  500000 | consumed samples:        40224 | consumed tokens:    164757504 | elapsed time per iteration (ms): 6759.6 | learning rate: 7.542E-05 | global batch size:    32 | lm loss: 1.189227E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1258/  500000 | consumed samples:        40256 | consumed tokens:    164888576 | elapsed time per iteration (ms): 6764.6 | learning rate: 7.548E-05 | global batch size:    32 | lm loss: 1.205630E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration     1259/  500000 | consumed samples:        40288 | consumed tokens:    165019648 | elapsed time per iteration (ms): 6763.4 | learning rate: 7.554E-05 | global batch size:    32 | lm loss: 1.199602E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
[2023-10-10 17:32:10,755] [INFO] [logging.py:96:log_dist] [Rank 0] step=1260, skipped=0, lr=[7.56e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:32:11,012] [INFO] [timer.py:208:stop] epoch=0/micro_step=1260/global_step=1260, RunningAvgSamplesPerSec=4.742973685212519, CurrSamplesPerSec=4.739901802347975, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1260/  500000 | consumed samples:        40320 | consumed tokens:    165150720 | elapsed time per iteration (ms): 6763.9 | learning rate: 7.560E-05 | global batch size:    32 | lm loss: 1.179936E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     1261/  500000 | consumed samples:        40352 | consumed tokens:    165281792 | elapsed time per iteration (ms): 6766.6 | learning rate: 7.566E-05 | global batch size:    32 | lm loss: 1.179398E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.50 |
time (ms)
 iteration     1262/  500000 | consumed samples:        40384 | consumed tokens:    165412864 | elapsed time per iteration (ms): 6765.3 | learning rate: 7.572E-05 | global batch size:    32 | lm loss: 1.181334E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration     1263/  500000 | consumed samples:        40416 | consumed tokens:    165543936 | elapsed time per iteration (ms): 6761.3 | learning rate: 7.578E-05 | global batch size:    32 | lm loss: 1.152558E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1264/  500000 | consumed samples:        40448 | consumed tokens:    165675008 | elapsed time per iteration (ms): 6761.1 | learning rate: 7.584E-05 | global batch size:    32 | lm loss: 1.220929E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1265/  500000 | consumed samples:        40480 | consumed tokens:    165806080 | elapsed time per iteration (ms): 6760.4 | learning rate: 7.590E-05 | global batch size:    32 | lm loss: 1.180477E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1266/  500000 | consumed samples:        40512 | consumed tokens:    165937152 | elapsed time per iteration (ms): 6754.9 | learning rate: 7.596E-05 | global batch size:    32 | lm loss: 1.203952E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.75 |
time (ms)
 iteration     1267/  500000 | consumed samples:        40544 | consumed tokens:    166068224 | elapsed time per iteration (ms): 6757.5 | learning rate: 7.602E-05 | global batch size:    32 | lm loss: 1.198208E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.70 |
time (ms)
 iteration     1268/  500000 | consumed samples:        40576 | consumed tokens:    166199296 | elapsed time per iteration (ms): 6762.0 | learning rate: 7.608E-05 | global batch size:    32 | lm loss: 1.168854E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1269/  500000 | consumed samples:        40608 | consumed tokens:    166330368 | elapsed time per iteration (ms): 6757.0 | learning rate: 7.614E-05 | global batch size:    32 | lm loss: 1.186264E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
[2023-10-10 17:33:18,398] [INFO] [logging.py:96:log_dist] [Rank 0] step=1270, skipped=0, lr=[7.62e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:33:18,657] [INFO] [timer.py:208:stop] epoch=0/micro_step=1270/global_step=1270, RunningAvgSamplesPerSec=4.742969198173575, CurrSamplesPerSec=4.744081020746145, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1270/  500000 | consumed samples:        40640 | consumed tokens:    166461440 | elapsed time per iteration (ms): 6757.6 | learning rate: 7.620E-05 | global batch size:    32 | lm loss: 1.208855E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1271/  500000 | consumed samples:        40672 | consumed tokens:    166592512 | elapsed time per iteration (ms): 6759.8 | learning rate: 7.626E-05 | global batch size:    32 | lm loss: 1.175069E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1272/  500000 | consumed samples:        40704 | consumed tokens:    166723584 | elapsed time per iteration (ms): 6758.8 | learning rate: 7.632E-05 | global batch size:    32 | lm loss: 1.187601E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1273/  500000 | consumed samples:        40736 | consumed tokens:    166854656 | elapsed time per iteration (ms): 6758.4 | learning rate: 7.638E-05 | global batch size:    32 | lm loss: 1.188346E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1274/  500000 | consumed samples:        40768 | consumed tokens:    166985728 | elapsed time per iteration (ms): 6761.2 | learning rate: 7.644E-05 | global batch size:    32 | lm loss: 1.174748E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1275/  500000 | consumed samples:        40800 | consumed tokens:    167116800 | elapsed time per iteration (ms): 6756.3 | learning rate: 7.650E-05 | global batch size:    32 | lm loss: 1.206653E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1276/  500000 | consumed samples:        40832 | consumed tokens:    167247872 | elapsed time per iteration (ms): 6761.0 | learning rate: 7.656E-05 | global batch size:    32 | lm loss: 1.191824E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1277/  500000 | consumed samples:        40864 | consumed tokens:    167378944 | elapsed time per iteration (ms): 6761.0 | learning rate: 7.662E-05 | global batch size:    32 | lm loss: 1.175565E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1278/  500000 | consumed samples:        40896 | consumed tokens:    167510016 | elapsed time per iteration (ms): 6758.1 | learning rate: 7.668E-05 | global batch size:    32 | lm loss: 1.201313E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1279/  500000 | consumed samples:        40928 | consumed tokens:    167641088 | elapsed time per iteration (ms): 6759.3 | learning rate: 7.674E-05 | global batch size:    32 | lm loss: 1.219088E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
[2023-10-10 17:34:26,033] [INFO] [logging.py:96:log_dist] [Rank 0] step=1280, skipped=0, lr=[7.68e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:34:26,292] [INFO] [timer.py:208:stop] epoch=0/micro_step=1280/global_step=1280, RunningAvgSamplesPerSec=4.742971056633879, CurrSamplesPerSec=4.744368953429706, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1280/  500000 | consumed samples:        40960 | consumed tokens:    167772160 | elapsed time per iteration (ms): 6757.7 | learning rate: 7.680E-05 | global batch size:    32 | lm loss: 1.176758E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1281/  500000 | consumed samples:        40992 | consumed tokens:    167903232 | elapsed time per iteration (ms): 6758.4 | learning rate: 7.686E-05 | global batch size:    32 | lm loss: 1.175706E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1282/  500000 | consumed samples:        41024 | consumed tokens:    168034304 | elapsed time per iteration (ms): 6756.8 | learning rate: 7.692E-05 | global batch size:    32 | lm loss: 1.211997E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1283/  500000 | consumed samples:        41056 | consumed tokens:    168165376 | elapsed time per iteration (ms): 6760.9 | learning rate: 7.698E-05 | global batch size:    32 | lm loss: 1.158817E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1284/  500000 | consumed samples:        41088 | consumed tokens:    168296448 | elapsed time per iteration (ms): 6754.7 | learning rate: 7.704E-05 | global batch size:    32 | lm loss: 1.172658E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.76 |
time (ms)
 iteration     1285/  500000 | consumed samples:        41120 | consumed tokens:    168427520 | elapsed time per iteration (ms): 6761.7 | learning rate: 7.710E-05 | global batch size:    32 | lm loss: 1.166663E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     1286/  500000 | consumed samples:        41152 | consumed tokens:    168558592 | elapsed time per iteration (ms): 6761.6 | learning rate: 7.716E-05 | global batch size:    32 | lm loss: 1.223776E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1287/  500000 | consumed samples:        41184 | consumed tokens:    168689664 | elapsed time per iteration (ms): 6761.0 | learning rate: 7.722E-05 | global batch size:    32 | lm loss: 1.183788E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1288/  500000 | consumed samples:        41216 | consumed tokens:    168820736 | elapsed time per iteration (ms): 6760.4 | learning rate: 7.728E-05 | global batch size:    32 | lm loss: 1.178089E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1289/  500000 | consumed samples:        41248 | consumed tokens:    168951808 | elapsed time per iteration (ms): 6761.3 | learning rate: 7.734E-05 | global batch size:    32 | lm loss: 1.198600E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
[2023-10-10 17:35:33,668] [INFO] [logging.py:96:log_dist] [Rank 0] step=1290, skipped=0, lr=[7.74e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:35:33,929] [INFO] [timer.py:208:stop] epoch=0/micro_step=1290/global_step=1290, RunningAvgSamplesPerSec=4.742970430956652, CurrSamplesPerSec=4.743464020064394, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1290/  500000 | consumed samples:        41280 | consumed tokens:    169082880 | elapsed time per iteration (ms): 6758.8 | learning rate: 7.740E-05 | global batch size:    32 | lm loss: 1.194308E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1291/  500000 | consumed samples:        41312 | consumed tokens:    169213952 | elapsed time per iteration (ms): 6761.4 | learning rate: 7.746E-05 | global batch size:    32 | lm loss: 1.188192E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1292/  500000 | consumed samples:        41344 | consumed tokens:    169345024 | elapsed time per iteration (ms): 6758.8 | learning rate: 7.752E-05 | global batch size:    32 | lm loss: 1.189421E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1293/  500000 | consumed samples:        41376 | consumed tokens:    169476096 | elapsed time per iteration (ms): 6758.1 | learning rate: 7.758E-05 | global batch size:    32 | lm loss: 1.194536E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1294/  500000 | consumed samples:        41408 | consumed tokens:    169607168 | elapsed time per iteration (ms): 6760.1 | learning rate: 7.764E-05 | global batch size:    32 | lm loss: 1.181770E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1295/  500000 | consumed samples:        41440 | consumed tokens:    169738240 | elapsed time per iteration (ms): 6756.2 | learning rate: 7.770E-05 | global batch size:    32 | lm loss: 1.198962E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1296/  500000 | consumed samples:        41472 | consumed tokens:    169869312 | elapsed time per iteration (ms): 6759.2 | learning rate: 7.776E-05 | global batch size:    32 | lm loss: 1.205142E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1297/  500000 | consumed samples:        41504 | consumed tokens:    170000384 | elapsed time per iteration (ms): 6758.5 | learning rate: 7.782E-05 | global batch size:    32 | lm loss: 1.186019E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1298/  500000 | consumed samples:        41536 | consumed tokens:    170131456 | elapsed time per iteration (ms): 6758.2 | learning rate: 7.788E-05 | global batch size:    32 | lm loss: 1.202951E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1299/  500000 | consumed samples:        41568 | consumed tokens:    170262528 | elapsed time per iteration (ms): 6759.3 | learning rate: 7.794E-05 | global batch size:    32 | lm loss: 1.199889E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
[2023-10-10 17:36:41,327] [INFO] [logging.py:96:log_dist] [Rank 0] step=1300, skipped=0, lr=[7.799999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:36:41,563] [INFO] [timer.py:208:stop] epoch=0/micro_step=1300/global_step=1300, RunningAvgSamplesPerSec=4.742971115872363, CurrSamplesPerSec=4.741053723561652, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1300/  500000 | consumed samples:        41600 | consumed tokens:    170393600 | elapsed time per iteration (ms): 6762.3 | learning rate: 7.800E-05 | global batch size:    32 | lm loss: 1.164026E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1301/  500000 | consumed samples:        41632 | consumed tokens:    170524672 | elapsed time per iteration (ms): 6762.9 | learning rate: 7.806E-05 | global batch size:    32 | lm loss: 1.168241E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1302/  500000 | consumed samples:        41664 | consumed tokens:    170655744 | elapsed time per iteration (ms): 6759.8 | learning rate: 7.812E-05 | global batch size:    32 | lm loss: 1.170853E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1303/  500000 | consumed samples:        41696 | consumed tokens:    170786816 | elapsed time per iteration (ms): 6762.4 | learning rate: 7.818E-05 | global batch size:    32 | lm loss: 1.164171E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1304/  500000 | consumed samples:        41728 | consumed tokens:    170917888 | elapsed time per iteration (ms): 6757.9 | learning rate: 7.824E-05 | global batch size:    32 | lm loss: 1.213941E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1305/  500000 | consumed samples:        41760 | consumed tokens:    171048960 | elapsed time per iteration (ms): 6757.7 | learning rate: 7.830E-05 | global batch size:    32 | lm loss: 1.232579E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1306/  500000 | consumed samples:        41792 | consumed tokens:    171180032 | elapsed time per iteration (ms): 6758.2 | learning rate: 7.836E-05 | global batch size:    32 | lm loss: 1.154127E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1307/  500000 | consumed samples:        41824 | consumed tokens:    171311104 | elapsed time per iteration (ms): 6758.8 | learning rate: 7.842E-05 | global batch size:    32 | lm loss: 1.194200E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1308/  500000 | consumed samples:        41856 | consumed tokens:    171442176 | elapsed time per iteration (ms): 6757.9 | learning rate: 7.848E-05 | global batch size:    32 | lm loss: 1.179567E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1309/  500000 | consumed samples:        41888 | consumed tokens:    171573248 | elapsed time per iteration (ms): 6764.9 | learning rate: 7.854E-05 | global batch size:    32 | lm loss: 1.127799E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
[2023-10-10 17:37:48,944] [INFO] [logging.py:96:log_dist] [Rank 0] step=1310, skipped=0, lr=[7.859999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:37:49,207] [INFO] [timer.py:208:stop] epoch=0/micro_step=1310/global_step=1310, RunningAvgSamplesPerSec=4.742968893849183, CurrSamplesPerSec=4.741903456716061, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1310/  500000 | consumed samples:        41920 | consumed tokens:    171704320 | elapsed time per iteration (ms): 6762.0 | learning rate: 7.860E-05 | global batch size:    32 | lm loss: 1.190604E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1311/  500000 | consumed samples:        41952 | consumed tokens:    171835392 | elapsed time per iteration (ms): 6758.5 | learning rate: 7.866E-05 | global batch size:    32 | lm loss: 1.206838E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1312/  500000 | consumed samples:        41984 | consumed tokens:    171966464 | elapsed time per iteration (ms): 6758.1 | learning rate: 7.872E-05 | global batch size:    32 | lm loss: 1.180355E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1313/  500000 | consumed samples:        42016 | consumed tokens:    172097536 | elapsed time per iteration (ms): 6758.6 | learning rate: 7.878E-05 | global batch size:    32 | lm loss: 1.149397E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1314/  500000 | consumed samples:        42048 | consumed tokens:    172228608 | elapsed time per iteration (ms): 6753.9 | learning rate: 7.884E-05 | global batch size:    32 | lm loss: 1.174620E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.738 | TFLOPs: 147.77 |
time (ms)
 iteration     1315/  500000 | consumed samples:        42080 | consumed tokens:    172359680 | elapsed time per iteration (ms): 6758.9 | learning rate: 7.890E-05 | global batch size:    32 | lm loss: 1.160966E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1316/  500000 | consumed samples:        42112 | consumed tokens:    172490752 | elapsed time per iteration (ms): 6760.0 | learning rate: 7.896E-05 | global batch size:    32 | lm loss: 1.222331E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1317/  500000 | consumed samples:        42144 | consumed tokens:    172621824 | elapsed time per iteration (ms): 6760.6 | learning rate: 7.902E-05 | global batch size:    32 | lm loss: 1.173944E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1318/  500000 | consumed samples:        42176 | consumed tokens:    172752896 | elapsed time per iteration (ms): 6759.9 | learning rate: 7.908E-05 | global batch size:    32 | lm loss: 1.175885E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1319/  500000 | consumed samples:        42208 | consumed tokens:    172883968 | elapsed time per iteration (ms): 6759.7 | learning rate: 7.914E-05 | global batch size:    32 | lm loss: 1.209826E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
[2023-10-10 17:38:56,574] [INFO] [logging.py:96:log_dist] [Rank 0] step=1320, skipped=0, lr=[7.919999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:38:56,836] [INFO] [timer.py:208:stop] epoch=0/micro_step=1320/global_step=1320, RunningAvgSamplesPerSec=4.742973148350208, CurrSamplesPerSec=4.7435875750113246, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1320/  500000 | consumed samples:        42240 | consumed tokens:    173015040 | elapsed time per iteration (ms): 6758.1 | learning rate: 7.920E-05 | global batch size:    32 | lm loss: 1.175774E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1321/  500000 | consumed samples:        42272 | consumed tokens:    173146112 | elapsed time per iteration (ms): 6759.0 | learning rate: 7.926E-05 | global batch size:    32 | lm loss: 1.173347E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1322/  500000 | consumed samples:        42304 | consumed tokens:    173277184 | elapsed time per iteration (ms): 6755.6 | learning rate: 7.932E-05 | global batch size:    32 | lm loss: 1.162770E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration     1323/  500000 | consumed samples:        42336 | consumed tokens:    173408256 | elapsed time per iteration (ms): 6761.0 | learning rate: 7.938E-05 | global batch size:    32 | lm loss: 1.172227E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1324/  500000 | consumed samples:        42368 | consumed tokens:    173539328 | elapsed time per iteration (ms): 6759.4 | learning rate: 7.944E-05 | global batch size:    32 | lm loss: 1.195342E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1325/  500000 | consumed samples:        42400 | consumed tokens:    173670400 | elapsed time per iteration (ms): 6760.6 | learning rate: 7.950E-05 | global batch size:    32 | lm loss: 1.181983E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1326/  500000 | consumed samples:        42432 | consumed tokens:    173801472 | elapsed time per iteration (ms): 6756.8 | learning rate: 7.956E-05 | global batch size:    32 | lm loss: 1.179998E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1327/  500000 | consumed samples:        42464 | consumed tokens:    173932544 | elapsed time per iteration (ms): 6758.8 | learning rate: 7.962E-05 | global batch size:    32 | lm loss: 1.145083E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1328/  500000 | consumed samples:        42496 | consumed tokens:    174063616 | elapsed time per iteration (ms): 6758.7 | learning rate: 7.968E-05 | global batch size:    32 | lm loss: 1.136503E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1329/  500000 | consumed samples:        42528 | consumed tokens:    174194688 | elapsed time per iteration (ms): 6758.0 | learning rate: 7.974E-05 | global batch size:    32 | lm loss: 1.177086E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
[2023-10-10 17:40:04,206] [INFO] [logging.py:96:log_dist] [Rank 0] step=1330, skipped=0, lr=[7.979999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:40:04,465] [INFO] [timer.py:208:stop] epoch=0/micro_step=1330/global_step=1330, RunningAvgSamplesPerSec=4.742977846654415, CurrSamplesPerSec=4.742827235794838, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1330/  500000 | consumed samples:        42560 | consumed tokens:    174325760 | elapsed time per iteration (ms): 6759.7 | learning rate: 7.980E-05 | global batch size:    32 | lm loss: 1.149882E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1331/  500000 | consumed samples:        42592 | consumed tokens:    174456832 | elapsed time per iteration (ms): 6758.5 | learning rate: 7.986E-05 | global batch size:    32 | lm loss: 1.143306E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1332/  500000 | consumed samples:        42624 | consumed tokens:    174587904 | elapsed time per iteration (ms): 6759.4 | learning rate: 7.992E-05 | global batch size:    32 | lm loss: 1.183186E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1333/  500000 | consumed samples:        42656 | consumed tokens:    174718976 | elapsed time per iteration (ms): 6761.8 | learning rate: 7.998E-05 | global batch size:    32 | lm loss: 1.188712E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1334/  500000 | consumed samples:        42688 | consumed tokens:    174850048 | elapsed time per iteration (ms): 6757.4 | learning rate: 8.004E-05 | global batch size:    32 | lm loss: 1.175068E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1335/  500000 | consumed samples:        42720 | consumed tokens:    174981120 | elapsed time per iteration (ms): 6761.1 | learning rate: 8.010E-05 | global batch size:    32 | lm loss: 1.162437E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1336/  500000 | consumed samples:        42752 | consumed tokens:    175112192 | elapsed time per iteration (ms): 6758.7 | learning rate: 8.016E-05 | global batch size:    32 | lm loss: 1.186425E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1337/  500000 | consumed samples:        42784 | consumed tokens:    175243264 | elapsed time per iteration (ms): 6760.1 | learning rate: 8.022E-05 | global batch size:    32 | lm loss: 1.175893E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1338/  500000 | consumed samples:        42816 | consumed tokens:    175374336 | elapsed time per iteration (ms): 6759.1 | learning rate: 8.028E-05 | global batch size:    32 | lm loss: 1.148055E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1339/  500000 | consumed samples:        42848 | consumed tokens:    175505408 | elapsed time per iteration (ms): 6757.2 | learning rate: 8.034E-05 | global batch size:    32 | lm loss: 1.226958E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
[2023-10-10 17:41:11,873] [INFO] [logging.py:96:log_dist] [Rank 0] step=1340, skipped=0, lr=[8.039999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:41:12,103] [INFO] [timer.py:208:stop] epoch=0/micro_step=1340/global_step=1340, RunningAvgSamplesPerSec=4.742978483982861, CurrSamplesPerSec=4.742977239331319, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1340/  500000 | consumed samples:        42880 | consumed tokens:    175636480 | elapsed time per iteration (ms): 6759.6 | learning rate: 8.040E-05 | global batch size:    32 | lm loss: 1.176191E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1341/  500000 | consumed samples:        42912 | consumed tokens:    175767552 | elapsed time per iteration (ms): 6758.8 | learning rate: 8.046E-05 | global batch size:    32 | lm loss: 1.182165E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1342/  500000 | consumed samples:        42944 | consumed tokens:    175898624 | elapsed time per iteration (ms): 6755.6 | learning rate: 8.052E-05 | global batch size:    32 | lm loss: 1.153923E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration     1343/  500000 | consumed samples:        42976 | consumed tokens:    176029696 | elapsed time per iteration (ms): 6763.4 | learning rate: 8.058E-05 | global batch size:    32 | lm loss: 1.169128E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration     1344/  500000 | consumed samples:        43008 | consumed tokens:    176160768 | elapsed time per iteration (ms): 6759.0 | learning rate: 8.064E-05 | global batch size:    32 | lm loss: 1.212306E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1345/  500000 | consumed samples:        43040 | consumed tokens:    176291840 | elapsed time per iteration (ms): 6760.6 | learning rate: 8.070E-05 | global batch size:    32 | lm loss: 1.191903E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1346/  500000 | consumed samples:        43072 | consumed tokens:    176422912 | elapsed time per iteration (ms): 6764.1 | learning rate: 8.076E-05 | global batch size:    32 | lm loss: 1.199364E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     1347/  500000 | consumed samples:        43104 | consumed tokens:    176553984 | elapsed time per iteration (ms): 6759.1 | learning rate: 8.082E-05 | global batch size:    32 | lm loss: 1.141414E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1348/  500000 | consumed samples:        43136 | consumed tokens:    176685056 | elapsed time per iteration (ms): 6762.4 | learning rate: 8.088E-05 | global batch size:    32 | lm loss: 1.184772E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1349/  500000 | consumed samples:        43168 | consumed tokens:    176816128 | elapsed time per iteration (ms): 6766.3 | learning rate: 8.094E-05 | global batch size:    32 | lm loss: 1.184106E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.50 |
time (ms)
[2023-10-10 17:42:19,496] [INFO] [logging.py:96:log_dist] [Rank 0] step=1350, skipped=0, lr=[8.099999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:42:19,753] [INFO] [timer.py:208:stop] epoch=0/micro_step=1350/global_step=1350, RunningAvgSamplesPerSec=4.742972869492146, CurrSamplesPerSec=4.744119253242771, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1350/  500000 | consumed samples:        43200 | consumed tokens:    176947200 | elapsed time per iteration (ms): 6758.7 | learning rate: 8.100E-05 | global batch size:    32 | lm loss: 1.181901E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1351/  500000 | consumed samples:        43232 | consumed tokens:    177078272 | elapsed time per iteration (ms): 6760.5 | learning rate: 8.106E-05 | global batch size:    32 | lm loss: 1.190105E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1352/  500000 | consumed samples:        43264 | consumed tokens:    177209344 | elapsed time per iteration (ms): 6758.3 | learning rate: 8.112E-05 | global batch size:    32 | lm loss: 1.211497E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1353/  500000 | consumed samples:        43296 | consumed tokens:    177340416 | elapsed time per iteration (ms): 6760.4 | learning rate: 8.118E-05 | global batch size:    32 | lm loss: 1.186264E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1354/  500000 | consumed samples:        43328 | consumed tokens:    177471488 | elapsed time per iteration (ms): 6761.1 | learning rate: 8.124E-05 | global batch size:    32 | lm loss: 1.172972E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1355/  500000 | consumed samples:        43360 | consumed tokens:    177602560 | elapsed time per iteration (ms): 6756.3 | learning rate: 8.130E-05 | global batch size:    32 | lm loss: 1.170567E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1356/  500000 | consumed samples:        43392 | consumed tokens:    177733632 | elapsed time per iteration (ms): 6757.1 | learning rate: 8.136E-05 | global batch size:    32 | lm loss: 1.171888E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1357/  500000 | consumed samples:        43424 | consumed tokens:    177864704 | elapsed time per iteration (ms): 6757.2 | learning rate: 8.142E-05 | global batch size:    32 | lm loss: 1.175592E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1358/  500000 | consumed samples:        43456 | consumed tokens:    177995776 | elapsed time per iteration (ms): 6757.4 | learning rate: 8.148E-05 | global batch size:    32 | lm loss: 1.136258E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1359/  500000 | consumed samples:        43488 | consumed tokens:    178126848 | elapsed time per iteration (ms): 6756.6 | learning rate: 8.154E-05 | global batch size:    32 | lm loss: 1.171423E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
[2023-10-10 17:43:27,125] [INFO] [logging.py:96:log_dist] [Rank 0] step=1360, skipped=0, lr=[8.159999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:43:27,377] [INFO] [timer.py:208:stop] epoch=0/micro_step=1360/global_step=1360, RunningAvgSamplesPerSec=4.742980490885004, CurrSamplesPerSec=4.744470585074672, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1360/  500000 | consumed samples:        43520 | consumed tokens:    178257920 | elapsed time per iteration (ms): 6757.3 | learning rate: 8.160E-05 | global batch size:    32 | lm loss: 1.175693E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1361/  500000 | consumed samples:        43552 | consumed tokens:    178388992 | elapsed time per iteration (ms): 6763.7 | learning rate: 8.166E-05 | global batch size:    32 | lm loss: 1.179368E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     1362/  500000 | consumed samples:        43584 | consumed tokens:    178520064 | elapsed time per iteration (ms): 6758.3 | learning rate: 8.172E-05 | global batch size:    32 | lm loss: 1.169785E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1363/  500000 | consumed samples:        43616 | consumed tokens:    178651136 | elapsed time per iteration (ms): 6758.7 | learning rate: 8.178E-05 | global batch size:    32 | lm loss: 1.138496E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1364/  500000 | consumed samples:        43648 | consumed tokens:    178782208 | elapsed time per iteration (ms): 6763.0 | learning rate: 8.184E-05 | global batch size:    32 | lm loss: 1.151176E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1365/  500000 | consumed samples:        43680 | consumed tokens:    178913280 | elapsed time per iteration (ms): 6760.0 | learning rate: 8.190E-05 | global batch size:    32 | lm loss: 1.218609E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1366/  500000 | consumed samples:        43712 | consumed tokens:    179044352 | elapsed time per iteration (ms): 6760.2 | learning rate: 8.196E-05 | global batch size:    32 | lm loss: 1.156105E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1367/  500000 | consumed samples:        43744 | consumed tokens:    179175424 | elapsed time per iteration (ms): 6759.9 | learning rate: 8.202E-05 | global batch size:    32 | lm loss: 1.174519E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1368/  500000 | consumed samples:        43776 | consumed tokens:    179306496 | elapsed time per iteration (ms): 6756.3 | learning rate: 8.208E-05 | global batch size:    32 | lm loss: 1.166338E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1369/  500000 | consumed samples:        43808 | consumed tokens:    179437568 | elapsed time per iteration (ms): 6756.8 | learning rate: 8.214E-05 | global batch size:    32 | lm loss: 1.158115E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
[2023-10-10 17:44:34,758] [INFO] [logging.py:96:log_dist] [Rank 0] step=1370, skipped=0, lr=[8.219999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:44:35,017] [INFO] [timer.py:208:stop] epoch=0/micro_step=1370/global_step=1370, RunningAvgSamplesPerSec=4.742979087297423, CurrSamplesPerSec=4.742421016877503, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1370/  500000 | consumed samples:        43840 | consumed tokens:    179568640 | elapsed time per iteration (ms): 6760.8 | learning rate: 8.220E-05 | global batch size:    32 | lm loss: 1.180714E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1371/  500000 | consumed samples:        43872 | consumed tokens:    179699712 | elapsed time per iteration (ms): 6759.5 | learning rate: 8.226E-05 | global batch size:    32 | lm loss: 1.148323E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1372/  500000 | consumed samples:        43904 | consumed tokens:    179830784 | elapsed time per iteration (ms): 6758.9 | learning rate: 8.232E-05 | global batch size:    32 | lm loss: 1.141810E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.66 |
time (ms)
 iteration     1373/  500000 | consumed samples:        43936 | consumed tokens:    179961856 | elapsed time per iteration (ms): 6755.3 | learning rate: 8.238E-05 | global batch size:    32 | lm loss: 1.171902E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration     1374/  500000 | consumed samples:        43968 | consumed tokens:    180092928 | elapsed time per iteration (ms): 6763.1 | learning rate: 8.244E-05 | global batch size:    32 | lm loss: 1.182474E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration     1375/  500000 | consumed samples:        44000 | consumed tokens:    180224000 | elapsed time per iteration (ms): 6759.0 | learning rate: 8.250E-05 | global batch size:    32 | lm loss: 1.154634E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1376/  500000 | consumed samples:        44032 | consumed tokens:    180355072 | elapsed time per iteration (ms): 6758.0 | learning rate: 8.256E-05 | global batch size:    32 | lm loss: 1.199343E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1377/  500000 | consumed samples:        44064 | consumed tokens:    180486144 | elapsed time per iteration (ms): 6761.9 | learning rate: 8.262E-05 | global batch size:    32 | lm loss: 1.167302E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1378/  500000 | consumed samples:        44096 | consumed tokens:    180617216 | elapsed time per iteration (ms): 6760.2 | learning rate: 8.268E-05 | global batch size:    32 | lm loss: 1.209074E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration     1379/  500000 | consumed samples:        44128 | consumed tokens:    180748288 | elapsed time per iteration (ms): 6759.3 | learning rate: 8.274E-05 | global batch size:    32 | lm loss: 1.171059E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
[2023-10-10 17:45:42,418] [INFO] [logging.py:96:log_dist] [Rank 0] step=1380, skipped=0, lr=[8.28e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:45:42,656] [INFO] [timer.py:208:stop] epoch=0/micro_step=1380/global_step=1380, RunningAvgSamplesPerSec=4.742977523095611, CurrSamplesPerSec=4.740987908333414, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1380/  500000 | consumed samples:        44160 | consumed tokens:    180879360 | elapsed time per iteration (ms): 6761.7 | learning rate: 8.280E-05 | global batch size:    32 | lm loss: 1.176954E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     1381/  500000 | consumed samples:        44192 | consumed tokens:    181010432 | elapsed time per iteration (ms): 6758.7 | learning rate: 8.286E-05 | global batch size:    32 | lm loss: 1.167078E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1382/  500000 | consumed samples:        44224 | consumed tokens:    181141504 | elapsed time per iteration (ms): 6758.6 | learning rate: 8.292E-05 | global batch size:    32 | lm loss: 1.155802E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1383/  500000 | consumed samples:        44256 | consumed tokens:    181272576 | elapsed time per iteration (ms): 6757.4 | learning rate: 8.298E-05 | global batch size:    32 | lm loss: 1.157811E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1384/  500000 | consumed samples:        44288 | consumed tokens:    181403648 | elapsed time per iteration (ms): 6759.4 | learning rate: 8.304E-05 | global batch size:    32 | lm loss: 1.160328E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1385/  500000 | consumed samples:        44320 | consumed tokens:    181534720 | elapsed time per iteration (ms): 6761.0 | learning rate: 8.310E-05 | global batch size:    32 | lm loss: 1.176563E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1386/  500000 | consumed samples:        44352 | consumed tokens:    181665792 | elapsed time per iteration (ms): 6756.1 | learning rate: 8.316E-05 | global batch size:    32 | lm loss: 1.195894E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1387/  500000 | consumed samples:        44384 | consumed tokens:    181796864 | elapsed time per iteration (ms): 6757.9 | learning rate: 8.322E-05 | global batch size:    32 | lm loss: 1.182588E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1388/  500000 | consumed samples:        44416 | consumed tokens:    181927936 | elapsed time per iteration (ms): 6759.0 | learning rate: 8.328E-05 | global batch size:    32 | lm loss: 1.205243E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1389/  500000 | consumed samples:        44448 | consumed tokens:    182059008 | elapsed time per iteration (ms): 6756.9 | learning rate: 8.334E-05 | global batch size:    32 | lm loss: 1.184448E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
[2023-10-10 17:46:50,026] [INFO] [logging.py:96:log_dist] [Rank 0] step=1390, skipped=0, lr=[8.34e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:46:50,285] [INFO] [timer.py:208:stop] epoch=0/micro_step=1390/global_step=1390, RunningAvgSamplesPerSec=4.742981320952122, CurrSamplesPerSec=4.742206875016143, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1390/  500000 | consumed samples:        44480 | consumed tokens:    182190080 | elapsed time per iteration (ms): 6760.2 | learning rate: 8.340E-05 | global batch size:    32 | lm loss: 1.154519E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1391/  500000 | consumed samples:        44512 | consumed tokens:    182321152 | elapsed time per iteration (ms): 6757.2 | learning rate: 8.346E-05 | global batch size:    32 | lm loss: 1.158910E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1392/  500000 | consumed samples:        44544 | consumed tokens:    182452224 | elapsed time per iteration (ms): 6762.5 | learning rate: 8.352E-05 | global batch size:    32 | lm loss: 1.169205E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1393/  500000 | consumed samples:        44576 | consumed tokens:    182583296 | elapsed time per iteration (ms): 6761.3 | learning rate: 8.358E-05 | global batch size:    32 | lm loss: 1.169187E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1394/  500000 | consumed samples:        44608 | consumed tokens:    182714368 | elapsed time per iteration (ms): 6761.8 | learning rate: 8.364E-05 | global batch size:    32 | lm loss: 1.155986E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1395/  500000 | consumed samples:        44640 | consumed tokens:    182845440 | elapsed time per iteration (ms): 6758.3 | learning rate: 8.370E-05 | global batch size:    32 | lm loss: 1.175226E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1396/  500000 | consumed samples:        44672 | consumed tokens:    182976512 | elapsed time per iteration (ms): 6760.3 | learning rate: 8.376E-05 | global batch size:    32 | lm loss: 1.135599E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration     1397/  500000 | consumed samples:        44704 | consumed tokens:    183107584 | elapsed time per iteration (ms): 6758.9 | learning rate: 8.382E-05 | global batch size:    32 | lm loss: 1.181112E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.66 |
time (ms)
 iteration     1398/  500000 | consumed samples:        44736 | consumed tokens:    183238656 | elapsed time per iteration (ms): 6758.2 | learning rate: 8.388E-05 | global batch size:    32 | lm loss: 1.169929E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1399/  500000 | consumed samples:        44768 | consumed tokens:    183369728 | elapsed time per iteration (ms): 6756.5 | learning rate: 8.394E-05 | global batch size:    32 | lm loss: 1.184003E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
[2023-10-10 17:47:57,671] [INFO] [logging.py:96:log_dist] [Rank 0] step=1400, skipped=0, lr=[8.4e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:47:57,929] [INFO] [timer.py:208:stop] epoch=0/micro_step=1400/global_step=1400, RunningAvgSamplesPerSec=4.7429776561908685, CurrSamplesPerSec=4.738326351873888, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1400/  500000 | consumed samples:        44800 | consumed tokens:    183500800 | elapsed time per iteration (ms): 6765.6 | learning rate: 8.400E-05 | global batch size:    32 | lm loss: 1.201157E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration     1401/  500000 | consumed samples:        44832 | consumed tokens:    183631872 | elapsed time per iteration (ms): 6762.0 | learning rate: 8.406E-05 | global batch size:    32 | lm loss: 1.201710E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1402/  500000 | consumed samples:        44864 | consumed tokens:    183762944 | elapsed time per iteration (ms): 6760.2 | learning rate: 8.412E-05 | global batch size:    32 | lm loss: 1.255254E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1403/  500000 | consumed samples:        44896 | consumed tokens:    183894016 | elapsed time per iteration (ms): 6757.2 | learning rate: 8.418E-05 | global batch size:    32 | lm loss: 1.247666E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1404/  500000 | consumed samples:        44928 | consumed tokens:    184025088 | elapsed time per iteration (ms): 6763.1 | learning rate: 8.424E-05 | global batch size:    32 | lm loss: 1.213346E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration     1405/  500000 | consumed samples:        44960 | consumed tokens:    184156160 | elapsed time per iteration (ms): 6758.6 | learning rate: 8.430E-05 | global batch size:    32 | lm loss: 1.260219E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1406/  500000 | consumed samples:        44992 | consumed tokens:    184287232 | elapsed time per iteration (ms): 6761.6 | learning rate: 8.436E-05 | global batch size:    32 | lm loss: 1.230048E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     1407/  500000 | consumed samples:        45024 | consumed tokens:    184418304 | elapsed time per iteration (ms): 6758.7 | learning rate: 8.442E-05 | global batch size:    32 | lm loss: 1.214210E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1408/  500000 | consumed samples:        45056 | consumed tokens:    184549376 | elapsed time per iteration (ms): 6763.7 | learning rate: 8.448E-05 | global batch size:    32 | lm loss: 1.209666E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     1409/  500000 | consumed samples:        45088 | consumed tokens:    184680448 | elapsed time per iteration (ms): 6760.1 | learning rate: 8.454E-05 | global batch size:    32 | lm loss: 1.219948E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
[2023-10-10 17:49:05,318] [INFO] [logging.py:96:log_dist] [Rank 0] step=1410, skipped=0, lr=[8.46e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:49:05,576] [INFO] [timer.py:208:stop] epoch=0/micro_step=1410/global_step=1410, RunningAvgSamplesPerSec=4.742973184387736, CurrSamplesPerSec=4.742990815538601, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1410/  500000 | consumed samples:        45120 | consumed tokens:    184811520 | elapsed time per iteration (ms): 6759.5 | learning rate: 8.460E-05 | global batch size:    32 | lm loss: 1.243317E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1411/  500000 | consumed samples:        45152 | consumed tokens:    184942592 | elapsed time per iteration (ms): 6757.6 | learning rate: 8.466E-05 | global batch size:    32 | lm loss: 1.207374E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1412/  500000 | consumed samples:        45184 | consumed tokens:    185073664 | elapsed time per iteration (ms): 6756.2 | learning rate: 8.472E-05 | global batch size:    32 | lm loss: 1.253016E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1413/  500000 | consumed samples:        45216 | consumed tokens:    185204736 | elapsed time per iteration (ms): 6761.3 | learning rate: 8.478E-05 | global batch size:    32 | lm loss: 1.240468E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1414/  500000 | consumed samples:        45248 | consumed tokens:    185335808 | elapsed time per iteration (ms): 6762.4 | learning rate: 8.484E-05 | global batch size:    32 | lm loss: 1.222703E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1415/  500000 | consumed samples:        45280 | consumed tokens:    185466880 | elapsed time per iteration (ms): 6758.7 | learning rate: 8.490E-05 | global batch size:    32 | lm loss: 1.199688E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1416/  500000 | consumed samples:        45312 | consumed tokens:    185597952 | elapsed time per iteration (ms): 6759.9 | learning rate: 8.496E-05 | global batch size:    32 | lm loss: 1.172431E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1417/  500000 | consumed samples:        45344 | consumed tokens:    185729024 | elapsed time per iteration (ms): 6763.3 | learning rate: 8.502E-05 | global batch size:    32 | lm loss: 1.242033E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration     1418/  500000 | consumed samples:        45376 | consumed tokens:    185860096 | elapsed time per iteration (ms): 6764.1 | learning rate: 8.508E-05 | global batch size:    32 | lm loss: 1.192992E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     1419/  500000 | consumed samples:        45408 | consumed tokens:    185991168 | elapsed time per iteration (ms): 6761.4 | learning rate: 8.514E-05 | global batch size:    32 | lm loss: 1.186760E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
[2023-10-10 17:50:12,960] [INFO] [logging.py:96:log_dist] [Rank 0] step=1420, skipped=0, lr=[8.52e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:50:13,221] [INFO] [timer.py:208:stop] epoch=0/micro_step=1420/global_step=1420, RunningAvgSamplesPerSec=4.742968198616569, CurrSamplesPerSec=4.7437666321369365, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1420/  500000 | consumed samples:        45440 | consumed tokens:    186122240 | elapsed time per iteration (ms): 6758.2 | learning rate: 8.520E-05 | global batch size:    32 | lm loss: 1.200981E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1421/  500000 | consumed samples:        45472 | consumed tokens:    186253312 | elapsed time per iteration (ms): 6757.3 | learning rate: 8.526E-05 | global batch size:    32 | lm loss: 1.191950E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1422/  500000 | consumed samples:        45504 | consumed tokens:    186384384 | elapsed time per iteration (ms): 6758.0 | learning rate: 8.532E-05 | global batch size:    32 | lm loss: 1.184893E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1423/  500000 | consumed samples:        45536 | consumed tokens:    186515456 | elapsed time per iteration (ms): 6760.7 | learning rate: 8.538E-05 | global batch size:    32 | lm loss: 1.184535E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1424/  500000 | consumed samples:        45568 | consumed tokens:    186646528 | elapsed time per iteration (ms): 6759.7 | learning rate: 8.544E-05 | global batch size:    32 | lm loss: 1.204329E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1425/  500000 | consumed samples:        45600 | consumed tokens:    186777600 | elapsed time per iteration (ms): 6762.2 | learning rate: 8.550E-05 | global batch size:    32 | lm loss: 1.207139E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1426/  500000 | consumed samples:        45632 | consumed tokens:    186908672 | elapsed time per iteration (ms): 6759.7 | learning rate: 8.556E-05 | global batch size:    32 | lm loss: 1.200334E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1427/  500000 | consumed samples:        45664 | consumed tokens:    187039744 | elapsed time per iteration (ms): 6759.2 | learning rate: 8.562E-05 | global batch size:    32 | lm loss: 1.153538E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1428/  500000 | consumed samples:        45696 | consumed tokens:    187170816 | elapsed time per iteration (ms): 6760.4 | learning rate: 8.568E-05 | global batch size:    32 | lm loss: 1.184400E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1429/  500000 | consumed samples:        45728 | consumed tokens:    187301888 | elapsed time per iteration (ms): 6761.8 | learning rate: 8.574E-05 | global batch size:    32 | lm loss: 1.192238E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
[2023-10-10 17:51:20,616] [INFO] [logging.py:96:log_dist] [Rank 0] step=1430, skipped=0, lr=[8.579999999999998e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:51:20,864] [INFO] [timer.py:208:stop] epoch=0/micro_step=1430/global_step=1430, RunningAvgSamplesPerSec=4.7429658234194765, CurrSamplesPerSec=4.741070638202994, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1430/  500000 | consumed samples:        45760 | consumed tokens:    187432960 | elapsed time per iteration (ms): 6762.0 | learning rate: 8.580E-05 | global batch size:    32 | lm loss: 1.174675E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1431/  500000 | consumed samples:        45792 | consumed tokens:    187564032 | elapsed time per iteration (ms): 6761.1 | learning rate: 8.586E-05 | global batch size:    32 | lm loss: 1.195410E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1432/  500000 | consumed samples:        45824 | consumed tokens:    187695104 | elapsed time per iteration (ms): 6757.9 | learning rate: 8.592E-05 | global batch size:    32 | lm loss: 1.164075E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1433/  500000 | consumed samples:        45856 | consumed tokens:    187826176 | elapsed time per iteration (ms): 6761.8 | learning rate: 8.598E-05 | global batch size:    32 | lm loss: 1.184429E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1434/  500000 | consumed samples:        45888 | consumed tokens:    187957248 | elapsed time per iteration (ms): 6763.8 | learning rate: 8.604E-05 | global batch size:    32 | lm loss: 1.154323E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     1435/  500000 | consumed samples:        45920 | consumed tokens:    188088320 | elapsed time per iteration (ms): 6766.3 | learning rate: 8.610E-05 | global batch size:    32 | lm loss: 1.174909E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.50 |
time (ms)
 iteration     1436/  500000 | consumed samples:        45952 | consumed tokens:    188219392 | elapsed time per iteration (ms): 6759.9 | learning rate: 8.616E-05 | global batch size:    32 | lm loss: 1.132229E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1437/  500000 | consumed samples:        45984 | consumed tokens:    188350464 | elapsed time per iteration (ms): 6760.1 | learning rate: 8.622E-05 | global batch size:    32 | lm loss: 1.167515E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1438/  500000 | consumed samples:        46016 | consumed tokens:    188481536 | elapsed time per iteration (ms): 6760.5 | learning rate: 8.628E-05 | global batch size:    32 | lm loss: 1.143993E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1439/  500000 | consumed samples:        46048 | consumed tokens:    188612608 | elapsed time per iteration (ms): 6762.0 | learning rate: 8.634E-05 | global batch size:    32 | lm loss: 1.176660E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
[2023-10-10 17:52:28,273] [INFO] [logging.py:96:log_dist] [Rank 0] step=1440, skipped=0, lr=[8.639999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:52:28,521] [INFO] [timer.py:208:stop] epoch=0/micro_step=1440/global_step=1440, RunningAvgSamplesPerSec=4.742959389833902, CurrSamplesPerSec=4.7431311075649525, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1440/  500000 | consumed samples:        46080 | consumed tokens:    188743680 | elapsed time per iteration (ms): 6759.6 | learning rate: 8.640E-05 | global batch size:    32 | lm loss: 1.178639E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1441/  500000 | consumed samples:        46112 | consumed tokens:    188874752 | elapsed time per iteration (ms): 6760.1 | learning rate: 8.646E-05 | global batch size:    32 | lm loss: 1.182510E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1442/  500000 | consumed samples:        46144 | consumed tokens:    189005824 | elapsed time per iteration (ms): 6760.1 | learning rate: 8.652E-05 | global batch size:    32 | lm loss: 1.179932E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1443/  500000 | consumed samples:        46176 | consumed tokens:    189136896 | elapsed time per iteration (ms): 6758.1 | learning rate: 8.658E-05 | global batch size:    32 | lm loss: 1.157724E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1444/  500000 | consumed samples:        46208 | consumed tokens:    189267968 | elapsed time per iteration (ms): 6757.6 | learning rate: 8.664E-05 | global batch size:    32 | lm loss: 1.202595E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1445/  500000 | consumed samples:        46240 | consumed tokens:    189399040 | elapsed time per iteration (ms): 6758.4 | learning rate: 8.670E-05 | global batch size:    32 | lm loss: 1.159365E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1446/  500000 | consumed samples:        46272 | consumed tokens:    189530112 | elapsed time per iteration (ms): 6758.5 | learning rate: 8.676E-05 | global batch size:    32 | lm loss: 1.178530E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1447/  500000 | consumed samples:        46304 | consumed tokens:    189661184 | elapsed time per iteration (ms): 6760.9 | learning rate: 8.682E-05 | global batch size:    32 | lm loss: 1.159021E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1448/  500000 | consumed samples:        46336 | consumed tokens:    189792256 | elapsed time per iteration (ms): 6761.1 | learning rate: 8.688E-05 | global batch size:    32 | lm loss: 1.148667E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1449/  500000 | consumed samples:        46368 | consumed tokens:    189923328 | elapsed time per iteration (ms): 6758.4 | learning rate: 8.694E-05 | global batch size:    32 | lm loss: 1.197509E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
[2023-10-10 17:53:35,897] [INFO] [logging.py:96:log_dist] [Rank 0] step=1450, skipped=0, lr=[8.699999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:53:36,158] [INFO] [timer.py:208:stop] epoch=0/micro_step=1450/global_step=1450, RunningAvgSamplesPerSec=4.742961259074643, CurrSamplesPerSec=4.741376462337742, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1450/  500000 | consumed samples:        46400 | consumed tokens:    190054400 | elapsed time per iteration (ms): 6762.0 | learning rate: 8.700E-05 | global batch size:    32 | lm loss: 1.135153E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1451/  500000 | consumed samples:        46432 | consumed tokens:    190185472 | elapsed time per iteration (ms): 6760.7 | learning rate: 8.706E-05 | global batch size:    32 | lm loss: 1.151749E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1452/  500000 | consumed samples:        46464 | consumed tokens:    190316544 | elapsed time per iteration (ms): 6757.8 | learning rate: 8.712E-05 | global batch size:    32 | lm loss: 1.198079E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1453/  500000 | consumed samples:        46496 | consumed tokens:    190447616 | elapsed time per iteration (ms): 6757.2 | learning rate: 8.718E-05 | global batch size:    32 | lm loss: 1.138081E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1454/  500000 | consumed samples:        46528 | consumed tokens:    190578688 | elapsed time per iteration (ms): 6762.1 | learning rate: 8.724E-05 | global batch size:    32 | lm loss: 1.131889E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1455/  500000 | consumed samples:        46560 | consumed tokens:    190709760 | elapsed time per iteration (ms): 6759.1 | learning rate: 8.730E-05 | global batch size:    32 | lm loss: 1.153310E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1456/  500000 | consumed samples:        46592 | consumed tokens:    190840832 | elapsed time per iteration (ms): 6758.5 | learning rate: 8.736E-05 | global batch size:    32 | lm loss: 1.154536E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1457/  500000 | consumed samples:        46624 | consumed tokens:    190971904 | elapsed time per iteration (ms): 6762.4 | learning rate: 8.742E-05 | global batch size:    32 | lm loss: 1.205631E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1458/  500000 | consumed samples:        46656 | consumed tokens:    191102976 | elapsed time per iteration (ms): 6761.0 | learning rate: 8.748E-05 | global batch size:    32 | lm loss: 1.151553E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1459/  500000 | consumed samples:        46688 | consumed tokens:    191234048 | elapsed time per iteration (ms): 6760.3 | learning rate: 8.754E-05 | global batch size:    32 | lm loss: 1.176515E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
[2023-10-10 17:54:43,544] [INFO] [logging.py:96:log_dist] [Rank 0] step=1460, skipped=0, lr=[8.759999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:54:43,807] [INFO] [timer.py:208:stop] epoch=0/micro_step=1460/global_step=1460, RunningAvgSamplesPerSec=4.742956215089923, CurrSamplesPerSec=4.737517865707485, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1460/  500000 | consumed samples:        46720 | consumed tokens:    191365120 | elapsed time per iteration (ms): 6767.3 | learning rate: 8.760E-05 | global batch size:    32 | lm loss: 1.224337E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.48 |
time (ms)
 iteration     1461/  500000 | consumed samples:        46752 | consumed tokens:    191496192 | elapsed time per iteration (ms): 6762.9 | learning rate: 8.766E-05 | global batch size:    32 | lm loss: 1.159591E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1462/  500000 | consumed samples:        46784 | consumed tokens:    191627264 | elapsed time per iteration (ms): 6763.8 | learning rate: 8.772E-05 | global batch size:    32 | lm loss: 1.164939E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     1463/  500000 | consumed samples:        46816 | consumed tokens:    191758336 | elapsed time per iteration (ms): 6758.4 | learning rate: 8.778E-05 | global batch size:    32 | lm loss: 1.193161E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1464/  500000 | consumed samples:        46848 | consumed tokens:    191889408 | elapsed time per iteration (ms): 6759.1 | learning rate: 8.784E-05 | global batch size:    32 | lm loss: 1.194847E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1465/  500000 | consumed samples:        46880 | consumed tokens:    192020480 | elapsed time per iteration (ms): 6761.7 | learning rate: 8.790E-05 | global batch size:    32 | lm loss: 1.151930E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     1466/  500000 | consumed samples:        46912 | consumed tokens:    192151552 | elapsed time per iteration (ms): 6766.9 | learning rate: 8.796E-05 | global batch size:    32 | lm loss: 1.163048E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.49 |
time (ms)
 iteration     1467/  500000 | consumed samples:        46944 | consumed tokens:    192282624 | elapsed time per iteration (ms): 6759.5 | learning rate: 8.802E-05 | global batch size:    32 | lm loss: 1.192252E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1468/  500000 | consumed samples:        46976 | consumed tokens:    192413696 | elapsed time per iteration (ms): 6755.9 | learning rate: 8.808E-05 | global batch size:    32 | lm loss: 1.144630E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration     1469/  500000 | consumed samples:        47008 | consumed tokens:    192544768 | elapsed time per iteration (ms): 6759.9 | learning rate: 8.814E-05 | global batch size:    32 | lm loss: 1.147742E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
[2023-10-10 17:55:51,197] [INFO] [logging.py:96:log_dist] [Rank 0] step=1470, skipped=0, lr=[8.819999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:55:51,458] [INFO] [timer.py:208:stop] epoch=0/micro_step=1470/global_step=1470, RunningAvgSamplesPerSec=4.742951936629512, CurrSamplesPerSec=4.742459222622797, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1470/  500000 | consumed samples:        47040 | consumed tokens:    192675840 | elapsed time per iteration (ms): 6759.5 | learning rate: 8.820E-05 | global batch size:    32 | lm loss: 1.167945E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1471/  500000 | consumed samples:        47072 | consumed tokens:    192806912 | elapsed time per iteration (ms): 6759.9 | learning rate: 8.826E-05 | global batch size:    32 | lm loss: 1.137806E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1472/  500000 | consumed samples:        47104 | consumed tokens:    192937984 | elapsed time per iteration (ms): 6758.4 | learning rate: 8.832E-05 | global batch size:    32 | lm loss: 1.142354E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1473/  500000 | consumed samples:        47136 | consumed tokens:    193069056 | elapsed time per iteration (ms): 6762.7 | learning rate: 8.838E-05 | global batch size:    32 | lm loss: 1.144337E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1474/  500000 | consumed samples:        47168 | consumed tokens:    193200128 | elapsed time per iteration (ms): 6768.1 | learning rate: 8.844E-05 | global batch size:    32 | lm loss: 1.180514E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.728 | TFLOPs: 147.46 |
time (ms)
 iteration     1475/  500000 | consumed samples:        47200 | consumed tokens:    193331200 | elapsed time per iteration (ms): 6764.4 | learning rate: 8.850E-05 | global batch size:    32 | lm loss: 1.218901E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.54 |
time (ms)
 iteration     1476/  500000 | consumed samples:        47232 | consumed tokens:    193462272 | elapsed time per iteration (ms): 6763.4 | learning rate: 8.856E-05 | global batch size:    32 | lm loss: 1.167737E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration     1477/  500000 | consumed samples:        47264 | consumed tokens:    193593344 | elapsed time per iteration (ms): 6761.9 | learning rate: 8.862E-05 | global batch size:    32 | lm loss: 1.196227E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1478/  500000 | consumed samples:        47296 | consumed tokens:    193724416 | elapsed time per iteration (ms): 6760.7 | learning rate: 8.868E-05 | global batch size:    32 | lm loss: 1.153394E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1479/  500000 | consumed samples:        47328 | consumed tokens:    193855488 | elapsed time per iteration (ms): 6758.9 | learning rate: 8.874E-05 | global batch size:    32 | lm loss: 1.135461E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
[2023-10-10 17:56:58,867] [INFO] [logging.py:96:log_dist] [Rank 0] step=1480, skipped=0, lr=[8.879999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:56:59,120] [INFO] [timer.py:208:stop] epoch=0/micro_step=1480/global_step=1480, RunningAvgSamplesPerSec=4.742941624808535, CurrSamplesPerSec=4.741548987332552, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1480/  500000 | consumed samples:        47360 | consumed tokens:    193986560 | elapsed time per iteration (ms): 6761.2 | learning rate: 8.880E-05 | global batch size:    32 | lm loss: 1.112808E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1481/  500000 | consumed samples:        47392 | consumed tokens:    194117632 | elapsed time per iteration (ms): 6760.2 | learning rate: 8.886E-05 | global batch size:    32 | lm loss: 1.147471E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1482/  500000 | consumed samples:        47424 | consumed tokens:    194248704 | elapsed time per iteration (ms): 6762.8 | learning rate: 8.892E-05 | global batch size:    32 | lm loss: 1.159113E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1483/  500000 | consumed samples:        47456 | consumed tokens:    194379776 | elapsed time per iteration (ms): 6762.0 | learning rate: 8.898E-05 | global batch size:    32 | lm loss: 1.201775E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1484/  500000 | consumed samples:        47488 | consumed tokens:    194510848 | elapsed time per iteration (ms): 6761.8 | learning rate: 8.904E-05 | global batch size:    32 | lm loss: 1.180633E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1485/  500000 | consumed samples:        47520 | consumed tokens:    194641920 | elapsed time per iteration (ms): 6760.6 | learning rate: 8.910E-05 | global batch size:    32 | lm loss: 1.162592E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1486/  500000 | consumed samples:        47552 | consumed tokens:    194772992 | elapsed time per iteration (ms): 6758.3 | learning rate: 8.916E-05 | global batch size:    32 | lm loss: 1.145466E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1487/  500000 | consumed samples:        47584 | consumed tokens:    194904064 | elapsed time per iteration (ms): 6757.1 | learning rate: 8.922E-05 | global batch size:    32 | lm loss: 1.168211E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1488/  500000 | consumed samples:        47616 | consumed tokens:    195035136 | elapsed time per iteration (ms): 6758.9 | learning rate: 8.928E-05 | global batch size:    32 | lm loss: 1.128652E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.66 |
time (ms)
 iteration     1489/  500000 | consumed samples:        47648 | consumed tokens:    195166208 | elapsed time per iteration (ms): 6759.4 | learning rate: 8.934E-05 | global batch size:    32 | lm loss: 1.133133E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
[2023-10-10 17:58:06,504] [INFO] [logging.py:96:log_dist] [Rank 0] step=1490, skipped=0, lr=[8.939999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:58:06,763] [INFO] [timer.py:208:stop] epoch=0/micro_step=1490/global_step=1490, RunningAvgSamplesPerSec=4.7429409820879975, CurrSamplesPerSec=4.742797739009055, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1490/  500000 | consumed samples:        47680 | consumed tokens:    195297280 | elapsed time per iteration (ms): 6760.3 | learning rate: 8.940E-05 | global batch size:    32 | lm loss: 1.137849E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1491/  500000 | consumed samples:        47712 | consumed tokens:    195428352 | elapsed time per iteration (ms): 6760.8 | learning rate: 8.946E-05 | global batch size:    32 | lm loss: 1.136720E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1492/  500000 | consumed samples:        47744 | consumed tokens:    195559424 | elapsed time per iteration (ms): 6760.9 | learning rate: 8.952E-05 | global batch size:    32 | lm loss: 1.153578E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1493/  500000 | consumed samples:        47776 | consumed tokens:    195690496 | elapsed time per iteration (ms): 6759.6 | learning rate: 8.958E-05 | global batch size:    32 | lm loss: 1.190937E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1494/  500000 | consumed samples:        47808 | consumed tokens:    195821568 | elapsed time per iteration (ms): 6761.1 | learning rate: 8.964E-05 | global batch size:    32 | lm loss: 1.127354E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1495/  500000 | consumed samples:        47840 | consumed tokens:    195952640 | elapsed time per iteration (ms): 6759.5 | learning rate: 8.970E-05 | global batch size:    32 | lm loss: 1.152435E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1496/  500000 | consumed samples:        47872 | consumed tokens:    196083712 | elapsed time per iteration (ms): 6761.4 | learning rate: 8.976E-05 | global batch size:    32 | lm loss: 1.145077E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1497/  500000 | consumed samples:        47904 | consumed tokens:    196214784 | elapsed time per iteration (ms): 6760.5 | learning rate: 8.982E-05 | global batch size:    32 | lm loss: 1.103215E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1498/  500000 | consumed samples:        47936 | consumed tokens:    196345856 | elapsed time per iteration (ms): 6760.6 | learning rate: 8.988E-05 | global batch size:    32 | lm loss: 1.122151E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1499/  500000 | consumed samples:        47968 | consumed tokens:    196476928 | elapsed time per iteration (ms): 6755.3 | learning rate: 8.994E-05 | global batch size:    32 | lm loss: 1.136014E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
[2023-10-10 17:59:14,140] [INFO] [logging.py:96:log_dist] [Rank 0] step=1500, skipped=0, lr=[8.999999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 17:59:14,402] [INFO] [timer.py:208:stop] epoch=0/micro_step=1500/global_step=1500, RunningAvgSamplesPerSec=4.742941304793275, CurrSamplesPerSec=4.745834983725209, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1500/  500000 | consumed samples:        48000 | consumed tokens:    196608000 | elapsed time per iteration (ms): 6755.5 | learning rate: 9.000E-05 | global batch size:    32 | lm loss: 1.145297E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration     1501/  500000 | consumed samples:        48032 | consumed tokens:    196739072 | elapsed time per iteration (ms): 6761.4 | learning rate: 9.006E-05 | global batch size:    32 | lm loss: 1.158046E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1502/  500000 | consumed samples:        48064 | consumed tokens:    196870144 | elapsed time per iteration (ms): 6757.5 | learning rate: 9.012E-05 | global batch size:    32 | lm loss: 1.182819E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1503/  500000 | consumed samples:        48096 | consumed tokens:    197001216 | elapsed time per iteration (ms): 6763.4 | learning rate: 9.018E-05 | global batch size:    32 | lm loss: 1.164425E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration     1504/  500000 | consumed samples:        48128 | consumed tokens:    197132288 | elapsed time per iteration (ms): 6758.6 | learning rate: 9.024E-05 | global batch size:    32 | lm loss: 1.165075E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1505/  500000 | consumed samples:        48160 | consumed tokens:    197263360 | elapsed time per iteration (ms): 6758.2 | learning rate: 9.030E-05 | global batch size:    32 | lm loss: 1.137533E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1506/  500000 | consumed samples:        48192 | consumed tokens:    197394432 | elapsed time per iteration (ms): 6761.6 | learning rate: 9.036E-05 | global batch size:    32 | lm loss: 1.194745E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     1507/  500000 | consumed samples:        48224 | consumed tokens:    197525504 | elapsed time per iteration (ms): 6765.0 | learning rate: 9.042E-05 | global batch size:    32 | lm loss: 1.153606E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration     1508/  500000 | consumed samples:        48256 | consumed tokens:    197656576 | elapsed time per iteration (ms): 6760.8 | learning rate: 9.048E-05 | global batch size:    32 | lm loss: 1.162004E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1509/  500000 | consumed samples:        48288 | consumed tokens:    197787648 | elapsed time per iteration (ms): 6757.5 | learning rate: 9.054E-05 | global batch size:    32 | lm loss: 1.114747E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.70 |
time (ms)
[2023-10-10 18:00:21,788] [INFO] [logging.py:96:log_dist] [Rank 0] step=1510, skipped=0, lr=[9.059999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 18:00:22,046] [INFO] [timer.py:208:stop] epoch=0/micro_step=1510/global_step=1510, RunningAvgSamplesPerSec=4.742938988673016, CurrSamplesPerSec=4.744539348228112, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1510/  500000 | consumed samples:        48320 | consumed tokens:    197918720 | elapsed time per iteration (ms): 6759.0 | learning rate: 9.060E-05 | global batch size:    32 | lm loss: 1.175316E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1511/  500000 | consumed samples:        48352 | consumed tokens:    198049792 | elapsed time per iteration (ms): 6761.0 | learning rate: 9.066E-05 | global batch size:    32 | lm loss: 1.138751E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1512/  500000 | consumed samples:        48384 | consumed tokens:    198180864 | elapsed time per iteration (ms): 6762.1 | learning rate: 9.072E-05 | global batch size:    32 | lm loss: 1.171412E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1513/  500000 | consumed samples:        48416 | consumed tokens:    198311936 | elapsed time per iteration (ms): 6756.7 | learning rate: 9.078E-05 | global batch size:    32 | lm loss: 1.155377E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1514/  500000 | consumed samples:        48448 | consumed tokens:    198443008 | elapsed time per iteration (ms): 6759.7 | learning rate: 9.084E-05 | global batch size:    32 | lm loss: 1.168354E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1515/  500000 | consumed samples:        48480 | consumed tokens:    198574080 | elapsed time per iteration (ms): 6757.8 | learning rate: 9.090E-05 | global batch size:    32 | lm loss: 1.149597E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1516/  500000 | consumed samples:        48512 | consumed tokens:    198705152 | elapsed time per iteration (ms): 6760.3 | learning rate: 9.096E-05 | global batch size:    32 | lm loss: 1.165731E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1517/  500000 | consumed samples:        48544 | consumed tokens:    198836224 | elapsed time per iteration (ms): 6761.0 | learning rate: 9.102E-05 | global batch size:    32 | lm loss: 1.167789E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1518/  500000 | consumed samples:        48576 | consumed tokens:    198967296 | elapsed time per iteration (ms): 6754.8 | learning rate: 9.108E-05 | global batch size:    32 | lm loss: 1.141929E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.75 |
time (ms)
 iteration     1519/  500000 | consumed samples:        48608 | consumed tokens:    199098368 | elapsed time per iteration (ms): 6759.0 | learning rate: 9.114E-05 | global batch size:    32 | lm loss: 1.177608E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
[2023-10-10 18:01:29,444] [INFO] [logging.py:96:log_dist] [Rank 0] step=1520, skipped=0, lr=[9.12e-05], mom=[(0.9, 0.95)]
[2023-10-10 18:01:29,680] [INFO] [timer.py:208:stop] epoch=0/micro_step=1520/global_step=1520, RunningAvgSamplesPerSec=4.7429403266572745, CurrSamplesPerSec=4.743036237735375, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1520/  500000 | consumed samples:        48640 | consumed tokens:    199229440 | elapsed time per iteration (ms): 6759.1 | learning rate: 9.120E-05 | global batch size:    32 | lm loss: 1.120826E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1521/  500000 | consumed samples:        48672 | consumed tokens:    199360512 | elapsed time per iteration (ms): 6756.1 | learning rate: 9.126E-05 | global batch size:    32 | lm loss: 1.139671E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.73 |
time (ms)
 iteration     1522/  500000 | consumed samples:        48704 | consumed tokens:    199491584 | elapsed time per iteration (ms): 6761.3 | learning rate: 9.132E-05 | global batch size:    32 | lm loss: 1.131633E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1523/  500000 | consumed samples:        48736 | consumed tokens:    199622656 | elapsed time per iteration (ms): 6760.4 | learning rate: 9.138E-05 | global batch size:    32 | lm loss: 1.175730E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1524/  500000 | consumed samples:        48768 | consumed tokens:    199753728 | elapsed time per iteration (ms): 6761.5 | learning rate: 9.144E-05 | global batch size:    32 | lm loss: 1.140766E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1525/  500000 | consumed samples:        48800 | consumed tokens:    199884800 | elapsed time per iteration (ms): 6762.6 | learning rate: 9.150E-05 | global batch size:    32 | lm loss: 1.161033E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1526/  500000 | consumed samples:        48832 | consumed tokens:    200015872 | elapsed time per iteration (ms): 6761.2 | learning rate: 9.156E-05 | global batch size:    32 | lm loss: 1.191571E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1527/  500000 | consumed samples:        48864 | consumed tokens:    200146944 | elapsed time per iteration (ms): 6765.3 | learning rate: 9.162E-05 | global batch size:    32 | lm loss: 1.134500E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration     1528/  500000 | consumed samples:        48896 | consumed tokens:    200278016 | elapsed time per iteration (ms): 6765.6 | learning rate: 9.168E-05 | global batch size:    32 | lm loss: 1.169876E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration     1529/  500000 | consumed samples:        48928 | consumed tokens:    200409088 | elapsed time per iteration (ms): 6762.6 | learning rate: 9.174E-05 | global batch size:    32 | lm loss: 1.129172E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
[2023-10-10 18:02:37,086] [INFO] [logging.py:96:log_dist] [Rank 0] step=1530, skipped=0, lr=[9.18e-05], mom=[(0.9, 0.95)]
[2023-10-10 18:02:37,343] [INFO] [timer.py:208:stop] epoch=0/micro_step=1530/global_step=1530, RunningAvgSamplesPerSec=4.742929494517864, CurrSamplesPerSec=4.740897980555914, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1530/  500000 | consumed samples:        48960 | consumed tokens:    200540160 | elapsed time per iteration (ms): 6762.9 | learning rate: 9.180E-05 | global batch size:    32 | lm loss: 1.166644E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1531/  500000 | consumed samples:        48992 | consumed tokens:    200671232 | elapsed time per iteration (ms): 6764.9 | learning rate: 9.186E-05 | global batch size:    32 | lm loss: 1.165542E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration     1532/  500000 | consumed samples:        49024 | consumed tokens:    200802304 | elapsed time per iteration (ms): 6762.6 | learning rate: 9.192E-05 | global batch size:    32 | lm loss: 1.139433E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1533/  500000 | consumed samples:        49056 | consumed tokens:    200933376 | elapsed time per iteration (ms): 6762.0 | learning rate: 9.198E-05 | global batch size:    32 | lm loss: 1.175405E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1534/  500000 | consumed samples:        49088 | consumed tokens:    201064448 | elapsed time per iteration (ms): 6764.9 | learning rate: 9.204E-05 | global batch size:    32 | lm loss: 1.162134E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration     1535/  500000 | consumed samples:        49120 | consumed tokens:    201195520 | elapsed time per iteration (ms): 6755.3 | learning rate: 9.210E-05 | global batch size:    32 | lm loss: 1.146952E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration     1536/  500000 | consumed samples:        49152 | consumed tokens:    201326592 | elapsed time per iteration (ms): 6757.5 | learning rate: 9.216E-05 | global batch size:    32 | lm loss: 1.173111E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1537/  500000 | consumed samples:        49184 | consumed tokens:    201457664 | elapsed time per iteration (ms): 6760.1 | learning rate: 9.222E-05 | global batch size:    32 | lm loss: 1.159975E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1538/  500000 | consumed samples:        49216 | consumed tokens:    201588736 | elapsed time per iteration (ms): 6760.2 | learning rate: 9.228E-05 | global batch size:    32 | lm loss: 1.159411E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1539/  500000 | consumed samples:        49248 | consumed tokens:    201719808 | elapsed time per iteration (ms): 6755.3 | learning rate: 9.234E-05 | global batch size:    32 | lm loss: 1.148910E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
[2023-10-10 18:03:44,733] [INFO] [logging.py:96:log_dist] [Rank 0] step=1540, skipped=0, lr=[9.24e-05], mom=[(0.9, 0.95)]
[2023-10-10 18:03:44,989] [INFO] [timer.py:208:stop] epoch=0/micro_step=1540/global_step=1540, RunningAvgSamplesPerSec=4.742928350677251, CurrSamplesPerSec=4.743407525577708, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1540/  500000 | consumed samples:        49280 | consumed tokens:    201850880 | elapsed time per iteration (ms): 6760.1 | learning rate: 9.240E-05 | global batch size:    32 | lm loss: 1.148614E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1541/  500000 | consumed samples:        49312 | consumed tokens:    201981952 | elapsed time per iteration (ms): 6756.0 | learning rate: 9.246E-05 | global batch size:    32 | lm loss: 1.195252E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration     1542/  500000 | consumed samples:        49344 | consumed tokens:    202113024 | elapsed time per iteration (ms): 6757.9 | learning rate: 9.252E-05 | global batch size:    32 | lm loss: 1.106446E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1543/  500000 | consumed samples:        49376 | consumed tokens:    202244096 | elapsed time per iteration (ms): 6755.5 | learning rate: 9.258E-05 | global batch size:    32 | lm loss: 1.131958E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration     1544/  500000 | consumed samples:        49408 | consumed tokens:    202375168 | elapsed time per iteration (ms): 6758.0 | learning rate: 9.264E-05 | global batch size:    32 | lm loss: 1.136294E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1545/  500000 | consumed samples:        49440 | consumed tokens:    202506240 | elapsed time per iteration (ms): 6760.4 | learning rate: 9.270E-05 | global batch size:    32 | lm loss: 1.164261E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1546/  500000 | consumed samples:        49472 | consumed tokens:    202637312 | elapsed time per iteration (ms): 6762.1 | learning rate: 9.276E-05 | global batch size:    32 | lm loss: 1.163471E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1547/  500000 | consumed samples:        49504 | consumed tokens:    202768384 | elapsed time per iteration (ms): 6762.1 | learning rate: 9.282E-05 | global batch size:    32 | lm loss: 1.173483E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1548/  500000 | consumed samples:        49536 | consumed tokens:    202899456 | elapsed time per iteration (ms): 6763.1 | learning rate: 9.288E-05 | global batch size:    32 | lm loss: 1.126342E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration     1549/  500000 | consumed samples:        49568 | consumed tokens:    203030528 | elapsed time per iteration (ms): 6758.6 | learning rate: 9.294E-05 | global batch size:    32 | lm loss: 1.158206E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
[2023-10-10 18:04:52,366] [INFO] [logging.py:96:log_dist] [Rank 0] step=1550, skipped=0, lr=[9.3e-05], mom=[(0.9, 0.95)]
[2023-10-10 18:04:52,625] [INFO] [timer.py:208:stop] epoch=0/micro_step=1550/global_step=1550, RunningAvgSamplesPerSec=4.742932252865151, CurrSamplesPerSec=4.74356393645708, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1550/  500000 | consumed samples:        49600 | consumed tokens:    203161600 | elapsed time per iteration (ms): 6758.4 | learning rate: 9.300E-05 | global batch size:    32 | lm loss: 1.153154E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1551/  500000 | consumed samples:        49632 | consumed tokens:    203292672 | elapsed time per iteration (ms): 6762.5 | learning rate: 9.306E-05 | global batch size:    32 | lm loss: 1.158298E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1552/  500000 | consumed samples:        49664 | consumed tokens:    203423744 | elapsed time per iteration (ms): 6761.2 | learning rate: 9.312E-05 | global batch size:    32 | lm loss: 1.154985E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1553/  500000 | consumed samples:        49696 | consumed tokens:    203554816 | elapsed time per iteration (ms): 6756.5 | learning rate: 9.318E-05 | global batch size:    32 | lm loss: 1.179054E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1554/  500000 | consumed samples:        49728 | consumed tokens:    203685888 | elapsed time per iteration (ms): 6760.1 | learning rate: 9.324E-05 | global batch size:    32 | lm loss: 1.135604E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1555/  500000 | consumed samples:        49760 | consumed tokens:    203816960 | elapsed time per iteration (ms): 6759.1 | learning rate: 9.330E-05 | global batch size:    32 | lm loss: 1.178800E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1556/  500000 | consumed samples:        49792 | consumed tokens:    203948032 | elapsed time per iteration (ms): 6758.9 | learning rate: 9.336E-05 | global batch size:    32 | lm loss: 1.167650E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1557/  500000 | consumed samples:        49824 | consumed tokens:    204079104 | elapsed time per iteration (ms): 6760.7 | learning rate: 9.342E-05 | global batch size:    32 | lm loss: 1.143918E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1558/  500000 | consumed samples:        49856 | consumed tokens:    204210176 | elapsed time per iteration (ms): 6760.4 | learning rate: 9.348E-05 | global batch size:    32 | lm loss: 1.165948E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1559/  500000 | consumed samples:        49888 | consumed tokens:    204341248 | elapsed time per iteration (ms): 6762.1 | learning rate: 9.354E-05 | global batch size:    32 | lm loss: 1.121456E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
[2023-10-10 18:06:00,019] [INFO] [logging.py:96:log_dist] [Rank 0] step=1560, skipped=0, lr=[9.36e-05], mom=[(0.9, 0.95)]
[2023-10-10 18:06:00,268] [INFO] [timer.py:208:stop] epoch=0/micro_step=1560/global_step=1560, RunningAvgSamplesPerSec=4.742929693526853, CurrSamplesPerSec=4.7430313770159245, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1560/  500000 | consumed samples:        49920 | consumed tokens:    204472320 | elapsed time per iteration (ms): 6759.2 | learning rate: 9.360E-05 | global batch size:    32 | lm loss: 1.141367E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1561/  500000 | consumed samples:        49952 | consumed tokens:    204603392 | elapsed time per iteration (ms): 6760.0 | learning rate: 9.366E-05 | global batch size:    32 | lm loss: 1.117446E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1562/  500000 | consumed samples:        49984 | consumed tokens:    204734464 | elapsed time per iteration (ms): 6758.3 | learning rate: 9.372E-05 | global batch size:    32 | lm loss: 1.125547E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1563/  500000 | consumed samples:        50016 | consumed tokens:    204865536 | elapsed time per iteration (ms): 6758.7 | learning rate: 9.378E-05 | global batch size:    32 | lm loss: 1.139552E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1564/  500000 | consumed samples:        50048 | consumed tokens:    204996608 | elapsed time per iteration (ms): 6757.7 | learning rate: 9.384E-05 | global batch size:    32 | lm loss: 1.159434E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1565/  500000 | consumed samples:        50080 | consumed tokens:    205127680 | elapsed time per iteration (ms): 6762.6 | learning rate: 9.390E-05 | global batch size:    32 | lm loss: 1.133445E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1566/  500000 | consumed samples:        50112 | consumed tokens:    205258752 | elapsed time per iteration (ms): 6755.5 | learning rate: 9.396E-05 | global batch size:    32 | lm loss: 1.164117E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration     1567/  500000 | consumed samples:        50144 | consumed tokens:    205389824 | elapsed time per iteration (ms): 6757.7 | learning rate: 9.402E-05 | global batch size:    32 | lm loss: 1.191697E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1568/  500000 | consumed samples:        50176 | consumed tokens:    205520896 | elapsed time per iteration (ms): 6756.8 | learning rate: 9.408E-05 | global batch size:    32 | lm loss: 1.148032E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1569/  500000 | consumed samples:        50208 | consumed tokens:    205651968 | elapsed time per iteration (ms): 6758.4 | learning rate: 9.414E-05 | global batch size:    32 | lm loss: 1.140306E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
[2023-10-10 18:07:07,633] [INFO] [logging.py:96:log_dist] [Rank 0] step=1570, skipped=0, lr=[9.42e-05], mom=[(0.9, 0.95)]
[2023-10-10 18:07:07,895] [INFO] [timer.py:208:stop] epoch=0/micro_step=1570/global_step=1570, RunningAvgSamplesPerSec=4.742935320523982, CurrSamplesPerSec=4.743823638178466, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1570/  500000 | consumed samples:        50240 | consumed tokens:    205783040 | elapsed time per iteration (ms): 6758.7 | learning rate: 9.420E-05 | global batch size:    32 | lm loss: 1.189216E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1571/  500000 | consumed samples:        50272 | consumed tokens:    205914112 | elapsed time per iteration (ms): 6767.8 | learning rate: 9.426E-05 | global batch size:    32 | lm loss: 1.170702E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.728 | TFLOPs: 147.47 |
time (ms)
 iteration     1572/  500000 | consumed samples:        50304 | consumed tokens:    206045184 | elapsed time per iteration (ms): 6765.8 | learning rate: 9.432E-05 | global batch size:    32 | lm loss: 1.130656E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.51 |
time (ms)
 iteration     1573/  500000 | consumed samples:        50336 | consumed tokens:    206176256 | elapsed time per iteration (ms): 6764.1 | learning rate: 9.438E-05 | global batch size:    32 | lm loss: 1.185196E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     1574/  500000 | consumed samples:        50368 | consumed tokens:    206307328 | elapsed time per iteration (ms): 6762.8 | learning rate: 9.444E-05 | global batch size:    32 | lm loss: 1.172369E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1575/  500000 | consumed samples:        50400 | consumed tokens:    206438400 | elapsed time per iteration (ms): 6758.9 | learning rate: 9.450E-05 | global batch size:    32 | lm loss: 1.131398E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1576/  500000 | consumed samples:        50432 | consumed tokens:    206569472 | elapsed time per iteration (ms): 6759.7 | learning rate: 9.456E-05 | global batch size:    32 | lm loss: 1.147781E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1577/  500000 | consumed samples:        50464 | consumed tokens:    206700544 | elapsed time per iteration (ms): 6766.0 | learning rate: 9.462E-05 | global batch size:    32 | lm loss: 1.192658E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.51 |
time (ms)
 iteration     1578/  500000 | consumed samples:        50496 | consumed tokens:    206831616 | elapsed time per iteration (ms): 6764.8 | learning rate: 9.468E-05 | global batch size:    32 | lm loss: 1.151372E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration     1579/  500000 | consumed samples:        50528 | consumed tokens:    206962688 | elapsed time per iteration (ms): 6761.6 | learning rate: 9.474E-05 | global batch size:    32 | lm loss: 1.172452E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
[2023-10-10 18:08:15,310] [INFO] [logging.py:96:log_dist] [Rank 0] step=1580, skipped=0, lr=[9.48e-05], mom=[(0.9, 0.95)]
[2023-10-10 18:08:15,571] [INFO] [timer.py:208:stop] epoch=0/micro_step=1580/global_step=1580, RunningAvgSamplesPerSec=4.74291946819029, CurrSamplesPerSec=4.741277977970029, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1580/  500000 | consumed samples:        50560 | consumed tokens:    207093760 | elapsed time per iteration (ms): 6762.5 | learning rate: 9.480E-05 | global batch size:    32 | lm loss: 1.124817E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1581/  500000 | consumed samples:        50592 | consumed tokens:    207224832 | elapsed time per iteration (ms): 6758.3 | learning rate: 9.486E-05 | global batch size:    32 | lm loss: 1.197553E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1582/  500000 | consumed samples:        50624 | consumed tokens:    207355904 | elapsed time per iteration (ms): 6763.1 | learning rate: 9.492E-05 | global batch size:    32 | lm loss: 1.158831E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration     1583/  500000 | consumed samples:        50656 | consumed tokens:    207486976 | elapsed time per iteration (ms): 6758.1 | learning rate: 9.498E-05 | global batch size:    32 | lm loss: 1.163103E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1584/  500000 | consumed samples:        50688 | consumed tokens:    207618048 | elapsed time per iteration (ms): 6757.1 | learning rate: 9.504E-05 | global batch size:    32 | lm loss: 1.146747E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1585/  500000 | consumed samples:        50720 | consumed tokens:    207749120 | elapsed time per iteration (ms): 6757.4 | learning rate: 9.510E-05 | global batch size:    32 | lm loss: 1.157448E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1586/  500000 | consumed samples:        50752 | consumed tokens:    207880192 | elapsed time per iteration (ms): 6765.5 | learning rate: 9.516E-05 | global batch size:    32 | lm loss: 1.175530E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration     1587/  500000 | consumed samples:        50784 | consumed tokens:    208011264 | elapsed time per iteration (ms): 6759.2 | learning rate: 9.522E-05 | global batch size:    32 | lm loss: 1.121019E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1588/  500000 | consumed samples:        50816 | consumed tokens:    208142336 | elapsed time per iteration (ms): 6760.1 | learning rate: 9.528E-05 | global batch size:    32 | lm loss: 1.129749E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1589/  500000 | consumed samples:        50848 | consumed tokens:    208273408 | elapsed time per iteration (ms): 6760.0 | learning rate: 9.534E-05 | global batch size:    32 | lm loss: 1.143330E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
[2023-10-10 18:09:22,966] [INFO] [logging.py:96:log_dist] [Rank 0] step=1590, skipped=0, lr=[9.54e-05], mom=[(0.9, 0.95)]
[2023-10-10 18:09:23,214] [INFO] [timer.py:208:stop] epoch=0/micro_step=1590/global_step=1590, RunningAvgSamplesPerSec=4.742918983520555, CurrSamplesPerSec=4.743712310007519, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1590/  500000 | consumed samples:        50880 | consumed tokens:    208404480 | elapsed time per iteration (ms): 6759.2 | learning rate: 9.540E-05 | global batch size:    32 | lm loss: 1.149854E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1591/  500000 | consumed samples:        50912 | consumed tokens:    208535552 | elapsed time per iteration (ms): 6760.4 | learning rate: 9.546E-05 | global batch size:    32 | lm loss: 1.174204E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1592/  500000 | consumed samples:        50944 | consumed tokens:    208666624 | elapsed time per iteration (ms): 6759.1 | learning rate: 9.552E-05 | global batch size:    32 | lm loss: 1.152929E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1593/  500000 | consumed samples:        50976 | consumed tokens:    208797696 | elapsed time per iteration (ms): 6756.9 | learning rate: 9.558E-05 | global batch size:    32 | lm loss: 1.137936E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1594/  500000 | consumed samples:        51008 | consumed tokens:    208928768 | elapsed time per iteration (ms): 6760.8 | learning rate: 9.564E-05 | global batch size:    32 | lm loss: 1.161995E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1595/  500000 | consumed samples:        51040 | consumed tokens:    209059840 | elapsed time per iteration (ms): 6763.1 | learning rate: 9.570E-05 | global batch size:    32 | lm loss: 1.146377E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration     1596/  500000 | consumed samples:        51072 | consumed tokens:    209190912 | elapsed time per iteration (ms): 6763.6 | learning rate: 9.576E-05 | global batch size:    32 | lm loss: 1.128774E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     1597/  500000 | consumed samples:        51104 | consumed tokens:    209321984 | elapsed time per iteration (ms): 6761.4 | learning rate: 9.582E-05 | global batch size:    32 | lm loss: 1.139986E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1598/  500000 | consumed samples:        51136 | consumed tokens:    209453056 | elapsed time per iteration (ms): 6761.6 | learning rate: 9.588E-05 | global batch size:    32 | lm loss: 1.149862E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1599/  500000 | consumed samples:        51168 | consumed tokens:    209584128 | elapsed time per iteration (ms): 6762.4 | learning rate: 9.594E-05 | global batch size:    32 | lm loss: 1.141721E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
[2023-10-10 18:10:30,617] [INFO] [logging.py:96:log_dist] [Rank 0] step=1600, skipped=0, lr=[9.6e-05], mom=[(0.9, 0.95)]
[2023-10-10 18:10:30,867] [INFO] [timer.py:208:stop] epoch=0/micro_step=1600/global_step=1600, RunningAvgSamplesPerSec=4.742914095434293, CurrSamplesPerSec=4.742765896299869, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1600/  500000 | consumed samples:        51200 | consumed tokens:    209715200 | elapsed time per iteration (ms): 6761.2 | learning rate: 9.600E-05 | global batch size:    32 | lm loss: 1.170286E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1601/  500000 | consumed samples:        51232 | consumed tokens:    209846272 | elapsed time per iteration (ms): 6759.6 | learning rate: 9.606E-05 | global batch size:    32 | lm loss: 1.140959E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1602/  500000 | consumed samples:        51264 | consumed tokens:    209977344 | elapsed time per iteration (ms): 6757.5 | learning rate: 9.612E-05 | global batch size:    32 | lm loss: 1.158660E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1603/  500000 | consumed samples:        51296 | consumed tokens:    210108416 | elapsed time per iteration (ms): 6761.4 | learning rate: 9.618E-05 | global batch size:    32 | lm loss: 1.124872E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1604/  500000 | consumed samples:        51328 | consumed tokens:    210239488 | elapsed time per iteration (ms): 6759.6 | learning rate: 9.624E-05 | global batch size:    32 | lm loss: 1.147513E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1605/  500000 | consumed samples:        51360 | consumed tokens:    210370560 | elapsed time per iteration (ms): 6757.0 | learning rate: 9.630E-05 | global batch size:    32 | lm loss: 1.173228E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1606/  500000 | consumed samples:        51392 | consumed tokens:    210501632 | elapsed time per iteration (ms): 6764.5 | learning rate: 9.636E-05 | global batch size:    32 | lm loss: 1.135715E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.54 |
time (ms)
 iteration     1607/  500000 | consumed samples:        51424 | consumed tokens:    210632704 | elapsed time per iteration (ms): 6756.4 | learning rate: 9.642E-05 | global batch size:    32 | lm loss: 1.179811E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1608/  500000 | consumed samples:        51456 | consumed tokens:    210763776 | elapsed time per iteration (ms): 6761.1 | learning rate: 9.648E-05 | global batch size:    32 | lm loss: 1.146098E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1609/  500000 | consumed samples:        51488 | consumed tokens:    210894848 | elapsed time per iteration (ms): 6761.7 | learning rate: 9.654E-05 | global batch size:    32 | lm loss: 1.147311E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
[2023-10-10 18:11:38,248] [INFO] [logging.py:96:log_dist] [Rank 0] step=1610, skipped=0, lr=[9.66e-05], mom=[(0.9, 0.95)]
[2023-10-10 18:11:38,509] [INFO] [timer.py:208:stop] epoch=0/micro_step=1610/global_step=1610, RunningAvgSamplesPerSec=4.742912316265887, CurrSamplesPerSec=4.741601584828201, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1610/  500000 | consumed samples:        51520 | consumed tokens:    211025920 | elapsed time per iteration (ms): 6762.1 | learning rate: 9.660E-05 | global batch size:    32 | lm loss: 1.147301E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1611/  500000 | consumed samples:        51552 | consumed tokens:    211156992 | elapsed time per iteration (ms): 6760.1 | learning rate: 9.666E-05 | global batch size:    32 | lm loss: 1.173153E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1612/  500000 | consumed samples:        51584 | consumed tokens:    211288064 | elapsed time per iteration (ms): 6757.2 | learning rate: 9.672E-05 | global batch size:    32 | lm loss: 1.170922E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1613/  500000 | consumed samples:        51616 | consumed tokens:    211419136 | elapsed time per iteration (ms): 6759.6 | learning rate: 9.678E-05 | global batch size:    32 | lm loss: 1.192327E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1614/  500000 | consumed samples:        51648 | consumed tokens:    211550208 | elapsed time per iteration (ms): 6760.3 | learning rate: 9.684E-05 | global batch size:    32 | lm loss: 1.173129E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration     1615/  500000 | consumed samples:        51680 | consumed tokens:    211681280 | elapsed time per iteration (ms): 6760.6 | learning rate: 9.690E-05 | global batch size:    32 | lm loss: 1.136329E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1616/  500000 | consumed samples:        51712 | consumed tokens:    211812352 | elapsed time per iteration (ms): 6761.6 | learning rate: 9.696E-05 | global batch size:    32 | lm loss: 1.113005E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     1617/  500000 | consumed samples:        51744 | consumed tokens:    211943424 | elapsed time per iteration (ms): 6762.4 | learning rate: 9.702E-05 | global batch size:    32 | lm loss: 1.132677E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1618/  500000 | consumed samples:        51776 | consumed tokens:    212074496 | elapsed time per iteration (ms): 6758.4 | learning rate: 9.708E-05 | global batch size:    32 | lm loss: 1.123246E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1619/  500000 | consumed samples:        51808 | consumed tokens:    212205568 | elapsed time per iteration (ms): 6762.8 | learning rate: 9.714E-05 | global batch size:    32 | lm loss: 1.148756E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
[2023-10-10 18:12:45,901] [INFO] [logging.py:96:log_dist] [Rank 0] step=1620, skipped=0, lr=[9.719999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 18:12:46,154] [INFO] [timer.py:208:stop] epoch=0/micro_step=1620/global_step=1620, RunningAvgSamplesPerSec=4.742910561473463, CurrSamplesPerSec=4.74358338376112, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1620/  500000 | consumed samples:        51840 | consumed tokens:    212336640 | elapsed time per iteration (ms): 6758.0 | learning rate: 9.720E-05 | global batch size:    32 | lm loss: 1.160972E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1621/  500000 | consumed samples:        51872 | consumed tokens:    212467712 | elapsed time per iteration (ms): 6760.4 | learning rate: 9.726E-05 | global batch size:    32 | lm loss: 1.184317E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1622/  500000 | consumed samples:        51904 | consumed tokens:    212598784 | elapsed time per iteration (ms): 6755.9 | learning rate: 9.732E-05 | global batch size:    32 | lm loss: 1.132776E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration     1623/  500000 | consumed samples:        51936 | consumed tokens:    212729856 | elapsed time per iteration (ms): 6757.5 | learning rate: 9.738E-05 | global batch size:    32 | lm loss: 1.125728E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1624/  500000 | consumed samples:        51968 | consumed tokens:    212860928 | elapsed time per iteration (ms): 6762.0 | learning rate: 9.744E-05 | global batch size:    32 | lm loss: 1.136204E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1625/  500000 | consumed samples:        52000 | consumed tokens:    212992000 | elapsed time per iteration (ms): 6759.4 | learning rate: 9.750E-05 | global batch size:    32 | lm loss: 1.111366E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1626/  500000 | consumed samples:        52032 | consumed tokens:    213123072 | elapsed time per iteration (ms): 6757.5 | learning rate: 9.756E-05 | global batch size:    32 | lm loss: 1.127372E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1627/  500000 | consumed samples:        52064 | consumed tokens:    213254144 | elapsed time per iteration (ms): 6760.5 | learning rate: 9.762E-05 | global batch size:    32 | lm loss: 1.099486E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1628/  500000 | consumed samples:        52096 | consumed tokens:    213385216 | elapsed time per iteration (ms): 6758.7 | learning rate: 9.768E-05 | global batch size:    32 | lm loss: 1.152406E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1629/  500000 | consumed samples:        52128 | consumed tokens:    213516288 | elapsed time per iteration (ms): 6766.2 | learning rate: 9.774E-05 | global batch size:    32 | lm loss: 1.124600E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.51 |
time (ms)
[2023-10-10 18:13:53,586] [INFO] [logging.py:96:log_dist] [Rank 0] step=1630, skipped=0, lr=[9.779999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 18:13:53,807] [INFO] [timer.py:208:stop] epoch=0/micro_step=1630/global_step=1630, RunningAvgSamplesPerSec=4.742908265928528, CurrSamplesPerSec=4.739365713685628, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1630/  500000 | consumed samples:        52160 | consumed tokens:    213647360 | elapsed time per iteration (ms): 6765.7 | learning rate: 9.780E-05 | global batch size:    32 | lm loss: 1.128829E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration     1631/  500000 | consumed samples:        52192 | consumed tokens:    213778432 | elapsed time per iteration (ms): 6760.0 | learning rate: 9.786E-05 | global batch size:    32 | lm loss: 1.118896E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1632/  500000 | consumed samples:        52224 | consumed tokens:    213909504 | elapsed time per iteration (ms): 6756.3 | learning rate: 9.792E-05 | global batch size:    32 | lm loss: 1.148343E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1633/  500000 | consumed samples:        52256 | consumed tokens:    214040576 | elapsed time per iteration (ms): 6759.4 | learning rate: 9.798E-05 | global batch size:    32 | lm loss: 1.167320E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1634/  500000 | consumed samples:        52288 | consumed tokens:    214171648 | elapsed time per iteration (ms): 6759.1 | learning rate: 9.804E-05 | global batch size:    32 | lm loss: 1.139482E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1635/  500000 | consumed samples:        52320 | consumed tokens:    214302720 | elapsed time per iteration (ms): 6760.1 | learning rate: 9.810E-05 | global batch size:    32 | lm loss: 1.160109E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1636/  500000 | consumed samples:        52352 | consumed tokens:    214433792 | elapsed time per iteration (ms): 6763.3 | learning rate: 9.816E-05 | global batch size:    32 | lm loss: 1.116455E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration     1637/  500000 | consumed samples:        52384 | consumed tokens:    214564864 | elapsed time per iteration (ms): 6764.5 | learning rate: 9.822E-05 | global batch size:    32 | lm loss: 1.150282E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.54 |
time (ms)
 iteration     1638/  500000 | consumed samples:        52416 | consumed tokens:    214695936 | elapsed time per iteration (ms): 6759.8 | learning rate: 9.828E-05 | global batch size:    32 | lm loss: 1.114289E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1639/  500000 | consumed samples:        52448 | consumed tokens:    214827008 | elapsed time per iteration (ms): 6757.7 | learning rate: 9.834E-05 | global batch size:    32 | lm loss: 1.116152E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
[2023-10-10 18:15:01,190] [INFO] [logging.py:96:log_dist] [Rank 0] step=1640, skipped=0, lr=[9.839999999999999e-05], mom=[(0.9, 0.95)]
[2023-10-10 18:15:01,451] [INFO] [timer.py:208:stop] epoch=0/micro_step=1640/global_step=1640, RunningAvgSamplesPerSec=4.742908813986135, CurrSamplesPerSec=4.740797674080502, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1640/  500000 | consumed samples:        52480 | consumed tokens:    214958080 | elapsed time per iteration (ms): 6763.2 | learning rate: 9.840E-05 | global batch size:    32 | lm loss: 1.164065E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration     1641/  500000 | consumed samples:        52512 | consumed tokens:    215089152 | elapsed time per iteration (ms): 6758.4 | learning rate: 9.846E-05 | global batch size:    32 | lm loss: 1.124598E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1642/  500000 | consumed samples:        52544 | consumed tokens:    215220224 | elapsed time per iteration (ms): 6757.2 | learning rate: 9.852E-05 | global batch size:    32 | lm loss: 1.152052E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1643/  500000 | consumed samples:        52576 | consumed tokens:    215351296 | elapsed time per iteration (ms): 6757.8 | learning rate: 9.858E-05 | global batch size:    32 | lm loss: 1.122618E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1644/  500000 | consumed samples:        52608 | consumed tokens:    215482368 | elapsed time per iteration (ms): 6760.3 | learning rate: 9.864E-05 | global batch size:    32 | lm loss: 1.131843E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration     1645/  500000 | consumed samples:        52640 | consumed tokens:    215613440 | elapsed time per iteration (ms): 6765.1 | learning rate: 9.870E-05 | global batch size:    32 | lm loss: 1.180526E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration     1646/  500000 | consumed samples:        52672 | consumed tokens:    215744512 | elapsed time per iteration (ms): 6765.7 | learning rate: 9.876E-05 | global batch size:    32 | lm loss: 1.193521E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration     1647/  500000 | consumed samples:        52704 | consumed tokens:    215875584 | elapsed time per iteration (ms): 6766.5 | learning rate: 9.882E-05 | global batch size:    32 | lm loss: 1.123368E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.50 |
time (ms)
 iteration     1648/  500000 | consumed samples:        52736 | consumed tokens:    216006656 | elapsed time per iteration (ms): 6757.6 | learning rate: 9.888E-05 | global batch size:    32 | lm loss: 1.131930E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1649/  500000 | consumed samples:        52768 | consumed tokens:    216137728 | elapsed time per iteration (ms): 6760.3 | learning rate: 9.894E-05 | global batch size:    32 | lm loss: 1.160275E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
[2023-10-10 18:16:08,866] [INFO] [logging.py:96:log_dist] [Rank 0] step=1650, skipped=0, lr=[9.9e-05], mom=[(0.9, 0.95)]
[2023-10-10 18:16:09,104] [INFO] [timer.py:208:stop] epoch=0/micro_step=1650/global_step=1650, RunningAvgSamplesPerSec=4.7429033838592165, CurrSamplesPerSec=4.742326343012314, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1650/  500000 | consumed samples:        52800 | consumed tokens:    216268800 | elapsed time per iteration (ms): 6760.5 | learning rate: 9.900E-05 | global batch size:    32 | lm loss: 1.159773E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1651/  500000 | consumed samples:        52832 | consumed tokens:    216399872 | elapsed time per iteration (ms): 6757.0 | learning rate: 9.906E-05 | global batch size:    32 | lm loss: 1.177211E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1652/  500000 | consumed samples:        52864 | consumed tokens:    216530944 | elapsed time per iteration (ms): 6757.7 | learning rate: 9.912E-05 | global batch size:    32 | lm loss: 1.170197E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1653/  500000 | consumed samples:        52896 | consumed tokens:    216662016 | elapsed time per iteration (ms): 6761.0 | learning rate: 9.918E-05 | global batch size:    32 | lm loss: 1.161790E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1654/  500000 | consumed samples:        52928 | consumed tokens:    216793088 | elapsed time per iteration (ms): 6762.0 | learning rate: 9.924E-05 | global batch size:    32 | lm loss: 1.141249E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1655/  500000 | consumed samples:        52960 | consumed tokens:    216924160 | elapsed time per iteration (ms): 6758.7 | learning rate: 9.930E-05 | global batch size:    32 | lm loss: 1.162082E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1656/  500000 | consumed samples:        52992 | consumed tokens:    217055232 | elapsed time per iteration (ms): 6758.3 | learning rate: 9.936E-05 | global batch size:    32 | lm loss: 1.154215E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1657/  500000 | consumed samples:        53024 | consumed tokens:    217186304 | elapsed time per iteration (ms): 6762.5 | learning rate: 9.942E-05 | global batch size:    32 | lm loss: 1.150394E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1658/  500000 | consumed samples:        53056 | consumed tokens:    217317376 | elapsed time per iteration (ms): 6761.1 | learning rate: 9.948E-05 | global batch size:    32 | lm loss: 1.099790E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1659/  500000 | consumed samples:        53088 | consumed tokens:    217448448 | elapsed time per iteration (ms): 6758.1 | learning rate: 9.954E-05 | global batch size:    32 | lm loss: 1.121275E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
[2023-10-10 18:17:16,486] [INFO] [logging.py:96:log_dist] [Rank 0] step=1660, skipped=0, lr=[9.96e-05], mom=[(0.9, 0.95)]
[2023-10-10 18:17:16,743] [INFO] [timer.py:208:stop] epoch=0/micro_step=1660/global_step=1660, RunningAvgSamplesPerSec=4.742906293292269, CurrSamplesPerSec=4.743682634554881, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1660/  500000 | consumed samples:        53120 | consumed tokens:    217579520 | elapsed time per iteration (ms): 6759.6 | learning rate: 9.960E-05 | global batch size:    32 | lm loss: 1.152085E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1661/  500000 | consumed samples:        53152 | consumed tokens:    217710592 | elapsed time per iteration (ms): 6762.1 | learning rate: 9.966E-05 | global batch size:    32 | lm loss: 1.122720E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1662/  500000 | consumed samples:        53184 | consumed tokens:    217841664 | elapsed time per iteration (ms): 6759.3 | learning rate: 9.972E-05 | global batch size:    32 | lm loss: 1.169701E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1663/  500000 | consumed samples:        53216 | consumed tokens:    217972736 | elapsed time per iteration (ms): 6760.3 | learning rate: 9.978E-05 | global batch size:    32 | lm loss: 1.163153E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration     1664/  500000 | consumed samples:        53248 | consumed tokens:    218103808 | elapsed time per iteration (ms): 6764.5 | learning rate: 9.984E-05 | global batch size:    32 | lm loss: 1.136542E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.54 |
time (ms)
 iteration     1665/  500000 | consumed samples:        53280 | consumed tokens:    218234880 | elapsed time per iteration (ms): 6757.6 | learning rate: 9.990E-05 | global batch size:    32 | lm loss: 1.146893E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1666/  500000 | consumed samples:        53312 | consumed tokens:    218365952 | elapsed time per iteration (ms): 6756.8 | learning rate: 9.996E-05 | global batch size:    32 | lm loss: 1.149258E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1667/  500000 | consumed samples:        53344 | consumed tokens:    218497024 | elapsed time per iteration (ms): 6760.2 | learning rate: 1.000E-04 | global batch size:    32 | lm loss: 1.126008E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1668/  500000 | consumed samples:        53376 | consumed tokens:    218628096 | elapsed time per iteration (ms): 6781.5 | learning rate: 1.001E-04 | global batch size:    32 | lm loss: 1.125049E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.719 | TFLOPs: 147.17 |
time (ms)
 iteration     1669/  500000 | consumed samples:        53408 | consumed tokens:    218759168 | elapsed time per iteration (ms): 6764.0 | learning rate: 1.001E-04 | global batch size:    32 | lm loss: 1.124178E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
[2023-10-10 18:18:24,156] [INFO] [logging.py:96:log_dist] [Rank 0] step=1670, skipped=0, lr=[0.0001002], mom=[(0.9, 0.95)]
[2023-10-10 18:18:24,417] [INFO] [timer.py:208:stop] epoch=0/micro_step=1670/global_step=1670, RunningAvgSamplesPerSec=4.74289353687919, CurrSamplesPerSec=4.739458595792093, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1670/  500000 | consumed samples:        53440 | consumed tokens:    218890240 | elapsed time per iteration (ms): 6764.6 | learning rate: 1.002E-04 | global batch size:    32 | lm loss: 1.130997E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration     1671/  500000 | consumed samples:        53472 | consumed tokens:    219021312 | elapsed time per iteration (ms): 6758.7 | learning rate: 1.003E-04 | global batch size:    32 | lm loss: 1.160320E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1672/  500000 | consumed samples:        53504 | consumed tokens:    219152384 | elapsed time per iteration (ms): 6761.9 | learning rate: 1.003E-04 | global batch size:    32 | lm loss: 1.113654E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1673/  500000 | consumed samples:        53536 | consumed tokens:    219283456 | elapsed time per iteration (ms): 6760.6 | learning rate: 1.004E-04 | global batch size:    32 | lm loss: 1.139833E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1674/  500000 | consumed samples:        53568 | consumed tokens:    219414528 | elapsed time per iteration (ms): 6764.5 | learning rate: 1.004E-04 | global batch size:    32 | lm loss: 1.117330E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.54 |
time (ms)
 iteration     1675/  500000 | consumed samples:        53600 | consumed tokens:    219545600 | elapsed time per iteration (ms): 6761.1 | learning rate: 1.005E-04 | global batch size:    32 | lm loss: 1.153175E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1676/  500000 | consumed samples:        53632 | consumed tokens:    219676672 | elapsed time per iteration (ms): 6760.6 | learning rate: 1.006E-04 | global batch size:    32 | lm loss: 1.111843E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1677/  500000 | consumed samples:        53664 | consumed tokens:    219807744 | elapsed time per iteration (ms): 6760.5 | learning rate: 1.006E-04 | global batch size:    32 | lm loss: 1.171128E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1678/  500000 | consumed samples:        53696 | consumed tokens:    219938816 | elapsed time per iteration (ms): 6757.8 | learning rate: 1.007E-04 | global batch size:    32 | lm loss: 1.107242E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1679/  500000 | consumed samples:        53728 | consumed tokens:    220069888 | elapsed time per iteration (ms): 6767.5 | learning rate: 1.007E-04 | global batch size:    32 | lm loss: 1.095032E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.728 | TFLOPs: 147.48 |
time (ms)
[2023-10-10 18:19:31,845] [INFO] [logging.py:96:log_dist] [Rank 0] step=1680, skipped=0, lr=[0.0001008], mom=[(0.9, 0.95)]
[2023-10-10 18:19:32,077] [INFO] [timer.py:208:stop] epoch=0/micro_step=1680/global_step=1680, RunningAvgSamplesPerSec=4.742888279629863, CurrSamplesPerSec=4.739668807299115, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1680/  500000 | consumed samples:        53760 | consumed tokens:    220200960 | elapsed time per iteration (ms): 6763.7 | learning rate: 1.008E-04 | global batch size:    32 | lm loss: 1.168149E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     1681/  500000 | consumed samples:        53792 | consumed tokens:    220332032 | elapsed time per iteration (ms): 6766.1 | learning rate: 1.009E-04 | global batch size:    32 | lm loss: 1.151333E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.51 |
time (ms)
 iteration     1682/  500000 | consumed samples:        53824 | consumed tokens:    220463104 | elapsed time per iteration (ms): 6759.8 | learning rate: 1.009E-04 | global batch size:    32 | lm loss: 1.138626E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1683/  500000 | consumed samples:        53856 | consumed tokens:    220594176 | elapsed time per iteration (ms): 6758.8 | learning rate: 1.010E-04 | global batch size:    32 | lm loss: 1.150681E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1684/  500000 | consumed samples:        53888 | consumed tokens:    220725248 | elapsed time per iteration (ms): 6758.2 | learning rate: 1.010E-04 | global batch size:    32 | lm loss: 1.108379E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1685/  500000 | consumed samples:        53920 | consumed tokens:    220856320 | elapsed time per iteration (ms): 6759.1 | learning rate: 1.011E-04 | global batch size:    32 | lm loss: 1.136875E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1686/  500000 | consumed samples:        53952 | consumed tokens:    220987392 | elapsed time per iteration (ms): 6761.8 | learning rate: 1.012E-04 | global batch size:    32 | lm loss: 1.131835E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1687/  500000 | consumed samples:        53984 | consumed tokens:    221118464 | elapsed time per iteration (ms): 6762.3 | learning rate: 1.012E-04 | global batch size:    32 | lm loss: 1.108771E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1688/  500000 | consumed samples:        54016 | consumed tokens:    221249536 | elapsed time per iteration (ms): 6758.4 | learning rate: 1.013E-04 | global batch size:    32 | lm loss: 1.163128E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1689/  500000 | consumed samples:        54048 | consumed tokens:    221380608 | elapsed time per iteration (ms): 6761.2 | learning rate: 1.013E-04 | global batch size:    32 | lm loss: 1.148013E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
[2023-10-10 18:20:39,468] [INFO] [logging.py:96:log_dist] [Rank 0] step=1690, skipped=0, lr=[0.0001014], mom=[(0.9, 0.95)]
[2023-10-10 18:20:39,729] [INFO] [timer.py:208:stop] epoch=0/micro_step=1690/global_step=1690, RunningAvgSamplesPerSec=4.742883263303152, CurrSamplesPerSec=4.739257439501324, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1690/  500000 | consumed samples:        54080 | consumed tokens:    221511680 | elapsed time per iteration (ms): 6764.7 | learning rate: 1.014E-04 | global batch size:    32 | lm loss: 1.157296E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration     1691/  500000 | consumed samples:        54112 | consumed tokens:    221642752 | elapsed time per iteration (ms): 6760.7 | learning rate: 1.015E-04 | global batch size:    32 | lm loss: 1.142591E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1692/  500000 | consumed samples:        54144 | consumed tokens:    221773824 | elapsed time per iteration (ms): 6761.3 | learning rate: 1.015E-04 | global batch size:    32 | lm loss: 1.137102E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1693/  500000 | consumed samples:        54176 | consumed tokens:    221904896 | elapsed time per iteration (ms): 6762.8 | learning rate: 1.016E-04 | global batch size:    32 | lm loss: 1.130673E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1694/  500000 | consumed samples:        54208 | consumed tokens:    222035968 | elapsed time per iteration (ms): 6759.1 | learning rate: 1.016E-04 | global batch size:    32 | lm loss: 1.151285E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1695/  500000 | consumed samples:        54240 | consumed tokens:    222167040 | elapsed time per iteration (ms): 6761.7 | learning rate: 1.017E-04 | global batch size:    32 | lm loss: 1.145885E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     1696/  500000 | consumed samples:        54272 | consumed tokens:    222298112 | elapsed time per iteration (ms): 6760.7 | learning rate: 1.018E-04 | global batch size:    32 | lm loss: 1.146877E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1697/  500000 | consumed samples:        54304 | consumed tokens:    222429184 | elapsed time per iteration (ms): 6762.7 | learning rate: 1.018E-04 | global batch size:    32 | lm loss: 1.145990E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1698/  500000 | consumed samples:        54336 | consumed tokens:    222560256 | elapsed time per iteration (ms): 6762.3 | learning rate: 1.019E-04 | global batch size:    32 | lm loss: 1.145573E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1699/  500000 | consumed samples:        54368 | consumed tokens:    222691328 | elapsed time per iteration (ms): 6758.6 | learning rate: 1.019E-04 | global batch size:    32 | lm loss: 1.155204E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
[2023-10-10 18:21:47,128] [INFO] [logging.py:96:log_dist] [Rank 0] step=1700, skipped=0, lr=[0.000102], mom=[(0.9, 0.95)]
[2023-10-10 18:21:47,381] [INFO] [timer.py:208:stop] epoch=0/micro_step=1700/global_step=1700, RunningAvgSamplesPerSec=4.742880208007312, CurrSamplesPerSec=4.743801338593191, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1700/  500000 | consumed samples:        54400 | consumed tokens:    222822400 | elapsed time per iteration (ms): 6758.3 | learning rate: 1.020E-04 | global batch size:    32 | lm loss: 1.130889E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1701/  500000 | consumed samples:        54432 | consumed tokens:    222953472 | elapsed time per iteration (ms): 6757.6 | learning rate: 1.021E-04 | global batch size:    32 | lm loss: 1.137260E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1702/  500000 | consumed samples:        54464 | consumed tokens:    223084544 | elapsed time per iteration (ms): 6762.2 | learning rate: 1.021E-04 | global batch size:    32 | lm loss: 1.130485E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1703/  500000 | consumed samples:        54496 | consumed tokens:    223215616 | elapsed time per iteration (ms): 6761.0 | learning rate: 1.022E-04 | global batch size:    32 | lm loss: 1.116704E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1704/  500000 | consumed samples:        54528 | consumed tokens:    223346688 | elapsed time per iteration (ms): 6765.9 | learning rate: 1.022E-04 | global batch size:    32 | lm loss: 1.148423E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.51 |
time (ms)
 iteration     1705/  500000 | consumed samples:        54560 | consumed tokens:    223477760 | elapsed time per iteration (ms): 6760.2 | learning rate: 1.023E-04 | global batch size:    32 | lm loss: 1.154820E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1706/  500000 | consumed samples:        54592 | consumed tokens:    223608832 | elapsed time per iteration (ms): 6759.7 | learning rate: 1.024E-04 | global batch size:    32 | lm loss: 1.156527E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1707/  500000 | consumed samples:        54624 | consumed tokens:    223739904 | elapsed time per iteration (ms): 6764.3 | learning rate: 1.024E-04 | global batch size:    32 | lm loss: 1.104817E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     1708/  500000 | consumed samples:        54656 | consumed tokens:    223870976 | elapsed time per iteration (ms): 6766.9 | learning rate: 1.025E-04 | global batch size:    32 | lm loss: 1.145006E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.49 |
time (ms)
 iteration     1709/  500000 | consumed samples:        54688 | consumed tokens:    224002048 | elapsed time per iteration (ms): 6757.8 | learning rate: 1.025E-04 | global batch size:    32 | lm loss: 1.139531E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
[2023-10-10 18:22:54,796] [INFO] [logging.py:96:log_dist] [Rank 0] step=1710, skipped=0, lr=[0.00010259999999999999], mom=[(0.9, 0.95)]
[2023-10-10 18:22:55,045] [INFO] [timer.py:208:stop] epoch=0/micro_step=1710/global_step=1710, RunningAvgSamplesPerSec=4.742872012720485, CurrSamplesPerSec=4.738975481265547, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1710/  500000 | consumed samples:        54720 | consumed tokens:    224133120 | elapsed time per iteration (ms): 6765.5 | learning rate: 1.026E-04 | global batch size:    32 | lm loss: 1.121999E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration     1711/  500000 | consumed samples:        54752 | consumed tokens:    224264192 | elapsed time per iteration (ms): 6761.9 | learning rate: 1.027E-04 | global batch size:    32 | lm loss: 1.151129E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1712/  500000 | consumed samples:        54784 | consumed tokens:    224395264 | elapsed time per iteration (ms): 6763.4 | learning rate: 1.027E-04 | global batch size:    32 | lm loss: 1.109695E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration     1713/  500000 | consumed samples:        54816 | consumed tokens:    224526336 | elapsed time per iteration (ms): 6758.1 | learning rate: 1.028E-04 | global batch size:    32 | lm loss: 1.099010E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1714/  500000 | consumed samples:        54848 | consumed tokens:    224657408 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.028E-04 | global batch size:    32 | lm loss: 1.120894E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1715/  500000 | consumed samples:        54880 | consumed tokens:    224788480 | elapsed time per iteration (ms): 6761.0 | learning rate: 1.029E-04 | global batch size:    32 | lm loss: 1.121167E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1716/  500000 | consumed samples:        54912 | consumed tokens:    224919552 | elapsed time per iteration (ms): 6757.5 | learning rate: 1.030E-04 | global batch size:    32 | lm loss: 1.153493E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1717/  500000 | consumed samples:        54944 | consumed tokens:    225050624 | elapsed time per iteration (ms): 6759.8 | learning rate: 1.030E-04 | global batch size:    32 | lm loss: 1.127476E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1718/  500000 | consumed samples:        54976 | consumed tokens:    225181696 | elapsed time per iteration (ms): 6760.1 | learning rate: 1.031E-04 | global batch size:    32 | lm loss: 1.137217E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1719/  500000 | consumed samples:        55008 | consumed tokens:    225312768 | elapsed time per iteration (ms): 6759.8 | learning rate: 1.031E-04 | global batch size:    32 | lm loss: 1.144290E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
[2023-10-10 18:24:02,430] [INFO] [logging.py:96:log_dist] [Rank 0] step=1720, skipped=0, lr=[0.00010319999999999997], mom=[(0.9, 0.95)]
[2023-10-10 18:24:02,691] [INFO] [timer.py:208:stop] epoch=0/micro_step=1720/global_step=1720, RunningAvgSamplesPerSec=4.7428717031113825, CurrSamplesPerSec=4.741758546712252, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1720/  500000 | consumed samples:        55040 | consumed tokens:    225443840 | elapsed time per iteration (ms): 6762.9 | learning rate: 1.032E-04 | global batch size:    32 | lm loss: 1.129235E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1721/  500000 | consumed samples:        55072 | consumed tokens:    225574912 | elapsed time per iteration (ms): 6758.4 | learning rate: 1.033E-04 | global batch size:    32 | lm loss: 1.175651E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1722/  500000 | consumed samples:        55104 | consumed tokens:    225705984 | elapsed time per iteration (ms): 6759.7 | learning rate: 1.033E-04 | global batch size:    32 | lm loss: 1.181922E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1723/  500000 | consumed samples:        55136 | consumed tokens:    225837056 | elapsed time per iteration (ms): 6761.7 | learning rate: 1.034E-04 | global batch size:    32 | lm loss: 1.174093E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     1724/  500000 | consumed samples:        55168 | consumed tokens:    225968128 | elapsed time per iteration (ms): 6759.8 | learning rate: 1.034E-04 | global batch size:    32 | lm loss: 1.159185E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1725/  500000 | consumed samples:        55200 | consumed tokens:    226099200 | elapsed time per iteration (ms): 6760.5 | learning rate: 1.035E-04 | global batch size:    32 | lm loss: 1.166869E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1726/  500000 | consumed samples:        55232 | consumed tokens:    226230272 | elapsed time per iteration (ms): 6761.4 | learning rate: 1.036E-04 | global batch size:    32 | lm loss: 1.107406E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1727/  500000 | consumed samples:        55264 | consumed tokens:    226361344 | elapsed time per iteration (ms): 6760.5 | learning rate: 1.036E-04 | global batch size:    32 | lm loss: 1.164366E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1728/  500000 | consumed samples:        55296 | consumed tokens:    226492416 | elapsed time per iteration (ms): 6759.8 | learning rate: 1.037E-04 | global batch size:    32 | lm loss: 1.117992E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1729/  500000 | consumed samples:        55328 | consumed tokens:    226623488 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.037E-04 | global batch size:    32 | lm loss: 1.148997E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
[2023-10-10 18:25:10,082] [INFO] [logging.py:96:log_dist] [Rank 0] step=1730, skipped=0, lr=[0.00010379999999999998], mom=[(0.9, 0.95)]
[2023-10-10 18:25:10,335] [INFO] [timer.py:208:stop] epoch=0/micro_step=1730/global_step=1730, RunningAvgSamplesPerSec=4.742870679259377, CurrSamplesPerSec=4.742908353847589, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1730/  500000 | consumed samples:        55360 | consumed tokens:    226754560 | elapsed time per iteration (ms): 6759.4 | learning rate: 1.038E-04 | global batch size:    32 | lm loss: 1.135066E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1731/  500000 | consumed samples:        55392 | consumed tokens:    226885632 | elapsed time per iteration (ms): 6758.4 | learning rate: 1.039E-04 | global batch size:    32 | lm loss: 1.131735E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1732/  500000 | consumed samples:        55424 | consumed tokens:    227016704 | elapsed time per iteration (ms): 6760.3 | learning rate: 1.039E-04 | global batch size:    32 | lm loss: 1.105192E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1733/  500000 | consumed samples:        55456 | consumed tokens:    227147776 | elapsed time per iteration (ms): 6761.0 | learning rate: 1.040E-04 | global batch size:    32 | lm loss: 1.144042E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1734/  500000 | consumed samples:        55488 | consumed tokens:    227278848 | elapsed time per iteration (ms): 6763.6 | learning rate: 1.040E-04 | global batch size:    32 | lm loss: 1.164428E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     1735/  500000 | consumed samples:        55520 | consumed tokens:    227409920 | elapsed time per iteration (ms): 6763.1 | learning rate: 1.041E-04 | global batch size:    32 | lm loss: 1.112665E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration     1736/  500000 | consumed samples:        55552 | consumed tokens:    227540992 | elapsed time per iteration (ms): 6759.1 | learning rate: 1.042E-04 | global batch size:    32 | lm loss: 1.123947E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1737/  500000 | consumed samples:        55584 | consumed tokens:    227672064 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.042E-04 | global batch size:    32 | lm loss: 1.134719E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1738/  500000 | consumed samples:        55616 | consumed tokens:    227803136 | elapsed time per iteration (ms): 6760.1 | learning rate: 1.043E-04 | global batch size:    32 | lm loss: 1.124560E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1739/  500000 | consumed samples:        55648 | consumed tokens:    227934208 | elapsed time per iteration (ms): 6759.5 | learning rate: 1.043E-04 | global batch size:    32 | lm loss: 1.124800E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
[2023-10-10 18:26:17,731] [INFO] [logging.py:96:log_dist] [Rank 0] step=1740, skipped=0, lr=[0.00010439999999999998], mom=[(0.9, 0.95)]
[2023-10-10 18:26:17,979] [INFO] [timer.py:208:stop] epoch=0/micro_step=1740/global_step=1740, RunningAvgSamplesPerSec=4.742869451470617, CurrSamplesPerSec=4.745011352053807, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1740/  500000 | consumed samples:        55680 | consumed tokens:    228065280 | elapsed time per iteration (ms): 6756.4 | learning rate: 1.044E-04 | global batch size:    32 | lm loss: 1.118543E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1741/  500000 | consumed samples:        55712 | consumed tokens:    228196352 | elapsed time per iteration (ms): 6759.8 | learning rate: 1.045E-04 | global batch size:    32 | lm loss: 1.077242E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1742/  500000 | consumed samples:        55744 | consumed tokens:    228327424 | elapsed time per iteration (ms): 6761.7 | learning rate: 1.045E-04 | global batch size:    32 | lm loss: 1.142340E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     1743/  500000 | consumed samples:        55776 | consumed tokens:    228458496 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.046E-04 | global batch size:    32 | lm loss: 1.096446E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1744/  500000 | consumed samples:        55808 | consumed tokens:    228589568 | elapsed time per iteration (ms): 6759.9 | learning rate: 1.046E-04 | global batch size:    32 | lm loss: 1.147851E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1745/  500000 | consumed samples:        55840 | consumed tokens:    228720640 | elapsed time per iteration (ms): 6760.7 | learning rate: 1.047E-04 | global batch size:    32 | lm loss: 1.151209E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1746/  500000 | consumed samples:        55872 | consumed tokens:    228851712 | elapsed time per iteration (ms): 6758.2 | learning rate: 1.048E-04 | global batch size:    32 | lm loss: 1.134091E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1747/  500000 | consumed samples:        55904 | consumed tokens:    228982784 | elapsed time per iteration (ms): 6760.3 | learning rate: 1.048E-04 | global batch size:    32 | lm loss: 1.104881E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration     1748/  500000 | consumed samples:        55936 | consumed tokens:    229113856 | elapsed time per iteration (ms): 6759.7 | learning rate: 1.049E-04 | global batch size:    32 | lm loss: 1.150939E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1749/  500000 | consumed samples:        55968 | consumed tokens:    229244928 | elapsed time per iteration (ms): 6763.4 | learning rate: 1.049E-04 | global batch size:    32 | lm loss: 1.119275E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
[2023-10-10 18:27:25,370] [INFO] [logging.py:96:log_dist] [Rank 0] step=1750, skipped=0, lr=[0.00010499999999999998], mom=[(0.9, 0.95)]
[2023-10-10 18:27:25,627] [INFO] [timer.py:208:stop] epoch=0/micro_step=1750/global_step=1750, RunningAvgSamplesPerSec=4.742867798117833, CurrSamplesPerSec=4.742244407090167, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1750/  500000 | consumed samples:        56000 | consumed tokens:    229376000 | elapsed time per iteration (ms): 6760.8 | learning rate: 1.050E-04 | global batch size:    32 | lm loss: 1.117340E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1751/  500000 | consumed samples:        56032 | consumed tokens:    229507072 | elapsed time per iteration (ms): 6764.0 | learning rate: 1.051E-04 | global batch size:    32 | lm loss: 1.121493E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     1752/  500000 | consumed samples:        56064 | consumed tokens:    229638144 | elapsed time per iteration (ms): 6758.1 | learning rate: 1.051E-04 | global batch size:    32 | lm loss: 1.101787E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1753/  500000 | consumed samples:        56096 | consumed tokens:    229769216 | elapsed time per iteration (ms): 6756.0 | learning rate: 1.052E-04 | global batch size:    32 | lm loss: 1.160653E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.73 |
time (ms)
 iteration     1754/  500000 | consumed samples:        56128 | consumed tokens:    229900288 | elapsed time per iteration (ms): 6759.5 | learning rate: 1.052E-04 | global batch size:    32 | lm loss: 1.142839E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1755/  500000 | consumed samples:        56160 | consumed tokens:    230031360 | elapsed time per iteration (ms): 6758.4 | learning rate: 1.053E-04 | global batch size:    32 | lm loss: 1.144098E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1756/  500000 | consumed samples:        56192 | consumed tokens:    230162432 | elapsed time per iteration (ms): 6765.7 | learning rate: 1.054E-04 | global batch size:    32 | lm loss: 1.143065E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration     1757/  500000 | consumed samples:        56224 | consumed tokens:    230293504 | elapsed time per iteration (ms): 6758.8 | learning rate: 1.054E-04 | global batch size:    32 | lm loss: 1.152505E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1758/  500000 | consumed samples:        56256 | consumed tokens:    230424576 | elapsed time per iteration (ms): 6758.3 | learning rate: 1.055E-04 | global batch size:    32 | lm loss: 1.118684E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1759/  500000 | consumed samples:        56288 | consumed tokens:    230555648 | elapsed time per iteration (ms): 6758.5 | learning rate: 1.055E-04 | global batch size:    32 | lm loss: 1.131488E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
[2023-10-10 18:28:33,008] [INFO] [logging.py:96:log_dist] [Rank 0] step=1760, skipped=0, lr=[0.00010559999999999998], mom=[(0.9, 0.95)]
[2023-10-10 18:28:33,268] [INFO] [timer.py:208:stop] epoch=0/micro_step=1760/global_step=1760, RunningAvgSamplesPerSec=4.742869906436008, CurrSamplesPerSec=4.742521727208868, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1760/  500000 | consumed samples:        56320 | consumed tokens:    230686720 | elapsed time per iteration (ms): 6760.6 | learning rate: 1.056E-04 | global batch size:    32 | lm loss: 1.120028E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1761/  500000 | consumed samples:        56352 | consumed tokens:    230817792 | elapsed time per iteration (ms): 6758.0 | learning rate: 1.057E-04 | global batch size:    32 | lm loss: 1.079789E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1762/  500000 | consumed samples:        56384 | consumed tokens:    230948864 | elapsed time per iteration (ms): 6761.1 | learning rate: 1.057E-04 | global batch size:    32 | lm loss: 1.129666E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1763/  500000 | consumed samples:        56416 | consumed tokens:    231079936 | elapsed time per iteration (ms): 6756.4 | learning rate: 1.058E-04 | global batch size:    32 | lm loss: 1.112517E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1764/  500000 | consumed samples:        56448 | consumed tokens:    231211008 | elapsed time per iteration (ms): 6756.0 | learning rate: 1.058E-04 | global batch size:    32 | lm loss: 1.114316E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration     1765/  500000 | consumed samples:        56480 | consumed tokens:    231342080 | elapsed time per iteration (ms): 6762.0 | learning rate: 1.059E-04 | global batch size:    32 | lm loss: 1.148028E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1766/  500000 | consumed samples:        56512 | consumed tokens:    231473152 | elapsed time per iteration (ms): 6761.5 | learning rate: 1.060E-04 | global batch size:    32 | lm loss: 1.171659E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1767/  500000 | consumed samples:        56544 | consumed tokens:    231604224 | elapsed time per iteration (ms): 6761.1 | learning rate: 1.060E-04 | global batch size:    32 | lm loss: 1.114700E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1768/  500000 | consumed samples:        56576 | consumed tokens:    231735296 | elapsed time per iteration (ms): 6760.3 | learning rate: 1.061E-04 | global batch size:    32 | lm loss: 1.112955E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration     1769/  500000 | consumed samples:        56608 | consumed tokens:    231866368 | elapsed time per iteration (ms): 6762.0 | learning rate: 1.061E-04 | global batch size:    32 | lm loss: 1.176555E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
[2023-10-10 18:29:40,684] [INFO] [logging.py:96:log_dist] [Rank 0] step=1770, skipped=0, lr=[0.00010619999999999998], mom=[(0.9, 0.95)]
[2023-10-10 18:29:40,913] [INFO] [timer.py:208:stop] epoch=0/micro_step=1770/global_step=1770, RunningAvgSamplesPerSec=4.7428724407140095, CurrSamplesPerSec=4.744428489591173, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1770/  500000 | consumed samples:        56640 | consumed tokens:    231997440 | elapsed time per iteration (ms): 6759.1 | learning rate: 1.062E-04 | global batch size:    32 | lm loss: 1.147242E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1771/  500000 | consumed samples:        56672 | consumed tokens:    232128512 | elapsed time per iteration (ms): 6763.0 | learning rate: 1.063E-04 | global batch size:    32 | lm loss: 1.156440E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration     1772/  500000 | consumed samples:        56704 | consumed tokens:    232259584 | elapsed time per iteration (ms): 6761.2 | learning rate: 1.063E-04 | global batch size:    32 | lm loss: 1.135104E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1773/  500000 | consumed samples:        56736 | consumed tokens:    232390656 | elapsed time per iteration (ms): 6761.8 | learning rate: 1.064E-04 | global batch size:    32 | lm loss: 1.131369E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1774/  500000 | consumed samples:        56768 | consumed tokens:    232521728 | elapsed time per iteration (ms): 6763.3 | learning rate: 1.064E-04 | global batch size:    32 | lm loss: 1.149072E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration     1775/  500000 | consumed samples:        56800 | consumed tokens:    232652800 | elapsed time per iteration (ms): 6758.5 | learning rate: 1.065E-04 | global batch size:    32 | lm loss: 1.097699E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1776/  500000 | consumed samples:        56832 | consumed tokens:    232783872 | elapsed time per iteration (ms): 6761.3 | learning rate: 1.066E-04 | global batch size:    32 | lm loss: 1.130951E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1777/  500000 | consumed samples:        56864 | consumed tokens:    232914944 | elapsed time per iteration (ms): 6760.8 | learning rate: 1.066E-04 | global batch size:    32 | lm loss: 1.130538E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1778/  500000 | consumed samples:        56896 | consumed tokens:    233046016 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.067E-04 | global batch size:    32 | lm loss: 1.127325E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1779/  500000 | consumed samples:        56928 | consumed tokens:    233177088 | elapsed time per iteration (ms): 6758.6 | learning rate: 1.067E-04 | global batch size:    32 | lm loss: 1.141996E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
[2023-10-10 18:30:48,311] [INFO] [logging.py:96:log_dist] [Rank 0] step=1780, skipped=0, lr=[0.00010679999999999998], mom=[(0.9, 0.95)]
[2023-10-10 18:30:48,567] [INFO] [timer.py:208:stop] epoch=0/micro_step=1780/global_step=1780, RunningAvgSamplesPerSec=4.742867179221066, CurrSamplesPerSec=4.741043005435548, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1780/  500000 | consumed samples:        56960 | consumed tokens:    233308160 | elapsed time per iteration (ms): 6762.0 | learning rate: 1.068E-04 | global batch size:    32 | lm loss: 1.124913E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1781/  500000 | consumed samples:        56992 | consumed tokens:    233439232 | elapsed time per iteration (ms): 6761.1 | learning rate: 1.069E-04 | global batch size:    32 | lm loss: 1.137322E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1782/  500000 | consumed samples:        57024 | consumed tokens:    233570304 | elapsed time per iteration (ms): 6758.1 | learning rate: 1.069E-04 | global batch size:    32 | lm loss: 1.138574E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1783/  500000 | consumed samples:        57056 | consumed tokens:    233701376 | elapsed time per iteration (ms): 6762.6 | learning rate: 1.070E-04 | global batch size:    32 | lm loss: 1.132658E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1784/  500000 | consumed samples:        57088 | consumed tokens:    233832448 | elapsed time per iteration (ms): 6758.3 | learning rate: 1.070E-04 | global batch size:    32 | lm loss: 1.122934E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1785/  500000 | consumed samples:        57120 | consumed tokens:    233963520 | elapsed time per iteration (ms): 6762.3 | learning rate: 1.071E-04 | global batch size:    32 | lm loss: 1.139102E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1786/  500000 | consumed samples:        57152 | consumed tokens:    234094592 | elapsed time per iteration (ms): 6759.7 | learning rate: 1.072E-04 | global batch size:    32 | lm loss: 1.135932E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1787/  500000 | consumed samples:        57184 | consumed tokens:    234225664 | elapsed time per iteration (ms): 6761.8 | learning rate: 1.072E-04 | global batch size:    32 | lm loss: 1.106979E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1788/  500000 | consumed samples:        57216 | consumed tokens:    234356736 | elapsed time per iteration (ms): 6761.8 | learning rate: 1.073E-04 | global batch size:    32 | lm loss: 1.131984E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1789/  500000 | consumed samples:        57248 | consumed tokens:    234487808 | elapsed time per iteration (ms): 6760.0 | learning rate: 1.073E-04 | global batch size:    32 | lm loss: 1.107698E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
[2023-10-10 18:31:55,964] [INFO] [logging.py:96:log_dist] [Rank 0] step=1790, skipped=0, lr=[0.00010739999999999998], mom=[(0.9, 0.95)]
[2023-10-10 18:31:56,214] [INFO] [timer.py:208:stop] epoch=0/micro_step=1790/global_step=1790, RunningAvgSamplesPerSec=4.742864988500346, CurrSamplesPerSec=4.743459661391402, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1790/  500000 | consumed samples:        57280 | consumed tokens:    234618880 | elapsed time per iteration (ms): 6758.9 | learning rate: 1.074E-04 | global batch size:    32 | lm loss: 1.132556E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1791/  500000 | consumed samples:        57312 | consumed tokens:    234749952 | elapsed time per iteration (ms): 6758.3 | learning rate: 1.075E-04 | global batch size:    32 | lm loss: 1.112151E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1792/  500000 | consumed samples:        57344 | consumed tokens:    234881024 | elapsed time per iteration (ms): 6756.7 | learning rate: 1.075E-04 | global batch size:    32 | lm loss: 1.150969E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1793/  500000 | consumed samples:        57376 | consumed tokens:    235012096 | elapsed time per iteration (ms): 6761.2 | learning rate: 1.076E-04 | global batch size:    32 | lm loss: 1.120251E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1794/  500000 | consumed samples:        57408 | consumed tokens:    235143168 | elapsed time per iteration (ms): 6756.1 | learning rate: 1.076E-04 | global batch size:    32 | lm loss: 1.168908E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1795/  500000 | consumed samples:        57440 | consumed tokens:    235274240 | elapsed time per iteration (ms): 6757.4 | learning rate: 1.077E-04 | global batch size:    32 | lm loss: 1.117162E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1796/  500000 | consumed samples:        57472 | consumed tokens:    235405312 | elapsed time per iteration (ms): 6758.2 | learning rate: 1.078E-04 | global batch size:    32 | lm loss: 1.123477E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1797/  500000 | consumed samples:        57504 | consumed tokens:    235536384 | elapsed time per iteration (ms): 6762.2 | learning rate: 1.078E-04 | global batch size:    32 | lm loss: 1.112006E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1798/  500000 | consumed samples:        57536 | consumed tokens:    235667456 | elapsed time per iteration (ms): 6761.0 | learning rate: 1.079E-04 | global batch size:    32 | lm loss: 1.126220E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1799/  500000 | consumed samples:        57568 | consumed tokens:    235798528 | elapsed time per iteration (ms): 6759.6 | learning rate: 1.079E-04 | global batch size:    32 | lm loss: 1.088843E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
[2023-10-10 18:33:03,587] [INFO] [logging.py:96:log_dist] [Rank 0] step=1800, skipped=0, lr=[0.00010799999999999998], mom=[(0.9, 0.95)]
[2023-10-10 18:33:03,847] [INFO] [timer.py:208:stop] epoch=0/micro_step=1800/global_step=1800, RunningAvgSamplesPerSec=4.742867732020801, CurrSamplesPerSec=4.7431311075649525, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1800/  500000 | consumed samples:        57600 | consumed tokens:    235929600 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.080E-04 | global batch size:    32 | lm loss: 1.148380E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1801/  500000 | consumed samples:        57632 | consumed tokens:    236060672 | elapsed time per iteration (ms): 6761.9 | learning rate: 1.081E-04 | global batch size:    32 | lm loss: 1.115311E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1802/  500000 | consumed samples:        57664 | consumed tokens:    236191744 | elapsed time per iteration (ms): 6760.8 | learning rate: 1.081E-04 | global batch size:    32 | lm loss: 1.128528E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1803/  500000 | consumed samples:        57696 | consumed tokens:    236322816 | elapsed time per iteration (ms): 6760.3 | learning rate: 1.082E-04 | global batch size:    32 | lm loss: 1.131848E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration     1804/  500000 | consumed samples:        57728 | consumed tokens:    236453888 | elapsed time per iteration (ms): 6760.6 | learning rate: 1.082E-04 | global batch size:    32 | lm loss: 1.120701E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1805/  500000 | consumed samples:        57760 | consumed tokens:    236584960 | elapsed time per iteration (ms): 6757.0 | learning rate: 1.083E-04 | global batch size:    32 | lm loss: 1.144605E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1806/  500000 | consumed samples:        57792 | consumed tokens:    236716032 | elapsed time per iteration (ms): 6759.0 | learning rate: 1.084E-04 | global batch size:    32 | lm loss: 1.148798E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1807/  500000 | consumed samples:        57824 | consumed tokens:    236847104 | elapsed time per iteration (ms): 6763.5 | learning rate: 1.084E-04 | global batch size:    32 | lm loss: 1.126275E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     1808/  500000 | consumed samples:        57856 | consumed tokens:    236978176 | elapsed time per iteration (ms): 6766.8 | learning rate: 1.085E-04 | global batch size:    32 | lm loss: 1.151663E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.49 |
time (ms)
 iteration     1809/  500000 | consumed samples:        57888 | consumed tokens:    237109248 | elapsed time per iteration (ms): 6757.0 | learning rate: 1.085E-04 | global batch size:    32 | lm loss: 1.129862E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
[2023-10-10 18:34:11,237] [INFO] [logging.py:96:log_dist] [Rank 0] step=1810, skipped=0, lr=[0.00010859999999999998], mom=[(0.9, 0.95)]
[2023-10-10 18:34:11,495] [INFO] [timer.py:208:stop] epoch=0/micro_step=1810/global_step=1810, RunningAvgSamplesPerSec=4.7428656465533425, CurrSamplesPerSec=4.744354530809788, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1810/  500000 | consumed samples:        57920 | consumed tokens:    237240320 | elapsed time per iteration (ms): 6758.1 | learning rate: 1.086E-04 | global batch size:    32 | lm loss: 1.109114E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1811/  500000 | consumed samples:        57952 | consumed tokens:    237371392 | elapsed time per iteration (ms): 6760.2 | learning rate: 1.087E-04 | global batch size:    32 | lm loss: 1.130298E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1812/  500000 | consumed samples:        57984 | consumed tokens:    237502464 | elapsed time per iteration (ms): 6759.6 | learning rate: 1.087E-04 | global batch size:    32 | lm loss: 1.124182E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1813/  500000 | consumed samples:        58016 | consumed tokens:    237633536 | elapsed time per iteration (ms): 6757.4 | learning rate: 1.088E-04 | global batch size:    32 | lm loss: 1.137752E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1814/  500000 | consumed samples:        58048 | consumed tokens:    237764608 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.088E-04 | global batch size:    32 | lm loss: 1.145355E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1815/  500000 | consumed samples:        58080 | consumed tokens:    237895680 | elapsed time per iteration (ms): 6761.0 | learning rate: 1.089E-04 | global batch size:    32 | lm loss: 1.126626E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1816/  500000 | consumed samples:        58112 | consumed tokens:    238026752 | elapsed time per iteration (ms): 6762.2 | learning rate: 1.090E-04 | global batch size:    32 | lm loss: 1.104202E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1817/  500000 | consumed samples:        58144 | consumed tokens:    238157824 | elapsed time per iteration (ms): 6762.8 | learning rate: 1.090E-04 | global batch size:    32 | lm loss: 1.122764E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1818/  500000 | consumed samples:        58176 | consumed tokens:    238288896 | elapsed time per iteration (ms): 6764.1 | learning rate: 1.091E-04 | global batch size:    32 | lm loss: 1.130673E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     1819/  500000 | consumed samples:        58208 | consumed tokens:    238419968 | elapsed time per iteration (ms): 6759.5 | learning rate: 1.091E-04 | global batch size:    32 | lm loss: 1.122721E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
[2023-10-10 18:35:18,890] [INFO] [logging.py:96:log_dist] [Rank 0] step=1820, skipped=0, lr=[0.00010919999999999998], mom=[(0.9, 0.95)]
[2023-10-10 18:35:19,143] [INFO] [timer.py:208:stop] epoch=0/micro_step=1820/global_step=1820, RunningAvgSamplesPerSec=4.7428628044829395, CurrSamplesPerSec=4.7440095879958335, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1820/  500000 | consumed samples:        58240 | consumed tokens:    238551040 | elapsed time per iteration (ms): 6758.6 | learning rate: 1.092E-04 | global batch size:    32 | lm loss: 1.122807E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1821/  500000 | consumed samples:        58272 | consumed tokens:    238682112 | elapsed time per iteration (ms): 6764.3 | learning rate: 1.093E-04 | global batch size:    32 | lm loss: 1.097760E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     1822/  500000 | consumed samples:        58304 | consumed tokens:    238813184 | elapsed time per iteration (ms): 6764.7 | learning rate: 1.093E-04 | global batch size:    32 | lm loss: 1.142595E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration     1823/  500000 | consumed samples:        58336 | consumed tokens:    238944256 | elapsed time per iteration (ms): 6762.4 | learning rate: 1.094E-04 | global batch size:    32 | lm loss: 1.098085E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1824/  500000 | consumed samples:        58368 | consumed tokens:    239075328 | elapsed time per iteration (ms): 6761.3 | learning rate: 1.094E-04 | global batch size:    32 | lm loss: 1.104534E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1825/  500000 | consumed samples:        58400 | consumed tokens:    239206400 | elapsed time per iteration (ms): 6762.3 | learning rate: 1.095E-04 | global batch size:    32 | lm loss: 1.113888E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1826/  500000 | consumed samples:        58432 | consumed tokens:    239337472 | elapsed time per iteration (ms): 6760.9 | learning rate: 1.096E-04 | global batch size:    32 | lm loss: 1.130104E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1827/  500000 | consumed samples:        58464 | consumed tokens:    239468544 | elapsed time per iteration (ms): 6761.9 | learning rate: 1.096E-04 | global batch size:    32 | lm loss: 1.121786E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1828/  500000 | consumed samples:        58496 | consumed tokens:    239599616 | elapsed time per iteration (ms): 6761.4 | learning rate: 1.097E-04 | global batch size:    32 | lm loss: 1.138573E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1829/  500000 | consumed samples:        58528 | consumed tokens:    239730688 | elapsed time per iteration (ms): 6763.0 | learning rate: 1.097E-04 | global batch size:    32 | lm loss: 1.134416E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
[2023-10-10 18:36:26,580] [INFO] [logging.py:96:log_dist] [Rank 0] step=1830, skipped=0, lr=[0.00010979999999999999], mom=[(0.9, 0.95)]
[2023-10-10 18:36:26,811] [INFO] [timer.py:208:stop] epoch=0/micro_step=1830/global_step=1830, RunningAvgSamplesPerSec=4.742860215936647, CurrSamplesPerSec=4.742875839253577, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1830/  500000 | consumed samples:        58560 | consumed tokens:    239861760 | elapsed time per iteration (ms): 6761.8 | learning rate: 1.098E-04 | global batch size:    32 | lm loss: 1.103115E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1831/  500000 | consumed samples:        58592 | consumed tokens:    239992832 | elapsed time per iteration (ms): 6762.5 | learning rate: 1.099E-04 | global batch size:    32 | lm loss: 1.094431E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1832/  500000 | consumed samples:        58624 | consumed tokens:    240123904 | elapsed time per iteration (ms): 6763.7 | learning rate: 1.099E-04 | global batch size:    32 | lm loss: 1.167893E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     1833/  500000 | consumed samples:        58656 | consumed tokens:    240254976 | elapsed time per iteration (ms): 6760.5 | learning rate: 1.100E-04 | global batch size:    32 | lm loss: 1.103833E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1834/  500000 | consumed samples:        58688 | consumed tokens:    240386048 | elapsed time per iteration (ms): 6764.4 | learning rate: 1.100E-04 | global batch size:    32 | lm loss: 1.126392E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.54 |
time (ms)
 iteration     1835/  500000 | consumed samples:        58720 | consumed tokens:    240517120 | elapsed time per iteration (ms): 6759.9 | learning rate: 1.101E-04 | global batch size:    32 | lm loss: 1.183229E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1836/  500000 | consumed samples:        58752 | consumed tokens:    240648192 | elapsed time per iteration (ms): 6765.1 | learning rate: 1.102E-04 | global batch size:    32 | lm loss: 1.136644E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration     1837/  500000 | consumed samples:        58784 | consumed tokens:    240779264 | elapsed time per iteration (ms): 6762.2 | learning rate: 1.102E-04 | global batch size:    32 | lm loss: 1.144311E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1838/  500000 | consumed samples:        58816 | consumed tokens:    240910336 | elapsed time per iteration (ms): 6765.0 | learning rate: 1.103E-04 | global batch size:    32 | lm loss: 1.096286E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration     1839/  500000 | consumed samples:        58848 | consumed tokens:    241041408 | elapsed time per iteration (ms): 6761.9 | learning rate: 1.103E-04 | global batch size:    32 | lm loss: 1.106490E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
[2023-10-10 18:37:34,230] [INFO] [logging.py:96:log_dist] [Rank 0] step=1840, skipped=0, lr=[0.00011039999999999999], mom=[(0.9, 0.95)]
[2023-10-10 18:37:34,483] [INFO] [timer.py:208:stop] epoch=0/micro_step=1840/global_step=1840, RunningAvgSamplesPerSec=4.742854434168328, CurrSamplesPerSec=4.741351505877952, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1840/  500000 | consumed samples:        58880 | consumed tokens:    241172480 | elapsed time per iteration (ms): 6762.5 | learning rate: 1.104E-04 | global batch size:    32 | lm loss: 1.111949E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1841/  500000 | consumed samples:        58912 | consumed tokens:    241303552 | elapsed time per iteration (ms): 6758.7 | learning rate: 1.105E-04 | global batch size:    32 | lm loss: 1.106545E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1842/  500000 | consumed samples:        58944 | consumed tokens:    241434624 | elapsed time per iteration (ms): 6765.8 | learning rate: 1.105E-04 | global batch size:    32 | lm loss: 1.093101E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.51 |
time (ms)
 iteration     1843/  500000 | consumed samples:        58976 | consumed tokens:    241565696 | elapsed time per iteration (ms): 6762.6 | learning rate: 1.106E-04 | global batch size:    32 | lm loss: 1.133126E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1844/  500000 | consumed samples:        59008 | consumed tokens:    241696768 | elapsed time per iteration (ms): 6759.5 | learning rate: 1.106E-04 | global batch size:    32 | lm loss: 1.133080E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1845/  500000 | consumed samples:        59040 | consumed tokens:    241827840 | elapsed time per iteration (ms): 6757.6 | learning rate: 1.107E-04 | global batch size:    32 | lm loss: 1.123393E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1846/  500000 | consumed samples:        59072 | consumed tokens:    241958912 | elapsed time per iteration (ms): 6757.4 | learning rate: 1.108E-04 | global batch size:    32 | lm loss: 1.088987E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1847/  500000 | consumed samples:        59104 | consumed tokens:    242089984 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.108E-04 | global batch size:    32 | lm loss: 1.132863E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1848/  500000 | consumed samples:        59136 | consumed tokens:    242221056 | elapsed time per iteration (ms): 6760.6 | learning rate: 1.109E-04 | global batch size:    32 | lm loss: 1.142804E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1849/  500000 | consumed samples:        59168 | consumed tokens:    242352128 | elapsed time per iteration (ms): 6761.7 | learning rate: 1.109E-04 | global batch size:    32 | lm loss: 1.141240E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
[2023-10-10 18:38:41,872] [INFO] [logging.py:96:log_dist] [Rank 0] step=1850, skipped=0, lr=[0.00011099999999999999], mom=[(0.9, 0.95)]
[2023-10-10 18:38:42,132] [INFO] [timer.py:208:stop] epoch=0/micro_step=1850/global_step=1850, RunningAvgSamplesPerSec=4.742852712854206, CurrSamplesPerSec=4.739873513652634, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1850/  500000 | consumed samples:        59200 | consumed tokens:    242483200 | elapsed time per iteration (ms): 6764.2 | learning rate: 1.110E-04 | global batch size:    32 | lm loss: 1.102356E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     1851/  500000 | consumed samples:        59232 | consumed tokens:    242614272 | elapsed time per iteration (ms): 6761.1 | learning rate: 1.111E-04 | global batch size:    32 | lm loss: 1.097909E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1852/  500000 | consumed samples:        59264 | consumed tokens:    242745344 | elapsed time per iteration (ms): 6757.3 | learning rate: 1.111E-04 | global batch size:    32 | lm loss: 1.162916E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1853/  500000 | consumed samples:        59296 | consumed tokens:    242876416 | elapsed time per iteration (ms): 6757.5 | learning rate: 1.112E-04 | global batch size:    32 | lm loss: 1.100946E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1854/  500000 | consumed samples:        59328 | consumed tokens:    243007488 | elapsed time per iteration (ms): 6760.5 | learning rate: 1.112E-04 | global batch size:    32 | lm loss: 1.140848E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1855/  500000 | consumed samples:        59360 | consumed tokens:    243138560 | elapsed time per iteration (ms): 6759.5 | learning rate: 1.113E-04 | global batch size:    32 | lm loss: 1.116874E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1856/  500000 | consumed samples:        59392 | consumed tokens:    243269632 | elapsed time per iteration (ms): 6759.0 | learning rate: 1.114E-04 | global batch size:    32 | lm loss: 1.089278E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1857/  500000 | consumed samples:        59424 | consumed tokens:    243400704 | elapsed time per iteration (ms): 6759.7 | learning rate: 1.114E-04 | global batch size:    32 | lm loss: 1.109956E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1858/  500000 | consumed samples:        59456 | consumed tokens:    243531776 | elapsed time per iteration (ms): 6758.4 | learning rate: 1.115E-04 | global batch size:    32 | lm loss: 1.115650E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1859/  500000 | consumed samples:        59488 | consumed tokens:    243662848 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.115E-04 | global batch size:    32 | lm loss: 1.119742E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
[2023-10-10 18:39:49,514] [INFO] [logging.py:96:log_dist] [Rank 0] step=1860, skipped=0, lr=[0.00011159999999999999], mom=[(0.9, 0.95)]
[2023-10-10 18:39:49,771] [INFO] [timer.py:208:stop] epoch=0/micro_step=1860/global_step=1860, RunningAvgSamplesPerSec=4.742856524847562, CurrSamplesPerSec=4.744336251103566, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1860/  500000 | consumed samples:        59520 | consumed tokens:    243793920 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.116E-04 | global batch size:    32 | lm loss: 1.114850E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1861/  500000 | consumed samples:        59552 | consumed tokens:    243924992 | elapsed time per iteration (ms): 6757.9 | learning rate: 1.117E-04 | global batch size:    32 | lm loss: 1.119169E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1862/  500000 | consumed samples:        59584 | consumed tokens:    244056064 | elapsed time per iteration (ms): 6757.5 | learning rate: 1.117E-04 | global batch size:    32 | lm loss: 1.108030E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1863/  500000 | consumed samples:        59616 | consumed tokens:    244187136 | elapsed time per iteration (ms): 6757.2 | learning rate: 1.118E-04 | global batch size:    32 | lm loss: 1.128763E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1864/  500000 | consumed samples:        59648 | consumed tokens:    244318208 | elapsed time per iteration (ms): 6758.2 | learning rate: 1.118E-04 | global batch size:    32 | lm loss: 1.137313E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1865/  500000 | consumed samples:        59680 | consumed tokens:    244449280 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.119E-04 | global batch size:    32 | lm loss: 1.098866E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1866/  500000 | consumed samples:        59712 | consumed tokens:    244580352 | elapsed time per iteration (ms): 6759.9 | learning rate: 1.120E-04 | global batch size:    32 | lm loss: 1.089084E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1867/  500000 | consumed samples:        59744 | consumed tokens:    244711424 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.120E-04 | global batch size:    32 | lm loss: 1.131758E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1868/  500000 | consumed samples:        59776 | consumed tokens:    244842496 | elapsed time per iteration (ms): 6760.3 | learning rate: 1.121E-04 | global batch size:    32 | lm loss: 1.122209E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1869/  500000 | consumed samples:        59808 | consumed tokens:    244973568 | elapsed time per iteration (ms): 6758.8 | learning rate: 1.121E-04 | global batch size:    32 | lm loss: 1.112566E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
[2023-10-10 18:40:57,149] [INFO] [logging.py:96:log_dist] [Rank 0] step=1870, skipped=0, lr=[0.00011219999999999999], mom=[(0.9, 0.95)]
[2023-10-10 18:40:57,401] [INFO] [timer.py:208:stop] epoch=0/micro_step=1870/global_step=1870, RunningAvgSamplesPerSec=4.742860040866918, CurrSamplesPerSec=4.744183143132152, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1870/  500000 | consumed samples:        59840 | consumed tokens:    245104640 | elapsed time per iteration (ms): 6757.3 | learning rate: 1.122E-04 | global batch size:    32 | lm loss: 1.117150E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1871/  500000 | consumed samples:        59872 | consumed tokens:    245235712 | elapsed time per iteration (ms): 6757.7 | learning rate: 1.123E-04 | global batch size:    32 | lm loss: 1.112071E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1872/  500000 | consumed samples:        59904 | consumed tokens:    245366784 | elapsed time per iteration (ms): 6760.1 | learning rate: 1.123E-04 | global batch size:    32 | lm loss: 1.128927E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1873/  500000 | consumed samples:        59936 | consumed tokens:    245497856 | elapsed time per iteration (ms): 6760.2 | learning rate: 1.124E-04 | global batch size:    32 | lm loss: 1.127271E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration     1874/  500000 | consumed samples:        59968 | consumed tokens:    245628928 | elapsed time per iteration (ms): 6756.2 | learning rate: 1.124E-04 | global batch size:    32 | lm loss: 1.114369E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1875/  500000 | consumed samples:        60000 | consumed tokens:    245760000 | elapsed time per iteration (ms): 6759.7 | learning rate: 1.125E-04 | global batch size:    32 | lm loss: 1.137504E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1876/  500000 | consumed samples:        60032 | consumed tokens:    245891072 | elapsed time per iteration (ms): 6759.5 | learning rate: 1.126E-04 | global batch size:    32 | lm loss: 1.123629E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1877/  500000 | consumed samples:        60064 | consumed tokens:    246022144 | elapsed time per iteration (ms): 6756.9 | learning rate: 1.126E-04 | global batch size:    32 | lm loss: 1.136458E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1878/  500000 | consumed samples:        60096 | consumed tokens:    246153216 | elapsed time per iteration (ms): 6756.3 | learning rate: 1.127E-04 | global batch size:    32 | lm loss: 1.127523E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1879/  500000 | consumed samples:        60128 | consumed tokens:    246284288 | elapsed time per iteration (ms): 6756.4 | learning rate: 1.127E-04 | global batch size:    32 | lm loss: 1.121594E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
[2023-10-10 18:42:04,764] [INFO] [logging.py:96:log_dist] [Rank 0] step=1880, skipped=0, lr=[0.00011279999999999999], mom=[(0.9, 0.95)]
[2023-10-10 18:42:05,024] [INFO] [timer.py:208:stop] epoch=0/micro_step=1880/global_step=1880, RunningAvgSamplesPerSec=4.742866172206683, CurrSamplesPerSec=4.74414155581705, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1880/  500000 | consumed samples:        60160 | consumed tokens:    246415360 | elapsed time per iteration (ms): 6758.9 | learning rate: 1.128E-04 | global batch size:    32 | lm loss: 1.112797E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.66 |
time (ms)
 iteration     1881/  500000 | consumed samples:        60192 | consumed tokens:    246546432 | elapsed time per iteration (ms): 6762.2 | learning rate: 1.129E-04 | global batch size:    32 | lm loss: 1.117759E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1882/  500000 | consumed samples:        60224 | consumed tokens:    246677504 | elapsed time per iteration (ms): 6762.0 | learning rate: 1.129E-04 | global batch size:    32 | lm loss: 1.109050E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1883/  500000 | consumed samples:        60256 | consumed tokens:    246808576 | elapsed time per iteration (ms): 6760.5 | learning rate: 1.130E-04 | global batch size:    32 | lm loss: 1.127966E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1884/  500000 | consumed samples:        60288 | consumed tokens:    246939648 | elapsed time per iteration (ms): 6759.7 | learning rate: 1.130E-04 | global batch size:    32 | lm loss: 1.100073E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1885/  500000 | consumed samples:        60320 | consumed tokens:    247070720 | elapsed time per iteration (ms): 6758.9 | learning rate: 1.131E-04 | global batch size:    32 | lm loss: 1.127141E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1886/  500000 | consumed samples:        60352 | consumed tokens:    247201792 | elapsed time per iteration (ms): 6753.5 | learning rate: 1.132E-04 | global batch size:    32 | lm loss: 1.100443E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.738 | TFLOPs: 147.78 |
time (ms)
 iteration     1887/  500000 | consumed samples:        60384 | consumed tokens:    247332864 | elapsed time per iteration (ms): 6758.4 | learning rate: 1.132E-04 | global batch size:    32 | lm loss: 1.083561E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1888/  500000 | consumed samples:        60416 | consumed tokens:    247463936 | elapsed time per iteration (ms): 6757.2 | learning rate: 1.133E-04 | global batch size:    32 | lm loss: 1.118016E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1889/  500000 | consumed samples:        60448 | consumed tokens:    247595008 | elapsed time per iteration (ms): 6758.5 | learning rate: 1.133E-04 | global batch size:    32 | lm loss: 1.125370E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
[2023-10-10 18:43:12,398] [INFO] [logging.py:96:log_dist] [Rank 0] step=1890, skipped=0, lr=[0.00011339999999999999], mom=[(0.9, 0.95)]
[2023-10-10 18:43:12,655] [INFO] [timer.py:208:stop] epoch=0/micro_step=1890/global_step=1890, RunningAvgSamplesPerSec=4.742869356219682, CurrSamplesPerSec=4.743750201238154, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1890/  500000 | consumed samples:        60480 | consumed tokens:    247726080 | elapsed time per iteration (ms): 6758.1 | learning rate: 1.134E-04 | global batch size:    32 | lm loss: 1.117672E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1891/  500000 | consumed samples:        60512 | consumed tokens:    247857152 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.135E-04 | global batch size:    32 | lm loss: 1.141581E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1892/  500000 | consumed samples:        60544 | consumed tokens:    247988224 | elapsed time per iteration (ms): 6760.3 | learning rate: 1.135E-04 | global batch size:    32 | lm loss: 1.118068E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration     1893/  500000 | consumed samples:        60576 | consumed tokens:    248119296 | elapsed time per iteration (ms): 6760.1 | learning rate: 1.136E-04 | global batch size:    32 | lm loss: 1.098821E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1894/  500000 | consumed samples:        60608 | consumed tokens:    248250368 | elapsed time per iteration (ms): 6758.0 | learning rate: 1.136E-04 | global batch size:    32 | lm loss: 1.132323E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1895/  500000 | consumed samples:        60640 | consumed tokens:    248381440 | elapsed time per iteration (ms): 6764.0 | learning rate: 1.137E-04 | global batch size:    32 | lm loss: 1.133153E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     1896/  500000 | consumed samples:        60672 | consumed tokens:    248512512 | elapsed time per iteration (ms): 6761.9 | learning rate: 1.138E-04 | global batch size:    32 | lm loss: 1.110342E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1897/  500000 | consumed samples:        60704 | consumed tokens:    248643584 | elapsed time per iteration (ms): 6763.7 | learning rate: 1.138E-04 | global batch size:    32 | lm loss: 1.122922E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     1898/  500000 | consumed samples:        60736 | consumed tokens:    248774656 | elapsed time per iteration (ms): 6759.2 | learning rate: 1.139E-04 | global batch size:    32 | lm loss: 1.124780E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1899/  500000 | consumed samples:        60768 | consumed tokens:    248905728 | elapsed time per iteration (ms): 6766.1 | learning rate: 1.139E-04 | global batch size:    32 | lm loss: 1.083599E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.51 |
time (ms)
[2023-10-10 18:44:20,081] [INFO] [logging.py:96:log_dist] [Rank 0] step=1900, skipped=0, lr=[0.00011399999999999999], mom=[(0.9, 0.95)]
[2023-10-10 18:44:20,312] [INFO] [timer.py:208:stop] epoch=0/micro_step=1900/global_step=1900, RunningAvgSamplesPerSec=4.742863779512448, CurrSamplesPerSec=4.7421663276394925, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1900/  500000 | consumed samples:        60800 | consumed tokens:    249036800 | elapsed time per iteration (ms): 6761.4 | learning rate: 1.140E-04 | global batch size:    32 | lm loss: 1.070645E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1901/  500000 | consumed samples:        60832 | consumed tokens:    249167872 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.141E-04 | global batch size:    32 | lm loss: 1.104711E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1902/  500000 | consumed samples:        60864 | consumed tokens:    249298944 | elapsed time per iteration (ms): 6756.2 | learning rate: 1.141E-04 | global batch size:    32 | lm loss: 1.087632E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1903/  500000 | consumed samples:        60896 | consumed tokens:    249430016 | elapsed time per iteration (ms): 6757.7 | learning rate: 1.142E-04 | global batch size:    32 | lm loss: 1.144923E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1904/  500000 | consumed samples:        60928 | consumed tokens:    249561088 | elapsed time per iteration (ms): 6757.2 | learning rate: 1.142E-04 | global batch size:    32 | lm loss: 1.118103E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1905/  500000 | consumed samples:        60960 | consumed tokens:    249692160 | elapsed time per iteration (ms): 6758.9 | learning rate: 1.143E-04 | global batch size:    32 | lm loss: 1.102695E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1906/  500000 | consumed samples:        60992 | consumed tokens:    249823232 | elapsed time per iteration (ms): 6761.8 | learning rate: 1.144E-04 | global batch size:    32 | lm loss: 1.071813E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1907/  500000 | consumed samples:        61024 | consumed tokens:    249954304 | elapsed time per iteration (ms): 6760.0 | learning rate: 1.144E-04 | global batch size:    32 | lm loss: 1.099164E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1908/  500000 | consumed samples:        61056 | consumed tokens:    250085376 | elapsed time per iteration (ms): 6758.9 | learning rate: 1.145E-04 | global batch size:    32 | lm loss: 1.121356E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1909/  500000 | consumed samples:        61088 | consumed tokens:    250216448 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.145E-04 | global batch size:    32 | lm loss: 1.102387E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
[2023-10-10 18:45:27,694] [INFO] [logging.py:96:log_dist] [Rank 0] step=1910, skipped=0, lr=[0.0001146], mom=[(0.9, 0.95)]
[2023-10-10 18:45:27,941] [INFO] [timer.py:208:stop] epoch=0/micro_step=1910/global_step=1910, RunningAvgSamplesPerSec=4.7428694094187405, CurrSamplesPerSec=4.746133702638905, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1910/  500000 | consumed samples:        61120 | consumed tokens:    250347520 | elapsed time per iteration (ms): 6756.7 | learning rate: 1.146E-04 | global batch size:    32 | lm loss: 1.120042E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1911/  500000 | consumed samples:        61152 | consumed tokens:    250478592 | elapsed time per iteration (ms): 6757.7 | learning rate: 1.147E-04 | global batch size:    32 | lm loss: 1.123799E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1912/  500000 | consumed samples:        61184 | consumed tokens:    250609664 | elapsed time per iteration (ms): 6760.8 | learning rate: 1.147E-04 | global batch size:    32 | lm loss: 1.097051E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1913/  500000 | consumed samples:        61216 | consumed tokens:    250740736 | elapsed time per iteration (ms): 6761.8 | learning rate: 1.148E-04 | global batch size:    32 | lm loss: 1.136485E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1914/  500000 | consumed samples:        61248 | consumed tokens:    250871808 | elapsed time per iteration (ms): 6756.2 | learning rate: 1.148E-04 | global batch size:    32 | lm loss: 1.137085E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1915/  500000 | consumed samples:        61280 | consumed tokens:    251002880 | elapsed time per iteration (ms): 6760.3 | learning rate: 1.149E-04 | global batch size:    32 | lm loss: 1.115240E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration     1916/  500000 | consumed samples:        61312 | consumed tokens:    251133952 | elapsed time per iteration (ms): 6760.6 | learning rate: 1.150E-04 | global batch size:    32 | lm loss: 1.119808E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1917/  500000 | consumed samples:        61344 | consumed tokens:    251265024 | elapsed time per iteration (ms): 6762.3 | learning rate: 1.150E-04 | global batch size:    32 | lm loss: 1.138791E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1918/  500000 | consumed samples:        61376 | consumed tokens:    251396096 | elapsed time per iteration (ms): 6762.1 | learning rate: 1.151E-04 | global batch size:    32 | lm loss: 1.101722E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1919/  500000 | consumed samples:        61408 | consumed tokens:    251527168 | elapsed time per iteration (ms): 6758.8 | learning rate: 1.151E-04 | global batch size:    32 | lm loss: 1.117129E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
[2023-10-10 18:46:35,322] [INFO] [logging.py:96:log_dist] [Rank 0] step=1920, skipped=0, lr=[0.0001152], mom=[(0.9, 0.95)]
[2023-10-10 18:46:35,581] [INFO] [timer.py:208:stop] epoch=0/micro_step=1920/global_step=1920, RunningAvgSamplesPerSec=4.7428701946930465, CurrSamplesPerSec=4.745702586076894, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1920/  500000 | consumed samples:        61440 | consumed tokens:    251658240 | elapsed time per iteration (ms): 6756.7 | learning rate: 1.152E-04 | global batch size:    32 | lm loss: 1.098822E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1921/  500000 | consumed samples:        61472 | consumed tokens:    251789312 | elapsed time per iteration (ms): 6756.8 | learning rate: 1.153E-04 | global batch size:    32 | lm loss: 1.134975E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1922/  500000 | consumed samples:        61504 | consumed tokens:    251920384 | elapsed time per iteration (ms): 6758.9 | learning rate: 1.153E-04 | global batch size:    32 | lm loss: 1.105393E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.66 |
time (ms)
 iteration     1923/  500000 | consumed samples:        61536 | consumed tokens:    252051456 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.154E-04 | global batch size:    32 | lm loss: 1.110269E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1924/  500000 | consumed samples:        61568 | consumed tokens:    252182528 | elapsed time per iteration (ms): 6758.7 | learning rate: 1.154E-04 | global batch size:    32 | lm loss: 1.102989E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1925/  500000 | consumed samples:        61600 | consumed tokens:    252313600 | elapsed time per iteration (ms): 6763.4 | learning rate: 1.155E-04 | global batch size:    32 | lm loss: 1.073383E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration     1926/  500000 | consumed samples:        61632 | consumed tokens:    252444672 | elapsed time per iteration (ms): 6755.9 | learning rate: 1.156E-04 | global batch size:    32 | lm loss: 1.094829E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration     1927/  500000 | consumed samples:        61664 | consumed tokens:    252575744 | elapsed time per iteration (ms): 6759.0 | learning rate: 1.156E-04 | global batch size:    32 | lm loss: 1.151213E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1928/  500000 | consumed samples:        61696 | consumed tokens:    252706816 | elapsed time per iteration (ms): 6757.5 | learning rate: 1.157E-04 | global batch size:    32 | lm loss: 1.110304E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1929/  500000 | consumed samples:        61728 | consumed tokens:    252837888 | elapsed time per iteration (ms): 6757.4 | learning rate: 1.157E-04 | global batch size:    32 | lm loss: 1.133066E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
[2023-10-10 18:47:42,953] [INFO] [logging.py:96:log_dist] [Rank 0] step=1930, skipped=0, lr=[0.0001158], mom=[(0.9, 0.95)]
[2023-10-10 18:47:43,208] [INFO] [timer.py:208:stop] epoch=0/micro_step=1930/global_step=1930, RunningAvgSamplesPerSec=4.742875304724859, CurrSamplesPerSec=4.744802846958181, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1930/  500000 | consumed samples:        61760 | consumed tokens:    252968960 | elapsed time per iteration (ms): 6757.2 | learning rate: 1.158E-04 | global batch size:    32 | lm loss: 1.086832E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1931/  500000 | consumed samples:        61792 | consumed tokens:    253100032 | elapsed time per iteration (ms): 6754.8 | learning rate: 1.159E-04 | global batch size:    32 | lm loss: 1.107593E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.75 |
time (ms)
 iteration     1932/  500000 | consumed samples:        61824 | consumed tokens:    253231104 | elapsed time per iteration (ms): 6758.0 | learning rate: 1.159E-04 | global batch size:    32 | lm loss: 1.129989E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1933/  500000 | consumed samples:        61856 | consumed tokens:    253362176 | elapsed time per iteration (ms): 6757.0 | learning rate: 1.160E-04 | global batch size:    32 | lm loss: 1.137787E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1934/  500000 | consumed samples:        61888 | consumed tokens:    253493248 | elapsed time per iteration (ms): 6758.4 | learning rate: 1.160E-04 | global batch size:    32 | lm loss: 1.129931E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1935/  500000 | consumed samples:        61920 | consumed tokens:    253624320 | elapsed time per iteration (ms): 6758.1 | learning rate: 1.161E-04 | global batch size:    32 | lm loss: 1.107201E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1936/  500000 | consumed samples:        61952 | consumed tokens:    253755392 | elapsed time per iteration (ms): 6756.9 | learning rate: 1.162E-04 | global batch size:    32 | lm loss: 1.105050E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1937/  500000 | consumed samples:        61984 | consumed tokens:    253886464 | elapsed time per iteration (ms): 6760.3 | learning rate: 1.162E-04 | global batch size:    32 | lm loss: 1.120684E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1938/  500000 | consumed samples:        62016 | consumed tokens:    254017536 | elapsed time per iteration (ms): 6761.1 | learning rate: 1.163E-04 | global batch size:    32 | lm loss: 1.097556E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1939/  500000 | consumed samples:        62048 | consumed tokens:    254148608 | elapsed time per iteration (ms): 6761.0 | learning rate: 1.163E-04 | global batch size:    32 | lm loss: 1.123121E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
[2023-10-10 18:48:50,578] [INFO] [logging.py:96:log_dist] [Rank 0] step=1940, skipped=0, lr=[0.0001164], mom=[(0.9, 0.95)]
[2023-10-10 18:48:50,835] [INFO] [timer.py:208:stop] epoch=0/micro_step=1940/global_step=1940, RunningAvgSamplesPerSec=4.742880379069162, CurrSamplesPerSec=4.7431986585376675, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1940/  500000 | consumed samples:        62080 | consumed tokens:    254279680 | elapsed time per iteration (ms): 6758.9 | learning rate: 1.164E-04 | global batch size:    32 | lm loss: 1.091118E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1941/  500000 | consumed samples:        62112 | consumed tokens:    254410752 | elapsed time per iteration (ms): 6754.9 | learning rate: 1.165E-04 | global batch size:    32 | lm loss: 1.129272E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.75 |
time (ms)
 iteration     1942/  500000 | consumed samples:        62144 | consumed tokens:    254541824 | elapsed time per iteration (ms): 6757.8 | learning rate: 1.165E-04 | global batch size:    32 | lm loss: 1.081794E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1943/  500000 | consumed samples:        62176 | consumed tokens:    254672896 | elapsed time per iteration (ms): 6766.1 | learning rate: 1.166E-04 | global batch size:    32 | lm loss: 1.087173E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.51 |
time (ms)
 iteration     1944/  500000 | consumed samples:        62208 | consumed tokens:    254803968 | elapsed time per iteration (ms): 6757.6 | learning rate: 1.166E-04 | global batch size:    32 | lm loss: 1.090046E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1945/  500000 | consumed samples:        62240 | consumed tokens:    254935040 | elapsed time per iteration (ms): 6762.8 | learning rate: 1.167E-04 | global batch size:    32 | lm loss: 1.155816E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1946/  500000 | consumed samples:        62272 | consumed tokens:    255066112 | elapsed time per iteration (ms): 6763.0 | learning rate: 1.168E-04 | global batch size:    32 | lm loss: 1.122654E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration     1947/  500000 | consumed samples:        62304 | consumed tokens:    255197184 | elapsed time per iteration (ms): 6764.2 | learning rate: 1.168E-04 | global batch size:    32 | lm loss: 1.116621E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     1948/  500000 | consumed samples:        62336 | consumed tokens:    255328256 | elapsed time per iteration (ms): 6758.2 | learning rate: 1.169E-04 | global batch size:    32 | lm loss: 1.096227E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1949/  500000 | consumed samples:        62368 | consumed tokens:    255459328 | elapsed time per iteration (ms): 6759.6 | learning rate: 1.169E-04 | global batch size:    32 | lm loss: 1.138869E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
[2023-10-10 18:49:58,226] [INFO] [logging.py:96:log_dist] [Rank 0] step=1950, skipped=0, lr=[0.000117], mom=[(0.9, 0.95)]
[2023-10-10 18:49:58,487] [INFO] [timer.py:208:stop] epoch=0/micro_step=1950/global_step=1950, RunningAvgSamplesPerSec=4.742877653341981, CurrSamplesPerSec=4.739887741652463, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1950/  500000 | consumed samples:        62400 | consumed tokens:    255590400 | elapsed time per iteration (ms): 6764.9 | learning rate: 1.170E-04 | global batch size:    32 | lm loss: 1.117778E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration     1951/  500000 | consumed samples:        62432 | consumed tokens:    255721472 | elapsed time per iteration (ms): 6766.2 | learning rate: 1.171E-04 | global batch size:    32 | lm loss: 1.111193E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.51 |
time (ms)
 iteration     1952/  500000 | consumed samples:        62464 | consumed tokens:    255852544 | elapsed time per iteration (ms): 6758.9 | learning rate: 1.171E-04 | global batch size:    32 | lm loss: 1.136932E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1953/  500000 | consumed samples:        62496 | consumed tokens:    255983616 | elapsed time per iteration (ms): 6761.7 | learning rate: 1.172E-04 | global batch size:    32 | lm loss: 1.107010E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     1954/  500000 | consumed samples:        62528 | consumed tokens:    256114688 | elapsed time per iteration (ms): 6763.0 | learning rate: 1.172E-04 | global batch size:    32 | lm loss: 1.107553E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     1955/  500000 | consumed samples:        62560 | consumed tokens:    256245760 | elapsed time per iteration (ms): 6763.7 | learning rate: 1.173E-04 | global batch size:    32 | lm loss: 1.136179E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     1956/  500000 | consumed samples:        62592 | consumed tokens:    256376832 | elapsed time per iteration (ms): 6760.3 | learning rate: 1.174E-04 | global batch size:    32 | lm loss: 1.090964E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration     1957/  500000 | consumed samples:        62624 | consumed tokens:    256507904 | elapsed time per iteration (ms): 6758.0 | learning rate: 1.174E-04 | global batch size:    32 | lm loss: 1.085705E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1958/  500000 | consumed samples:        62656 | consumed tokens:    256638976 | elapsed time per iteration (ms): 6756.6 | learning rate: 1.175E-04 | global batch size:    32 | lm loss: 1.122670E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1959/  500000 | consumed samples:        62688 | consumed tokens:    256770048 | elapsed time per iteration (ms): 6758.2 | learning rate: 1.175E-04 | global batch size:    32 | lm loss: 1.123016E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
[2023-10-10 18:51:05,889] [INFO] [logging.py:96:log_dist] [Rank 0] step=1960, skipped=0, lr=[0.0001176], mom=[(0.9, 0.95)]
[2023-10-10 18:51:06,137] [INFO] [timer.py:208:stop] epoch=0/micro_step=1960/global_step=1960, RunningAvgSamplesPerSec=4.742875669257003, CurrSamplesPerSec=4.743089706306886, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1960/  500000 | consumed samples:        62720 | consumed tokens:    256901120 | elapsed time per iteration (ms): 6758.9 | learning rate: 1.176E-04 | global batch size:    32 | lm loss: 1.110052E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1961/  500000 | consumed samples:        62752 | consumed tokens:    257032192 | elapsed time per iteration (ms): 6759.8 | learning rate: 1.177E-04 | global batch size:    32 | lm loss: 1.096181E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1962/  500000 | consumed samples:        62784 | consumed tokens:    257163264 | elapsed time per iteration (ms): 6761.4 | learning rate: 1.177E-04 | global batch size:    32 | lm loss: 1.116812E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1963/  500000 | consumed samples:        62816 | consumed tokens:    257294336 | elapsed time per iteration (ms): 6757.8 | learning rate: 1.178E-04 | global batch size:    32 | lm loss: 1.099248E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1964/  500000 | consumed samples:        62848 | consumed tokens:    257425408 | elapsed time per iteration (ms): 6759.6 | learning rate: 1.178E-04 | global batch size:    32 | lm loss: 1.100025E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     1965/  500000 | consumed samples:        62880 | consumed tokens:    257556480 | elapsed time per iteration (ms): 6761.4 | learning rate: 1.179E-04 | global batch size:    32 | lm loss: 1.098779E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     1966/  500000 | consumed samples:        62912 | consumed tokens:    257687552 | elapsed time per iteration (ms): 6761.6 | learning rate: 1.180E-04 | global batch size:    32 | lm loss: 1.145412E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     1967/  500000 | consumed samples:        62944 | consumed tokens:    257818624 | elapsed time per iteration (ms): 6759.0 | learning rate: 1.180E-04 | global batch size:    32 | lm loss: 1.122706E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1968/  500000 | consumed samples:        62976 | consumed tokens:    257949696 | elapsed time per iteration (ms): 6757.5 | learning rate: 1.181E-04 | global batch size:    32 | lm loss: 1.099924E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1969/  500000 | consumed samples:        63008 | consumed tokens:    258080768 | elapsed time per iteration (ms): 6761.5 | learning rate: 1.181E-04 | global batch size:    32 | lm loss: 1.108640E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
[2023-10-10 18:52:13,519] [INFO] [logging.py:96:log_dist] [Rank 0] step=1970, skipped=0, lr=[0.0001182], mom=[(0.9, 0.95)]
[2023-10-10 18:52:13,778] [INFO] [timer.py:208:stop] epoch=0/micro_step=1970/global_step=1970, RunningAvgSamplesPerSec=4.742876749555991, CurrSamplesPerSec=4.744495574380365, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1970/  500000 | consumed samples:        63040 | consumed tokens:    258211840 | elapsed time per iteration (ms): 6758.1 | learning rate: 1.182E-04 | global batch size:    32 | lm loss: 1.143883E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1971/  500000 | consumed samples:        63072 | consumed tokens:    258342912 | elapsed time per iteration (ms): 6758.4 | learning rate: 1.183E-04 | global batch size:    32 | lm loss: 1.121226E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1972/  500000 | consumed samples:        63104 | consumed tokens:    258473984 | elapsed time per iteration (ms): 6760.6 | learning rate: 1.183E-04 | global batch size:    32 | lm loss: 1.091077E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     1973/  500000 | consumed samples:        63136 | consumed tokens:    258605056 | elapsed time per iteration (ms): 6762.1 | learning rate: 1.184E-04 | global batch size:    32 | lm loss: 1.108889E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1974/  500000 | consumed samples:        63168 | consumed tokens:    258736128 | elapsed time per iteration (ms): 6757.9 | learning rate: 1.184E-04 | global batch size:    32 | lm loss: 1.102017E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1975/  500000 | consumed samples:        63200 | consumed tokens:    258867200 | elapsed time per iteration (ms): 6758.2 | learning rate: 1.185E-04 | global batch size:    32 | lm loss: 1.148309E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     1976/  500000 | consumed samples:        63232 | consumed tokens:    258998272 | elapsed time per iteration (ms): 6755.8 | learning rate: 1.186E-04 | global batch size:    32 | lm loss: 1.087070E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration     1977/  500000 | consumed samples:        63264 | consumed tokens:    259129344 | elapsed time per iteration (ms): 6758.8 | learning rate: 1.186E-04 | global batch size:    32 | lm loss: 1.099443E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     1978/  500000 | consumed samples:        63296 | consumed tokens:    259260416 | elapsed time per iteration (ms): 6760.0 | learning rate: 1.187E-04 | global batch size:    32 | lm loss: 1.117423E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     1979/  500000 | consumed samples:        63328 | consumed tokens:    259391488 | elapsed time per iteration (ms): 6758.3 | learning rate: 1.187E-04 | global batch size:    32 | lm loss: 1.106291E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
[2023-10-10 18:53:21,163] [INFO] [logging.py:96:log_dist] [Rank 0] step=1980, skipped=0, lr=[0.0001188], mom=[(0.9, 0.95)]
[2023-10-10 18:53:21,414] [INFO] [timer.py:208:stop] epoch=0/micro_step=1980/global_step=1980, RunningAvgSamplesPerSec=4.742878456032676, CurrSamplesPerSec=4.742258984439813, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1980/  500000 | consumed samples:        63360 | consumed tokens:    259522560 | elapsed time per iteration (ms): 6761.7 | learning rate: 1.188E-04 | global batch size:    32 | lm loss: 1.118373E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     1981/  500000 | consumed samples:        63392 | consumed tokens:    259653632 | elapsed time per iteration (ms): 6757.6 | learning rate: 1.189E-04 | global batch size:    32 | lm loss: 1.124976E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     1982/  500000 | consumed samples:        63424 | consumed tokens:    259784704 | elapsed time per iteration (ms): 6761.1 | learning rate: 1.189E-04 | global batch size:    32 | lm loss: 1.111444E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1983/  500000 | consumed samples:        63456 | consumed tokens:    259915776 | elapsed time per iteration (ms): 6756.3 | learning rate: 1.190E-04 | global batch size:    32 | lm loss: 1.139900E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     1984/  500000 | consumed samples:        63488 | consumed tokens:    260046848 | elapsed time per iteration (ms): 6756.1 | learning rate: 1.190E-04 | global batch size:    32 | lm loss: 1.104746E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.73 |
time (ms)
 iteration     1985/  500000 | consumed samples:        63520 | consumed tokens:    260177920 | elapsed time per iteration (ms): 6762.1 | learning rate: 1.191E-04 | global batch size:    32 | lm loss: 1.107472E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     1986/  500000 | consumed samples:        63552 | consumed tokens:    260308992 | elapsed time per iteration (ms): 6759.0 | learning rate: 1.192E-04 | global batch size:    32 | lm loss: 1.131567E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     1987/  500000 | consumed samples:        63584 | consumed tokens:    260440064 | elapsed time per iteration (ms): 6763.1 | learning rate: 1.192E-04 | global batch size:    32 | lm loss: 1.085425E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration     1988/  500000 | consumed samples:        63616 | consumed tokens:    260571136 | elapsed time per iteration (ms): 6761.6 | learning rate: 1.193E-04 | global batch size:    32 | lm loss: 1.139742E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     1989/  500000 | consumed samples:        63648 | consumed tokens:    260702208 | elapsed time per iteration (ms): 6759.6 | learning rate: 1.193E-04 | global batch size:    32 | lm loss: 1.075550E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
[2023-10-10 18:54:28,801] [INFO] [logging.py:96:log_dist] [Rank 0] step=1990, skipped=0, lr=[0.00011939999999999999], mom=[(0.9, 0.95)]
[2023-10-10 18:54:29,056] [INFO] [timer.py:208:stop] epoch=0/micro_step=1990/global_step=1990, RunningAvgSamplesPerSec=4.742877412146665, CurrSamplesPerSec=4.740790138707017, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     1990/  500000 | consumed samples:        63680 | consumed tokens:    260833280 | elapsed time per iteration (ms): 6764.1 | learning rate: 1.194E-04 | global batch size:    32 | lm loss: 1.108785E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     1991/  500000 | consumed samples:        63712 | consumed tokens:    260964352 | elapsed time per iteration (ms): 6762.1 | learning rate: 1.195E-04 | global batch size:    32 | lm loss: 1.137030E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     1992/  500000 | consumed samples:        63744 | consumed tokens:    261095424 | elapsed time per iteration (ms): 6761.0 | learning rate: 1.195E-04 | global batch size:    32 | lm loss: 1.144228E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     1993/  500000 | consumed samples:        63776 | consumed tokens:    261226496 | elapsed time per iteration (ms): 6765.2 | learning rate: 1.196E-04 | global batch size:    32 | lm loss: 1.144907E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration     1994/  500000 | consumed samples:        63808 | consumed tokens:    261357568 | elapsed time per iteration (ms): 6763.4 | learning rate: 1.196E-04 | global batch size:    32 | lm loss: 1.127773E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration     1995/  500000 | consumed samples:        63840 | consumed tokens:    261488640 | elapsed time per iteration (ms): 6765.3 | learning rate: 1.197E-04 | global batch size:    32 | lm loss: 1.117122E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration     1996/  500000 | consumed samples:        63872 | consumed tokens:    261619712 | elapsed time per iteration (ms): 6761.6 | learning rate: 1.198E-04 | global batch size:    32 | lm loss: 1.139961E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     1997/  500000 | consumed samples:        63904 | consumed tokens:    261750784 | elapsed time per iteration (ms): 6756.8 | learning rate: 1.198E-04 | global batch size:    32 | lm loss: 1.105513E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     1998/  500000 | consumed samples:        63936 | consumed tokens:    261881856 | elapsed time per iteration (ms): 6757.5 | learning rate: 1.199E-04 | global batch size:    32 | lm loss: 1.109856E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     1999/  500000 | consumed samples:        63968 | consumed tokens:    262012928 | elapsed time per iteration (ms): 6759.0 | learning rate: 1.199E-04 | global batch size:    32 | lm loss: 1.105636E-01 | loss scale: 512.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
[2023-10-10 18:55:36,456] [INFO] [logging.py:96:log_dist] [Rank 0] step=2000, skipped=0, lr=[0.00011999999999999999], mom=[(0.9, 0.95)]
[2023-10-10 18:55:36,714] [INFO] [timer.py:208:stop] epoch=0/micro_step=2000/global_step=2000, RunningAvgSamplesPerSec=4.742873843323057, CurrSamplesPerSec=4.744099801544675, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2000/  500000 | consumed samples:        64000 | consumed tokens:    262144000 | elapsed time per iteration (ms): 6757.7 | learning rate: 1.200E-04 | global batch size:    32 | lm loss: 1.109026E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
------------------------------------------------------------------------------------------------
 validation loss at iteration 2000 | lm loss value: 1.770795E+00 | lm loss PPL: 5.875522E+00 | 
------------------------------------------------------------------------------------------------
 iteration     2001/  500000 | consumed samples:        64032 | consumed tokens:    262275072 | elapsed time per iteration (ms): 21487.0 | learning rate: 1.201E-04 | global batch size:    32 | lm loss: 1.130119E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.489 | TFLOPs: 46.45 |
time (ms)
 iteration     2002/  500000 | consumed samples:        64064 | consumed tokens:    262406144 | elapsed time per iteration (ms): 6757.4 | learning rate: 1.201E-04 | global batch size:    32 | lm loss: 1.128517E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     2003/  500000 | consumed samples:        64096 | consumed tokens:    262537216 | elapsed time per iteration (ms): 6757.0 | learning rate: 1.202E-04 | global batch size:    32 | lm loss: 1.113598E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     2004/  500000 | consumed samples:        64128 | consumed tokens:    262668288 | elapsed time per iteration (ms): 6756.6 | learning rate: 1.202E-04 | global batch size:    32 | lm loss: 1.107736E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     2005/  500000 | consumed samples:        64160 | consumed tokens:    262799360 | elapsed time per iteration (ms): 6759.1 | learning rate: 1.203E-04 | global batch size:    32 | lm loss: 1.119434E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2006/  500000 | consumed samples:        64192 | consumed tokens:    262930432 | elapsed time per iteration (ms): 6763.6 | learning rate: 1.204E-04 | global batch size:    32 | lm loss: 1.112699E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     2007/  500000 | consumed samples:        64224 | consumed tokens:    263061504 | elapsed time per iteration (ms): 6758.9 | learning rate: 1.204E-04 | global batch size:    32 | lm loss: 1.138872E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2008/  500000 | consumed samples:        64256 | consumed tokens:    263192576 | elapsed time per iteration (ms): 6760.8 | learning rate: 1.205E-04 | global batch size:    32 | lm loss: 1.067078E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2009/  500000 | consumed samples:        64288 | consumed tokens:    263323648 | elapsed time per iteration (ms): 6760.2 | learning rate: 1.205E-04 | global batch size:    32 | lm loss: 1.098470E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
[2023-10-10 18:56:58,818] [INFO] [logging.py:96:log_dist] [Rank 0] step=2010, skipped=0, lr=[0.00012059999999999999], mom=[(0.9, 0.95)]
[2023-10-10 18:56:59,078] [INFO] [timer.py:208:stop] epoch=0/micro_step=2010/global_step=2010, RunningAvgSamplesPerSec=4.742875531848093, CurrSamplesPerSec=4.741729733293148, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2010/  500000 | consumed samples:        64320 | consumed tokens:    263454720 | elapsed time per iteration (ms): 6761.9 | learning rate: 1.206E-04 | global batch size:    32 | lm loss: 1.121466E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     2011/  500000 | consumed samples:        64352 | consumed tokens:    263585792 | elapsed time per iteration (ms): 6759.9 | learning rate: 1.207E-04 | global batch size:    32 | lm loss: 1.114216E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2012/  500000 | consumed samples:        64384 | consumed tokens:    263716864 | elapsed time per iteration (ms): 6762.5 | learning rate: 1.207E-04 | global batch size:    32 | lm loss: 1.110200E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2013/  500000 | consumed samples:        64416 | consumed tokens:    263847936 | elapsed time per iteration (ms): 6762.5 | learning rate: 1.208E-04 | global batch size:    32 | lm loss: 1.133383E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2014/  500000 | consumed samples:        64448 | consumed tokens:    263979008 | elapsed time per iteration (ms): 6765.0 | learning rate: 1.208E-04 | global batch size:    32 | lm loss: 1.110574E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration     2015/  500000 | consumed samples:        64480 | consumed tokens:    264110080 | elapsed time per iteration (ms): 6765.3 | learning rate: 1.209E-04 | global batch size:    32 | lm loss: 1.116503E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration     2016/  500000 | consumed samples:        64512 | consumed tokens:    264241152 | elapsed time per iteration (ms): 6758.5 | learning rate: 1.210E-04 | global batch size:    32 | lm loss: 1.129416E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2017/  500000 | consumed samples:        64544 | consumed tokens:    264372224 | elapsed time per iteration (ms): 6759.0 | learning rate: 1.210E-04 | global batch size:    32 | lm loss: 1.093006E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2018/  500000 | consumed samples:        64576 | consumed tokens:    264503296 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.211E-04 | global batch size:    32 | lm loss: 1.126628E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2019/  500000 | consumed samples:        64608 | consumed tokens:    264634368 | elapsed time per iteration (ms): 6762.2 | learning rate: 1.211E-04 | global batch size:    32 | lm loss: 1.122991E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
[2023-10-10 18:58:06,483] [INFO] [logging.py:96:log_dist] [Rank 0] step=2020, skipped=0, lr=[0.00012119999999999999], mom=[(0.9, 0.95)]
[2023-10-10 18:58:06,739] [INFO] [timer.py:208:stop] epoch=0/micro_step=2020/global_step=2020, RunningAvgSamplesPerSec=4.74286901052458, CurrSamplesPerSec=4.74118284729558, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2020/  500000 | consumed samples:        64640 | consumed tokens:    264765440 | elapsed time per iteration (ms): 6762.4 | learning rate: 1.212E-04 | global batch size:    32 | lm loss: 1.088746E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2021/  500000 | consumed samples:        64672 | consumed tokens:    264896512 | elapsed time per iteration (ms): 6760.1 | learning rate: 1.213E-04 | global batch size:    32 | lm loss: 1.077010E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2022/  500000 | consumed samples:        64704 | consumed tokens:    265027584 | elapsed time per iteration (ms): 6761.2 | learning rate: 1.213E-04 | global batch size:    32 | lm loss: 1.116924E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2023/  500000 | consumed samples:        64736 | consumed tokens:    265158656 | elapsed time per iteration (ms): 6761.1 | learning rate: 1.214E-04 | global batch size:    32 | lm loss: 1.074168E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2024/  500000 | consumed samples:        64768 | consumed tokens:    265289728 | elapsed time per iteration (ms): 6758.1 | learning rate: 1.214E-04 | global batch size:    32 | lm loss: 1.104900E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2025/  500000 | consumed samples:        64800 | consumed tokens:    265420800 | elapsed time per iteration (ms): 6758.9 | learning rate: 1.215E-04 | global batch size:    32 | lm loss: 1.146310E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2026/  500000 | consumed samples:        64832 | consumed tokens:    265551872 | elapsed time per iteration (ms): 6765.3 | learning rate: 1.216E-04 | global batch size:    32 | lm loss: 1.093262E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration     2027/  500000 | consumed samples:        64864 | consumed tokens:    265682944 | elapsed time per iteration (ms): 6761.2 | learning rate: 1.216E-04 | global batch size:    32 | lm loss: 1.110811E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2028/  500000 | consumed samples:        64896 | consumed tokens:    265814016 | elapsed time per iteration (ms): 6761.0 | learning rate: 1.217E-04 | global batch size:    32 | lm loss: 1.088362E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2029/  500000 | consumed samples:        64928 | consumed tokens:    265945088 | elapsed time per iteration (ms): 6763.0 | learning rate: 1.217E-04 | global batch size:    32 | lm loss: 1.110199E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
[2023-10-10 18:59:14,137] [INFO] [logging.py:96:log_dist] [Rank 0] step=2030, skipped=0, lr=[0.00012179999999999999], mom=[(0.9, 0.95)]
[2023-10-10 18:59:14,394] [INFO] [timer.py:208:stop] epoch=0/micro_step=2030/global_step=2030, RunningAvgSamplesPerSec=4.742864642238086, CurrSamplesPerSec=4.741436760908704, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2030/  500000 | consumed samples:        64960 | consumed tokens:    266076160 | elapsed time per iteration (ms): 6763.6 | learning rate: 1.218E-04 | global batch size:    32 | lm loss: 1.084487E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     2031/  500000 | consumed samples:        64992 | consumed tokens:    266207232 | elapsed time per iteration (ms): 6757.8 | learning rate: 1.219E-04 | global batch size:    32 | lm loss: 1.106536E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     2032/  500000 | consumed samples:        65024 | consumed tokens:    266338304 | elapsed time per iteration (ms): 6760.2 | learning rate: 1.219E-04 | global batch size:    32 | lm loss: 1.122996E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2033/  500000 | consumed samples:        65056 | consumed tokens:    266469376 | elapsed time per iteration (ms): 6758.0 | learning rate: 1.220E-04 | global batch size:    32 | lm loss: 1.113646E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2034/  500000 | consumed samples:        65088 | consumed tokens:    266600448 | elapsed time per iteration (ms): 6765.0 | learning rate: 1.220E-04 | global batch size:    32 | lm loss: 1.085244E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration     2035/  500000 | consumed samples:        65120 | consumed tokens:    266731520 | elapsed time per iteration (ms): 6766.3 | learning rate: 1.221E-04 | global batch size:    32 | lm loss: 1.111207E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.50 |
time (ms)
 iteration     2036/  500000 | consumed samples:        65152 | consumed tokens:    266862592 | elapsed time per iteration (ms): 6760.9 | learning rate: 1.222E-04 | global batch size:    32 | lm loss: 1.092636E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2037/  500000 | consumed samples:        65184 | consumed tokens:    266993664 | elapsed time per iteration (ms): 6761.6 | learning rate: 1.222E-04 | global batch size:    32 | lm loss: 1.122093E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     2038/  500000 | consumed samples:        65216 | consumed tokens:    267124736 | elapsed time per iteration (ms): 6759.7 | learning rate: 1.223E-04 | global batch size:    32 | lm loss: 1.112872E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2039/  500000 | consumed samples:        65248 | consumed tokens:    267255808 | elapsed time per iteration (ms): 6762.1 | learning rate: 1.223E-04 | global batch size:    32 | lm loss: 1.119715E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
[2023-10-10 19:00:21,787] [INFO] [logging.py:96:log_dist] [Rank 0] step=2040, skipped=0, lr=[0.0001224], mom=[(0.9, 0.95)]
[2023-10-10 19:00:22,050] [INFO] [timer.py:208:stop] epoch=0/micro_step=2040/global_step=2040, RunningAvgSamplesPerSec=4.742860709591239, CurrSamplesPerSec=4.742991653578634, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2040/  500000 | consumed samples:        65280 | consumed tokens:    267386880 | elapsed time per iteration (ms): 6758.7 | learning rate: 1.224E-04 | global batch size:    32 | lm loss: 1.092478E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2041/  500000 | consumed samples:        65312 | consumed tokens:    267517952 | elapsed time per iteration (ms): 6760.3 | learning rate: 1.225E-04 | global batch size:    32 | lm loss: 1.117122E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration     2042/  500000 | consumed samples:        65344 | consumed tokens:    267649024 | elapsed time per iteration (ms): 6760.6 | learning rate: 1.225E-04 | global batch size:    32 | lm loss: 1.133293E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2043/  500000 | consumed samples:        65376 | consumed tokens:    267780096 | elapsed time per iteration (ms): 6762.0 | learning rate: 1.226E-04 | global batch size:    32 | lm loss: 1.112228E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     2044/  500000 | consumed samples:        65408 | consumed tokens:    267911168 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.226E-04 | global batch size:    32 | lm loss: 1.120025E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2045/  500000 | consumed samples:        65440 | consumed tokens:    268042240 | elapsed time per iteration (ms): 6758.6 | learning rate: 1.227E-04 | global batch size:    32 | lm loss: 1.110326E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2046/  500000 | consumed samples:        65472 | consumed tokens:    268173312 | elapsed time per iteration (ms): 6761.3 | learning rate: 1.228E-04 | global batch size:    32 | lm loss: 1.069235E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2047/  500000 | consumed samples:        65504 | consumed tokens:    268304384 | elapsed time per iteration (ms): 6758.5 | learning rate: 1.228E-04 | global batch size:    32 | lm loss: 1.079739E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2048/  500000 | consumed samples:        65536 | consumed tokens:    268435456 | elapsed time per iteration (ms): 6758.6 | learning rate: 1.229E-04 | global batch size:    32 | lm loss: 1.096950E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2049/  500000 | consumed samples:        65568 | consumed tokens:    268566528 | elapsed time per iteration (ms): 6760.7 | learning rate: 1.229E-04 | global batch size:    32 | lm loss: 1.097531E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
[2023-10-10 19:01:29,431] [INFO] [logging.py:96:log_dist] [Rank 0] step=2050, skipped=0, lr=[0.000123], mom=[(0.9, 0.95)]
[2023-10-10 19:01:29,691] [INFO] [timer.py:208:stop] epoch=0/micro_step=2050/global_step=2050, RunningAvgSamplesPerSec=4.742860347774972, CurrSamplesPerSec=4.7427638851957505, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2050/  500000 | consumed samples:        65600 | consumed tokens:    268697600 | elapsed time per iteration (ms): 6759.5 | learning rate: 1.230E-04 | global batch size:    32 | lm loss: 1.096378E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2051/  500000 | consumed samples:        65632 | consumed tokens:    268828672 | elapsed time per iteration (ms): 6761.0 | learning rate: 1.231E-04 | global batch size:    32 | lm loss: 1.126555E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2052/  500000 | consumed samples:        65664 | consumed tokens:    268959744 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.231E-04 | global batch size:    32 | lm loss: 1.087629E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2053/  500000 | consumed samples:        65696 | consumed tokens:    269090816 | elapsed time per iteration (ms): 6758.4 | learning rate: 1.232E-04 | global batch size:    32 | lm loss: 1.095576E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2054/  500000 | consumed samples:        65728 | consumed tokens:    269221888 | elapsed time per iteration (ms): 6756.1 | learning rate: 1.232E-04 | global batch size:    32 | lm loss: 1.141009E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.73 |
time (ms)
 iteration     2055/  500000 | consumed samples:        65760 | consumed tokens:    269352960 | elapsed time per iteration (ms): 6756.5 | learning rate: 1.233E-04 | global batch size:    32 | lm loss: 1.109613E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     2056/  500000 | consumed samples:        65792 | consumed tokens:    269484032 | elapsed time per iteration (ms): 6758.0 | learning rate: 1.234E-04 | global batch size:    32 | lm loss: 1.111555E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2057/  500000 | consumed samples:        65824 | consumed tokens:    269615104 | elapsed time per iteration (ms): 6759.7 | learning rate: 1.234E-04 | global batch size:    32 | lm loss: 1.087067E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2058/  500000 | consumed samples:        65856 | consumed tokens:    269746176 | elapsed time per iteration (ms): 6760.2 | learning rate: 1.235E-04 | global batch size:    32 | lm loss: 1.082769E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2059/  500000 | consumed samples:        65888 | consumed tokens:    269877248 | elapsed time per iteration (ms): 6762.5 | learning rate: 1.235E-04 | global batch size:    32 | lm loss: 1.143911E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
[2023-10-10 19:02:37,095] [INFO] [logging.py:96:log_dist] [Rank 0] step=2060, skipped=0, lr=[0.0001236], mom=[(0.9, 0.95)]
[2023-10-10 19:02:37,326] [INFO] [timer.py:208:stop] epoch=0/micro_step=2060/global_step=2060, RunningAvgSamplesPerSec=4.742861246465766, CurrSamplesPerSec=4.741469255774555, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2060/  500000 | consumed samples:        65920 | consumed tokens:    270008320 | elapsed time per iteration (ms): 6761.7 | learning rate: 1.236E-04 | global batch size:    32 | lm loss: 1.116446E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     2061/  500000 | consumed samples:        65952 | consumed tokens:    270139392 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.237E-04 | global batch size:    32 | lm loss: 1.098783E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2062/  500000 | consumed samples:        65984 | consumed tokens:    270270464 | elapsed time per iteration (ms): 6761.5 | learning rate: 1.237E-04 | global batch size:    32 | lm loss: 1.093992E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2063/  500000 | consumed samples:        66016 | consumed tokens:    270401536 | elapsed time per iteration (ms): 6761.6 | learning rate: 1.238E-04 | global batch size:    32 | lm loss: 1.145391E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     2064/  500000 | consumed samples:        66048 | consumed tokens:    270532608 | elapsed time per iteration (ms): 6760.9 | learning rate: 1.238E-04 | global batch size:    32 | lm loss: 1.103253E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2065/  500000 | consumed samples:        66080 | consumed tokens:    270663680 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.239E-04 | global batch size:    32 | lm loss: 1.082070E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2066/  500000 | consumed samples:        66112 | consumed tokens:    270794752 | elapsed time per iteration (ms): 6765.7 | learning rate: 1.240E-04 | global batch size:    32 | lm loss: 1.123087E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration     2067/  500000 | consumed samples:        66144 | consumed tokens:    270925824 | elapsed time per iteration (ms): 6758.0 | learning rate: 1.240E-04 | global batch size:    32 | lm loss: 1.109633E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2068/  500000 | consumed samples:        66176 | consumed tokens:    271056896 | elapsed time per iteration (ms): 6756.4 | learning rate: 1.241E-04 | global batch size:    32 | lm loss: 1.108109E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     2069/  500000 | consumed samples:        66208 | consumed tokens:    271187968 | elapsed time per iteration (ms): 6761.4 | learning rate: 1.241E-04 | global batch size:    32 | lm loss: 1.103864E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
[2023-10-10 19:03:44,720] [INFO] [logging.py:96:log_dist] [Rank 0] step=2070, skipped=0, lr=[0.0001242], mom=[(0.9, 0.95)]
[2023-10-10 19:03:44,977] [INFO] [timer.py:208:stop] epoch=0/micro_step=2070/global_step=2070, RunningAvgSamplesPerSec=4.742857779708989, CurrSamplesPerSec=4.741743972439056, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2070/  500000 | consumed samples:        66240 | consumed tokens:    271319040 | elapsed time per iteration (ms): 6761.4 | learning rate: 1.242E-04 | global batch size:    32 | lm loss: 1.061118E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2071/  500000 | consumed samples:        66272 | consumed tokens:    271450112 | elapsed time per iteration (ms): 6759.6 | learning rate: 1.243E-04 | global batch size:    32 | lm loss: 1.116427E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2072/  500000 | consumed samples:        66304 | consumed tokens:    271581184 | elapsed time per iteration (ms): 6762.5 | learning rate: 1.243E-04 | global batch size:    32 | lm loss: 1.091690E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2073/  500000 | consumed samples:        66336 | consumed tokens:    271712256 | elapsed time per iteration (ms): 6761.4 | learning rate: 1.244E-04 | global batch size:    32 | lm loss: 1.122073E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2074/  500000 | consumed samples:        66368 | consumed tokens:    271843328 | elapsed time per iteration (ms): 6762.7 | learning rate: 1.244E-04 | global batch size:    32 | lm loss: 1.082532E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     2075/  500000 | consumed samples:        66400 | consumed tokens:    271974400 | elapsed time per iteration (ms): 6758.8 | learning rate: 1.245E-04 | global batch size:    32 | lm loss: 1.112844E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2076/  500000 | consumed samples:        66432 | consumed tokens:    272105472 | elapsed time per iteration (ms): 6760.0 | learning rate: 1.246E-04 | global batch size:    32 | lm loss: 1.081761E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2077/  500000 | consumed samples:        66464 | consumed tokens:    272236544 | elapsed time per iteration (ms): 6765.2 | learning rate: 1.246E-04 | global batch size:    32 | lm loss: 1.091485E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration     2078/  500000 | consumed samples:        66496 | consumed tokens:    272367616 | elapsed time per iteration (ms): 6765.8 | learning rate: 1.247E-04 | global batch size:    32 | lm loss: 1.110247E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.51 |
time (ms)
 iteration     2079/  500000 | consumed samples:        66528 | consumed tokens:    272498688 | elapsed time per iteration (ms): 6758.8 | learning rate: 1.247E-04 | global batch size:    32 | lm loss: 1.081018E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
[2023-10-10 19:04:52,382] [INFO] [logging.py:96:log_dist] [Rank 0] step=2080, skipped=0, lr=[0.0001248], mom=[(0.9, 0.95)]
[2023-10-10 19:04:52,638] [INFO] [timer.py:208:stop] epoch=0/micro_step=2080/global_step=2080, RunningAvgSamplesPerSec=4.742852443300841, CurrSamplesPerSec=4.740671082985118, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2080/  500000 | consumed samples:        66560 | consumed tokens:    272629760 | elapsed time per iteration (ms): 6762.5 | learning rate: 1.248E-04 | global batch size:    32 | lm loss: 1.106957E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2081/  500000 | consumed samples:        66592 | consumed tokens:    272760832 | elapsed time per iteration (ms): 6756.2 | learning rate: 1.249E-04 | global batch size:    32 | lm loss: 1.107834E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     2082/  500000 | consumed samples:        66624 | consumed tokens:    272891904 | elapsed time per iteration (ms): 6761.3 | learning rate: 1.249E-04 | global batch size:    32 | lm loss: 1.062230E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2083/  500000 | consumed samples:        66656 | consumed tokens:    273022976 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.250E-04 | global batch size:    32 | lm loss: 1.091243E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2084/  500000 | consumed samples:        66688 | consumed tokens:    273154048 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.250E-04 | global batch size:    32 | lm loss: 1.113994E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2085/  500000 | consumed samples:        66720 | consumed tokens:    273285120 | elapsed time per iteration (ms): 6761.0 | learning rate: 1.251E-04 | global batch size:    32 | lm loss: 1.093026E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2086/  500000 | consumed samples:        66752 | consumed tokens:    273416192 | elapsed time per iteration (ms): 6762.1 | learning rate: 1.252E-04 | global batch size:    32 | lm loss: 1.101672E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     2087/  500000 | consumed samples:        66784 | consumed tokens:    273547264 | elapsed time per iteration (ms): 6764.7 | learning rate: 1.252E-04 | global batch size:    32 | lm loss: 1.099906E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration     2088/  500000 | consumed samples:        66816 | consumed tokens:    273678336 | elapsed time per iteration (ms): 6757.9 | learning rate: 1.253E-04 | global batch size:    32 | lm loss: 1.133295E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     2089/  500000 | consumed samples:        66848 | consumed tokens:    273809408 | elapsed time per iteration (ms): 6759.2 | learning rate: 1.253E-04 | global batch size:    32 | lm loss: 1.093378E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
[2023-10-10 19:06:00,025] [INFO] [logging.py:96:log_dist] [Rank 0] step=2090, skipped=0, lr=[0.00012539999999999999], mom=[(0.9, 0.95)]
[2023-10-10 19:06:00,281] [INFO] [timer.py:208:stop] epoch=0/micro_step=2090/global_step=2090, RunningAvgSamplesPerSec=4.74285069732222, CurrSamplesPerSec=4.742680593464899, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2090/  500000 | consumed samples:        66880 | consumed tokens:    273940480 | elapsed time per iteration (ms): 6759.8 | learning rate: 1.254E-04 | global batch size:    32 | lm loss: 1.088470E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2091/  500000 | consumed samples:        66912 | consumed tokens:    274071552 | elapsed time per iteration (ms): 6761.3 | learning rate: 1.255E-04 | global batch size:    32 | lm loss: 1.068609E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2092/  500000 | consumed samples:        66944 | consumed tokens:    274202624 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.255E-04 | global batch size:    32 | lm loss: 1.079094E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2093/  500000 | consumed samples:        66976 | consumed tokens:    274333696 | elapsed time per iteration (ms): 6760.5 | learning rate: 1.256E-04 | global batch size:    32 | lm loss: 1.112135E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2094/  500000 | consumed samples:        67008 | consumed tokens:    274464768 | elapsed time per iteration (ms): 6761.5 | learning rate: 1.256E-04 | global batch size:    32 | lm loss: 1.134016E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2095/  500000 | consumed samples:        67040 | consumed tokens:    274595840 | elapsed time per iteration (ms): 6760.7 | learning rate: 1.257E-04 | global batch size:    32 | lm loss: 1.088477E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2096/  500000 | consumed samples:        67072 | consumed tokens:    274726912 | elapsed time per iteration (ms): 6764.3 | learning rate: 1.258E-04 | global batch size:    32 | lm loss: 1.085518E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     2097/  500000 | consumed samples:        67104 | consumed tokens:    274857984 | elapsed time per iteration (ms): 6761.6 | learning rate: 1.258E-04 | global batch size:    32 | lm loss: 1.098474E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     2098/  500000 | consumed samples:        67136 | consumed tokens:    274989056 | elapsed time per iteration (ms): 6763.1 | learning rate: 1.259E-04 | global batch size:    32 | lm loss: 1.074554E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration     2099/  500000 | consumed samples:        67168 | consumed tokens:    275120128 | elapsed time per iteration (ms): 6763.0 | learning rate: 1.259E-04 | global batch size:    32 | lm loss: 1.110077E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
[2023-10-10 19:07:07,704] [INFO] [logging.py:96:log_dist] [Rank 0] step=2100, skipped=0, lr=[0.00012599999999999997], mom=[(0.9, 0.95)]
[2023-10-10 19:07:07,943] [INFO] [timer.py:208:stop] epoch=0/micro_step=2100/global_step=2100, RunningAvgSamplesPerSec=4.742844027768993, CurrSamplesPerSec=4.740827983269137, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2100/  500000 | consumed samples:        67200 | consumed tokens:    275251200 | elapsed time per iteration (ms): 6763.0 | learning rate: 1.260E-04 | global batch size:    32 | lm loss: 1.087983E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration     2101/  500000 | consumed samples:        67232 | consumed tokens:    275382272 | elapsed time per iteration (ms): 6761.1 | learning rate: 1.261E-04 | global batch size:    32 | lm loss: 1.096910E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2102/  500000 | consumed samples:        67264 | consumed tokens:    275513344 | elapsed time per iteration (ms): 6763.6 | learning rate: 1.261E-04 | global batch size:    32 | lm loss: 1.107507E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     2103/  500000 | consumed samples:        67296 | consumed tokens:    275644416 | elapsed time per iteration (ms): 6761.1 | learning rate: 1.262E-04 | global batch size:    32 | lm loss: 1.097462E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2104/  500000 | consumed samples:        67328 | consumed tokens:    275775488 | elapsed time per iteration (ms): 6758.3 | learning rate: 1.262E-04 | global batch size:    32 | lm loss: 1.086632E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2105/  500000 | consumed samples:        67360 | consumed tokens:    275906560 | elapsed time per iteration (ms): 6758.1 | learning rate: 1.263E-04 | global batch size:    32 | lm loss: 1.058845E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2106/  500000 | consumed samples:        67392 | consumed tokens:    276037632 | elapsed time per iteration (ms): 6758.6 | learning rate: 1.264E-04 | global batch size:    32 | lm loss: 1.115223E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2107/  500000 | consumed samples:        67424 | consumed tokens:    276168704 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.264E-04 | global batch size:    32 | lm loss: 1.061411E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2108/  500000 | consumed samples:        67456 | consumed tokens:    276299776 | elapsed time per iteration (ms): 6760.9 | learning rate: 1.265E-04 | global batch size:    32 | lm loss: 1.072903E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2109/  500000 | consumed samples:        67488 | consumed tokens:    276430848 | elapsed time per iteration (ms): 6759.1 | learning rate: 1.265E-04 | global batch size:    32 | lm loss: 1.095958E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
[2023-10-10 19:08:15,328] [INFO] [logging.py:96:log_dist] [Rank 0] step=2110, skipped=0, lr=[0.0001266], mom=[(0.9, 0.95)]
[2023-10-10 19:08:15,591] [INFO] [timer.py:208:stop] epoch=0/micro_step=2110/global_step=2110, RunningAvgSamplesPerSec=4.742842700033357, CurrSamplesPerSec=4.739686716306974, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2110/  500000 | consumed samples:        67520 | consumed tokens:    276561920 | elapsed time per iteration (ms): 6764.4 | learning rate: 1.266E-04 | global batch size:    32 | lm loss: 1.125561E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.54 |
time (ms)
 iteration     2111/  500000 | consumed samples:        67552 | consumed tokens:    276692992 | elapsed time per iteration (ms): 6759.9 | learning rate: 1.267E-04 | global batch size:    32 | lm loss: 1.110318E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2112/  500000 | consumed samples:        67584 | consumed tokens:    276824064 | elapsed time per iteration (ms): 6761.1 | learning rate: 1.267E-04 | global batch size:    32 | lm loss: 1.131264E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2113/  500000 | consumed samples:        67616 | consumed tokens:    276955136 | elapsed time per iteration (ms): 6759.2 | learning rate: 1.268E-04 | global batch size:    32 | lm loss: 1.120264E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2114/  500000 | consumed samples:        67648 | consumed tokens:    277086208 | elapsed time per iteration (ms): 6764.9 | learning rate: 1.268E-04 | global batch size:    32 | lm loss: 1.094902E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration     2115/  500000 | consumed samples:        67680 | consumed tokens:    277217280 | elapsed time per iteration (ms): 6760.8 | learning rate: 1.269E-04 | global batch size:    32 | lm loss: 1.061110E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2116/  500000 | consumed samples:        67712 | consumed tokens:    277348352 | elapsed time per iteration (ms): 6762.3 | learning rate: 1.270E-04 | global batch size:    32 | lm loss: 1.099136E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2117/  500000 | consumed samples:        67744 | consumed tokens:    277479424 | elapsed time per iteration (ms): 6756.7 | learning rate: 1.270E-04 | global batch size:    32 | lm loss: 1.094833E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     2118/  500000 | consumed samples:        67776 | consumed tokens:    277610496 | elapsed time per iteration (ms): 6764.2 | learning rate: 1.271E-04 | global batch size:    32 | lm loss: 1.100997E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     2119/  500000 | consumed samples:        67808 | consumed tokens:    277741568 | elapsed time per iteration (ms): 6762.2 | learning rate: 1.271E-04 | global batch size:    32 | lm loss: 1.085469E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
[2023-10-10 19:09:22,989] [INFO] [logging.py:96:log_dist] [Rank 0] step=2120, skipped=0, lr=[0.00012719999999999997], mom=[(0.9, 0.95)]
[2023-10-10 19:09:23,252] [INFO] [timer.py:208:stop] epoch=0/micro_step=2120/global_step=2120, RunningAvgSamplesPerSec=4.7428365168404065, CurrSamplesPerSec=4.737174752259426, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2120/  500000 | consumed samples:        67840 | consumed tokens:    277872640 | elapsed time per iteration (ms): 6767.4 | learning rate: 1.272E-04 | global batch size:    32 | lm loss: 1.101094E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.48 |
time (ms)
 iteration     2121/  500000 | consumed samples:        67872 | consumed tokens:    278003712 | elapsed time per iteration (ms): 6763.5 | learning rate: 1.273E-04 | global batch size:    32 | lm loss: 1.091335E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     2122/  500000 | consumed samples:        67904 | consumed tokens:    278134784 | elapsed time per iteration (ms): 6759.2 | learning rate: 1.273E-04 | global batch size:    32 | lm loss: 1.106188E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2123/  500000 | consumed samples:        67936 | consumed tokens:    278265856 | elapsed time per iteration (ms): 6762.5 | learning rate: 1.274E-04 | global batch size:    32 | lm loss: 1.089903E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2124/  500000 | consumed samples:        67968 | consumed tokens:    278396928 | elapsed time per iteration (ms): 6761.6 | learning rate: 1.274E-04 | global batch size:    32 | lm loss: 1.077659E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2125/  500000 | consumed samples:        68000 | consumed tokens:    278528000 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.275E-04 | global batch size:    32 | lm loss: 1.066246E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2126/  500000 | consumed samples:        68032 | consumed tokens:    278659072 | elapsed time per iteration (ms): 6762.4 | learning rate: 1.276E-04 | global batch size:    32 | lm loss: 1.090433E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2127/  500000 | consumed samples:        68064 | consumed tokens:    278790144 | elapsed time per iteration (ms): 6762.2 | learning rate: 1.276E-04 | global batch size:    32 | lm loss: 1.103501E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2128/  500000 | consumed samples:        68096 | consumed tokens:    278921216 | elapsed time per iteration (ms): 6760.3 | learning rate: 1.277E-04 | global batch size:    32 | lm loss: 1.069900E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2129/  500000 | consumed samples:        68128 | consumed tokens:    279052288 | elapsed time per iteration (ms): 6764.8 | learning rate: 1.277E-04 | global batch size:    32 | lm loss: 1.120882E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
[2023-10-10 19:10:30,652] [INFO] [logging.py:96:log_dist] [Rank 0] step=2130, skipped=0, lr=[0.0001278], mom=[(0.9, 0.95)]
[2023-10-10 19:10:30,911] [INFO] [timer.py:208:stop] epoch=0/micro_step=2130/global_step=2130, RunningAvgSamplesPerSec=4.742830777138107, CurrSamplesPerSec=4.742200005370486, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2130/  500000 | consumed samples:        68160 | consumed tokens:    279183360 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.278E-04 | global batch size:    32 | lm loss: 1.108843E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2131/  500000 | consumed samples:        68192 | consumed tokens:    279314432 | elapsed time per iteration (ms): 6760.3 | learning rate: 1.279E-04 | global batch size:    32 | lm loss: 1.129651E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2132/  500000 | consumed samples:        68224 | consumed tokens:    279445504 | elapsed time per iteration (ms): 6761.0 | learning rate: 1.279E-04 | global batch size:    32 | lm loss: 1.112365E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2133/  500000 | consumed samples:        68256 | consumed tokens:    279576576 | elapsed time per iteration (ms): 6758.5 | learning rate: 1.280E-04 | global batch size:    32 | lm loss: 1.111320E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2134/  500000 | consumed samples:        68288 | consumed tokens:    279707648 | elapsed time per iteration (ms): 6759.4 | learning rate: 1.280E-04 | global batch size:    32 | lm loss: 1.128778E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2135/  500000 | consumed samples:        68320 | consumed tokens:    279838720 | elapsed time per iteration (ms): 6765.5 | learning rate: 1.281E-04 | global batch size:    32 | lm loss: 1.072976E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration     2136/  500000 | consumed samples:        68352 | consumed tokens:    279969792 | elapsed time per iteration (ms): 6761.0 | learning rate: 1.282E-04 | global batch size:    32 | lm loss: 1.121272E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2137/  500000 | consumed samples:        68384 | consumed tokens:    280100864 | elapsed time per iteration (ms): 6758.1 | learning rate: 1.282E-04 | global batch size:    32 | lm loss: 1.054441E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2138/  500000 | consumed samples:        68416 | consumed tokens:    280231936 | elapsed time per iteration (ms): 6758.8 | learning rate: 1.283E-04 | global batch size:    32 | lm loss: 1.099278E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2139/  500000 | consumed samples:        68448 | consumed tokens:    280363008 | elapsed time per iteration (ms): 6762.3 | learning rate: 1.283E-04 | global batch size:    32 | lm loss: 1.079748E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
[2023-10-10 19:11:38,300] [INFO] [logging.py:96:log_dist] [Rank 0] step=2140, skipped=0, lr=[0.00012839999999999998], mom=[(0.9, 0.95)]
[2023-10-10 19:11:38,559] [INFO] [timer.py:208:stop] epoch=0/micro_step=2140/global_step=2140, RunningAvgSamplesPerSec=4.742827827399286, CurrSamplesPerSec=4.741953046450799, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2140/  500000 | consumed samples:        68480 | consumed tokens:    280494080 | elapsed time per iteration (ms): 6761.1 | learning rate: 1.284E-04 | global batch size:    32 | lm loss: 1.099400E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2141/  500000 | consumed samples:        68512 | consumed tokens:    280625152 | elapsed time per iteration (ms): 6759.7 | learning rate: 1.285E-04 | global batch size:    32 | lm loss: 1.074410E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2142/  500000 | consumed samples:        68544 | consumed tokens:    280756224 | elapsed time per iteration (ms): 6763.5 | learning rate: 1.285E-04 | global batch size:    32 | lm loss: 1.123982E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     2143/  500000 | consumed samples:        68576 | consumed tokens:    280887296 | elapsed time per iteration (ms): 6762.0 | learning rate: 1.286E-04 | global batch size:    32 | lm loss: 1.122470E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     2144/  500000 | consumed samples:        68608 | consumed tokens:    281018368 | elapsed time per iteration (ms): 6758.4 | learning rate: 1.286E-04 | global batch size:    32 | lm loss: 1.084948E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2145/  500000 | consumed samples:        68640 | consumed tokens:    281149440 | elapsed time per iteration (ms): 6762.1 | learning rate: 1.287E-04 | global batch size:    32 | lm loss: 1.101359E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2146/  500000 | consumed samples:        68672 | consumed tokens:    281280512 | elapsed time per iteration (ms): 6766.3 | learning rate: 1.288E-04 | global batch size:    32 | lm loss: 1.111904E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.50 |
time (ms)
 iteration     2147/  500000 | consumed samples:        68704 | consumed tokens:    281411584 | elapsed time per iteration (ms): 6764.7 | learning rate: 1.288E-04 | global batch size:    32 | lm loss: 1.098592E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration     2148/  500000 | consumed samples:        68736 | consumed tokens:    281542656 | elapsed time per iteration (ms): 6763.1 | learning rate: 1.289E-04 | global batch size:    32 | lm loss: 1.128294E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration     2149/  500000 | consumed samples:        68768 | consumed tokens:    281673728 | elapsed time per iteration (ms): 6759.6 | learning rate: 1.289E-04 | global batch size:    32 | lm loss: 1.132853E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
[2023-10-10 19:12:45,983] [INFO] [logging.py:96:log_dist] [Rank 0] step=2150, skipped=0, lr=[0.000129], mom=[(0.9, 0.95)]
[2023-10-10 19:12:46,220] [INFO] [timer.py:208:stop] epoch=0/micro_step=2150/global_step=2150, RunningAvgSamplesPerSec=4.742821655730226, CurrSamplesPerSec=4.743631164452516, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2150/  500000 | consumed samples:        68800 | consumed tokens:    281804800 | elapsed time per iteration (ms): 6758.6 | learning rate: 1.290E-04 | global batch size:    32 | lm loss: 1.121161E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2151/  500000 | consumed samples:        68832 | consumed tokens:    281935872 | elapsed time per iteration (ms): 6765.0 | learning rate: 1.291E-04 | global batch size:    32 | lm loss: 1.127507E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration     2152/  500000 | consumed samples:        68864 | consumed tokens:    282066944 | elapsed time per iteration (ms): 6761.0 | learning rate: 1.291E-04 | global batch size:    32 | lm loss: 1.121036E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2153/  500000 | consumed samples:        68896 | consumed tokens:    282198016 | elapsed time per iteration (ms): 6760.9 | learning rate: 1.292E-04 | global batch size:    32 | lm loss: 1.106058E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2154/  500000 | consumed samples:        68928 | consumed tokens:    282329088 | elapsed time per iteration (ms): 6759.0 | learning rate: 1.292E-04 | global batch size:    32 | lm loss: 1.105636E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2155/  500000 | consumed samples:        68960 | consumed tokens:    282460160 | elapsed time per iteration (ms): 6760.9 | learning rate: 1.293E-04 | global batch size:    32 | lm loss: 1.091039E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2156/  500000 | consumed samples:        68992 | consumed tokens:    282591232 | elapsed time per iteration (ms): 6770.8 | learning rate: 1.294E-04 | global batch size:    32 | lm loss: 1.120404E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.726 | TFLOPs: 147.40 |
time (ms)
 iteration     2157/  500000 | consumed samples:        69024 | consumed tokens:    282722304 | elapsed time per iteration (ms): 6766.0 | learning rate: 1.294E-04 | global batch size:    32 | lm loss: 1.087452E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.51 |
time (ms)
 iteration     2158/  500000 | consumed samples:        69056 | consumed tokens:    282853376 | elapsed time per iteration (ms): 6760.2 | learning rate: 1.295E-04 | global batch size:    32 | lm loss: 1.096839E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2159/  500000 | consumed samples:        69088 | consumed tokens:    282984448 | elapsed time per iteration (ms): 6761.5 | learning rate: 1.295E-04 | global batch size:    32 | lm loss: 1.114031E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
[2023-10-10 19:13:53,631] [INFO] [logging.py:96:log_dist] [Rank 0] step=2160, skipped=0, lr=[0.00012959999999999998], mom=[(0.9, 0.95)]
[2023-10-10 19:13:53,887] [INFO] [timer.py:208:stop] epoch=0/micro_step=2160/global_step=2160, RunningAvgSamplesPerSec=4.742813677532056, CurrSamplesPerSec=4.743039757572922, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2160/  500000 | consumed samples:        69120 | consumed tokens:    283115520 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.296E-04 | global batch size:    32 | lm loss: 1.113150E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2161/  500000 | consumed samples:        69152 | consumed tokens:    283246592 | elapsed time per iteration (ms): 6759.0 | learning rate: 1.297E-04 | global batch size:    32 | lm loss: 1.122014E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2162/  500000 | consumed samples:        69184 | consumed tokens:    283377664 | elapsed time per iteration (ms): 6761.2 | learning rate: 1.297E-04 | global batch size:    32 | lm loss: 1.098195E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2163/  500000 | consumed samples:        69216 | consumed tokens:    283508736 | elapsed time per iteration (ms): 6757.7 | learning rate: 1.298E-04 | global batch size:    32 | lm loss: 1.119704E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     2164/  500000 | consumed samples:        69248 | consumed tokens:    283639808 | elapsed time per iteration (ms): 6761.5 | learning rate: 1.298E-04 | global batch size:    32 | lm loss: 1.104238E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2165/  500000 | consumed samples:        69280 | consumed tokens:    283770880 | elapsed time per iteration (ms): 6762.4 | learning rate: 1.299E-04 | global batch size:    32 | lm loss: 1.113544E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2166/  500000 | consumed samples:        69312 | consumed tokens:    283901952 | elapsed time per iteration (ms): 6765.4 | learning rate: 1.300E-04 | global batch size:    32 | lm loss: 1.082919E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration     2167/  500000 | consumed samples:        69344 | consumed tokens:    284033024 | elapsed time per iteration (ms): 6765.2 | learning rate: 1.300E-04 | global batch size:    32 | lm loss: 1.100710E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration     2168/  500000 | consumed samples:        69376 | consumed tokens:    284164096 | elapsed time per iteration (ms): 6764.5 | learning rate: 1.301E-04 | global batch size:    32 | lm loss: 1.113970E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.54 |
time (ms)
 iteration     2169/  500000 | consumed samples:        69408 | consumed tokens:    284295168 | elapsed time per iteration (ms): 6763.0 | learning rate: 1.301E-04 | global batch size:    32 | lm loss: 1.098987E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
[2023-10-10 19:15:01,288] [INFO] [logging.py:96:log_dist] [Rank 0] step=2170, skipped=0, lr=[0.0001302], mom=[(0.9, 0.95)]
[2023-10-10 19:15:01,552] [INFO] [timer.py:208:stop] epoch=0/micro_step=2170/global_step=2170, RunningAvgSamplesPerSec=4.7428065656345035, CurrSamplesPerSec=4.740816261437518, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2170/  500000 | consumed samples:        69440 | consumed tokens:    284426240 | elapsed time per iteration (ms): 6762.8 | learning rate: 1.302E-04 | global batch size:    32 | lm loss: 1.080067E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     2171/  500000 | consumed samples:        69472 | consumed tokens:    284557312 | elapsed time per iteration (ms): 6764.1 | learning rate: 1.303E-04 | global batch size:    32 | lm loss: 1.117704E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     2172/  500000 | consumed samples:        69504 | consumed tokens:    284688384 | elapsed time per iteration (ms): 6759.2 | learning rate: 1.303E-04 | global batch size:    32 | lm loss: 1.093013E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2173/  500000 | consumed samples:        69536 | consumed tokens:    284819456 | elapsed time per iteration (ms): 6761.0 | learning rate: 1.304E-04 | global batch size:    32 | lm loss: 1.096814E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2174/  500000 | consumed samples:        69568 | consumed tokens:    284950528 | elapsed time per iteration (ms): 6760.1 | learning rate: 1.304E-04 | global batch size:    32 | lm loss: 1.115790E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2175/  500000 | consumed samples:        69600 | consumed tokens:    285081600 | elapsed time per iteration (ms): 6760.3 | learning rate: 1.305E-04 | global batch size:    32 | lm loss: 1.082259E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration     2176/  500000 | consumed samples:        69632 | consumed tokens:    285212672 | elapsed time per iteration (ms): 6760.1 | learning rate: 1.306E-04 | global batch size:    32 | lm loss: 1.109089E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2177/  500000 | consumed samples:        69664 | consumed tokens:    285343744 | elapsed time per iteration (ms): 6760.8 | learning rate: 1.306E-04 | global batch size:    32 | lm loss: 1.133005E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2178/  500000 | consumed samples:        69696 | consumed tokens:    285474816 | elapsed time per iteration (ms): 6760.2 | learning rate: 1.307E-04 | global batch size:    32 | lm loss: 1.111102E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2179/  500000 | consumed samples:        69728 | consumed tokens:    285605888 | elapsed time per iteration (ms): 6761.9 | learning rate: 1.307E-04 | global batch size:    32 | lm loss: 1.120915E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
[2023-10-10 19:16:08,952] [INFO] [logging.py:96:log_dist] [Rank 0] step=2180, skipped=0, lr=[0.00013079999999999998], mom=[(0.9, 0.95)]
[2023-10-10 19:16:09,203] [INFO] [timer.py:208:stop] epoch=0/micro_step=2180/global_step=2180, RunningAvgSamplesPerSec=4.742804985897514, CurrSamplesPerSec=4.74446924337443, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2180/  500000 | consumed samples:        69760 | consumed tokens:    285736960 | elapsed time per iteration (ms): 6758.3 | learning rate: 1.308E-04 | global batch size:    32 | lm loss: 1.077335E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2181/  500000 | consumed samples:        69792 | consumed tokens:    285868032 | elapsed time per iteration (ms): 6762.2 | learning rate: 1.309E-04 | global batch size:    32 | lm loss: 1.083285E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2182/  500000 | consumed samples:        69824 | consumed tokens:    285999104 | elapsed time per iteration (ms): 6762.5 | learning rate: 1.309E-04 | global batch size:    32 | lm loss: 1.068663E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     2183/  500000 | consumed samples:        69856 | consumed tokens:    286130176 | elapsed time per iteration (ms): 6761.0 | learning rate: 1.310E-04 | global batch size:    32 | lm loss: 1.092156E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2184/  500000 | consumed samples:        69888 | consumed tokens:    286261248 | elapsed time per iteration (ms): 6760.2 | learning rate: 1.310E-04 | global batch size:    32 | lm loss: 1.069910E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2185/  500000 | consumed samples:        69920 | consumed tokens:    286392320 | elapsed time per iteration (ms): 6762.3 | learning rate: 1.311E-04 | global batch size:    32 | lm loss: 1.093303E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2186/  500000 | consumed samples:        69952 | consumed tokens:    286523392 | elapsed time per iteration (ms): 6760.9 | learning rate: 1.312E-04 | global batch size:    32 | lm loss: 1.116583E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2187/  500000 | consumed samples:        69984 | consumed tokens:    286654464 | elapsed time per iteration (ms): 6761.7 | learning rate: 1.312E-04 | global batch size:    32 | lm loss: 1.087981E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     2188/  500000 | consumed samples:        70016 | consumed tokens:    286785536 | elapsed time per iteration (ms): 6759.8 | learning rate: 1.313E-04 | global batch size:    32 | lm loss: 1.117400E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2189/  500000 | consumed samples:        70048 | consumed tokens:    286916608 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.313E-04 | global batch size:    32 | lm loss: 1.074167E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
[2023-10-10 19:17:16,599] [INFO] [logging.py:96:log_dist] [Rank 0] step=2190, skipped=0, lr=[0.0001314], mom=[(0.9, 0.95)]
[2023-10-10 19:17:16,857] [INFO] [timer.py:208:stop] epoch=0/micro_step=2190/global_step=2190, RunningAvgSamplesPerSec=4.742802180033205, CurrSamplesPerSec=4.7435079425239115, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2190/  500000 | consumed samples:        70080 | consumed tokens:    287047680 | elapsed time per iteration (ms): 6758.7 | learning rate: 1.314E-04 | global batch size:    32 | lm loss: 1.104437E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2191/  500000 | consumed samples:        70112 | consumed tokens:    287178752 | elapsed time per iteration (ms): 6764.5 | learning rate: 1.315E-04 | global batch size:    32 | lm loss: 1.092334E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.54 |
time (ms)
 iteration     2192/  500000 | consumed samples:        70144 | consumed tokens:    287309824 | elapsed time per iteration (ms): 6758.6 | learning rate: 1.315E-04 | global batch size:    32 | lm loss: 1.118109E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2193/  500000 | consumed samples:        70176 | consumed tokens:    287440896 | elapsed time per iteration (ms): 6757.1 | learning rate: 1.316E-04 | global batch size:    32 | lm loss: 1.097305E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     2194/  500000 | consumed samples:        70208 | consumed tokens:    287571968 | elapsed time per iteration (ms): 6758.5 | learning rate: 1.316E-04 | global batch size:    32 | lm loss: 1.081729E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2195/  500000 | consumed samples:        70240 | consumed tokens:    287703040 | elapsed time per iteration (ms): 6758.7 | learning rate: 1.317E-04 | global batch size:    32 | lm loss: 1.089489E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2196/  500000 | consumed samples:        70272 | consumed tokens:    287834112 | elapsed time per iteration (ms): 6763.6 | learning rate: 1.318E-04 | global batch size:    32 | lm loss: 1.073261E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     2197/  500000 | consumed samples:        70304 | consumed tokens:    287965184 | elapsed time per iteration (ms): 6759.6 | learning rate: 1.318E-04 | global batch size:    32 | lm loss: 1.106947E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2198/  500000 | consumed samples:        70336 | consumed tokens:    288096256 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.319E-04 | global batch size:    32 | lm loss: 1.123754E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2199/  500000 | consumed samples:        70368 | consumed tokens:    288227328 | elapsed time per iteration (ms): 6758.7 | learning rate: 1.319E-04 | global batch size:    32 | lm loss: 1.096223E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
[2023-10-10 19:18:24,241] [INFO] [logging.py:96:log_dist] [Rank 0] step=2200, skipped=0, lr=[0.00013199999999999998], mom=[(0.9, 0.95)]
[2023-10-10 19:18:24,498] [INFO] [timer.py:208:stop] epoch=0/micro_step=2200/global_step=2200, RunningAvgSamplesPerSec=4.742803040805996, CurrSamplesPerSec=4.743810560200777, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2200/  500000 | consumed samples:        70400 | consumed tokens:    288358400 | elapsed time per iteration (ms): 6758.5 | learning rate: 1.320E-04 | global batch size:    32 | lm loss: 1.087868E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2201/  500000 | consumed samples:        70432 | consumed tokens:    288489472 | elapsed time per iteration (ms): 6761.8 | learning rate: 1.321E-04 | global batch size:    32 | lm loss: 1.116832E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     2202/  500000 | consumed samples:        70464 | consumed tokens:    288620544 | elapsed time per iteration (ms): 6760.0 | learning rate: 1.321E-04 | global batch size:    32 | lm loss: 1.106821E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2203/  500000 | consumed samples:        70496 | consumed tokens:    288751616 | elapsed time per iteration (ms): 6761.6 | learning rate: 1.322E-04 | global batch size:    32 | lm loss: 1.116889E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2204/  500000 | consumed samples:        70528 | consumed tokens:    288882688 | elapsed time per iteration (ms): 6764.6 | learning rate: 1.322E-04 | global batch size:    32 | lm loss: 1.105963E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration     2205/  500000 | consumed samples:        70560 | consumed tokens:    289013760 | elapsed time per iteration (ms): 6759.7 | learning rate: 1.323E-04 | global batch size:    32 | lm loss: 1.082146E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2206/  500000 | consumed samples:        70592 | consumed tokens:    289144832 | elapsed time per iteration (ms): 6760.6 | learning rate: 1.324E-04 | global batch size:    32 | lm loss: 1.108364E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2207/  500000 | consumed samples:        70624 | consumed tokens:    289275904 | elapsed time per iteration (ms): 6762.5 | learning rate: 1.324E-04 | global batch size:    32 | lm loss: 1.126284E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2208/  500000 | consumed samples:        70656 | consumed tokens:    289406976 | elapsed time per iteration (ms): 6757.9 | learning rate: 1.325E-04 | global batch size:    32 | lm loss: 1.104518E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     2209/  500000 | consumed samples:        70688 | consumed tokens:    289538048 | elapsed time per iteration (ms): 6762.6 | learning rate: 1.325E-04 | global batch size:    32 | lm loss: 1.107346E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
[2023-10-10 19:19:31,897] [INFO] [logging.py:96:log_dist] [Rank 0] step=2210, skipped=0, lr=[0.0001326], mom=[(0.9, 0.95)]
[2023-10-10 19:19:32,159] [INFO] [timer.py:208:stop] epoch=0/micro_step=2210/global_step=2210, RunningAvgSamplesPerSec=4.74279809499523, CurrSamplesPerSec=4.738677662712712, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2210/  500000 | consumed samples:        70720 | consumed tokens:    289669120 | elapsed time per iteration (ms): 6766.0 | learning rate: 1.326E-04 | global batch size:    32 | lm loss: 1.118857E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.51 |
time (ms)
 iteration     2211/  500000 | consumed samples:        70752 | consumed tokens:    289800192 | elapsed time per iteration (ms): 6763.5 | learning rate: 1.327E-04 | global batch size:    32 | lm loss: 1.064184E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     2212/  500000 | consumed samples:        70784 | consumed tokens:    289931264 | elapsed time per iteration (ms): 6759.1 | learning rate: 1.327E-04 | global batch size:    32 | lm loss: 1.082673E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2213/  500000 | consumed samples:        70816 | consumed tokens:    290062336 | elapsed time per iteration (ms): 6758.0 | learning rate: 1.328E-04 | global batch size:    32 | lm loss: 1.075088E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2214/  500000 | consumed samples:        70848 | consumed tokens:    290193408 | elapsed time per iteration (ms): 6760.7 | learning rate: 1.328E-04 | global batch size:    32 | lm loss: 1.100554E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2215/  500000 | consumed samples:        70880 | consumed tokens:    290324480 | elapsed time per iteration (ms): 6758.4 | learning rate: 1.329E-04 | global batch size:    32 | lm loss: 1.082255E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2216/  500000 | consumed samples:        70912 | consumed tokens:    290455552 | elapsed time per iteration (ms): 6757.7 | learning rate: 1.330E-04 | global batch size:    32 | lm loss: 1.116398E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     2217/  500000 | consumed samples:        70944 | consumed tokens:    290586624 | elapsed time per iteration (ms): 6758.2 | learning rate: 1.330E-04 | global batch size:    32 | lm loss: 1.098021E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2218/  500000 | consumed samples:        70976 | consumed tokens:    290717696 | elapsed time per iteration (ms): 6758.9 | learning rate: 1.331E-04 | global batch size:    32 | lm loss: 1.124606E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2219/  500000 | consumed samples:        71008 | consumed tokens:    290848768 | elapsed time per iteration (ms): 6759.7 | learning rate: 1.331E-04 | global batch size:    32 | lm loss: 1.083694E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
[2023-10-10 19:20:39,547] [INFO] [logging.py:96:log_dist] [Rank 0] step=2220, skipped=0, lr=[0.00013319999999999999], mom=[(0.9, 0.95)]
[2023-10-10 19:20:39,798] [INFO] [timer.py:208:stop] epoch=0/micro_step=2220/global_step=2220, RunningAvgSamplesPerSec=4.742799173157555, CurrSamplesPerSec=4.741898095725783, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2220/  500000 | consumed samples:        71040 | consumed tokens:    290979840 | elapsed time per iteration (ms): 6760.8 | learning rate: 1.332E-04 | global batch size:    32 | lm loss: 1.105254E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2221/  500000 | consumed samples:        71072 | consumed tokens:    291110912 | elapsed time per iteration (ms): 6760.2 | learning rate: 1.333E-04 | global batch size:    32 | lm loss: 1.107970E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2222/  500000 | consumed samples:        71104 | consumed tokens:    291241984 | elapsed time per iteration (ms): 6756.3 | learning rate: 1.333E-04 | global batch size:    32 | lm loss: 1.112771E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     2223/  500000 | consumed samples:        71136 | consumed tokens:    291373056 | elapsed time per iteration (ms): 6762.0 | learning rate: 1.334E-04 | global batch size:    32 | lm loss: 1.108014E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     2224/  500000 | consumed samples:        71168 | consumed tokens:    291504128 | elapsed time per iteration (ms): 6775.0 | learning rate: 1.334E-04 | global batch size:    32 | lm loss: 1.077221E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.723 | TFLOPs: 147.31 |
time (ms)
 iteration     2225/  500000 | consumed samples:        71200 | consumed tokens:    291635200 | elapsed time per iteration (ms): 6760.9 | learning rate: 1.335E-04 | global batch size:    32 | lm loss: 1.075714E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2226/  500000 | consumed samples:        71232 | consumed tokens:    291766272 | elapsed time per iteration (ms): 6761.1 | learning rate: 1.336E-04 | global batch size:    32 | lm loss: 1.097502E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2227/  500000 | consumed samples:        71264 | consumed tokens:    291897344 | elapsed time per iteration (ms): 6761.8 | learning rate: 1.336E-04 | global batch size:    32 | lm loss: 1.058212E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     2228/  500000 | consumed samples:        71296 | consumed tokens:    292028416 | elapsed time per iteration (ms): 6759.0 | learning rate: 1.337E-04 | global batch size:    32 | lm loss: 1.105126E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2229/  500000 | consumed samples:        71328 | consumed tokens:    292159488 | elapsed time per iteration (ms): 6758.3 | learning rate: 1.337E-04 | global batch size:    32 | lm loss: 1.044884E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
[2023-10-10 19:21:47,207] [INFO] [logging.py:96:log_dist] [Rank 0] step=2230, skipped=0, lr=[0.00013379999999999997], mom=[(0.9, 0.95)]
[2023-10-10 19:21:47,456] [INFO] [timer.py:208:stop] epoch=0/micro_step=2230/global_step=2230, RunningAvgSamplesPerSec=4.742794414430296, CurrSamplesPerSec=4.742864274892049, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2230/  500000 | consumed samples:        71360 | consumed tokens:    292290560 | elapsed time per iteration (ms): 6760.9 | learning rate: 1.338E-04 | global batch size:    32 | lm loss: 1.104639E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2231/  500000 | consumed samples:        71392 | consumed tokens:    292421632 | elapsed time per iteration (ms): 6757.8 | learning rate: 1.339E-04 | global batch size:    32 | lm loss: 1.124101E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     2232/  500000 | consumed samples:        71424 | consumed tokens:    292552704 | elapsed time per iteration (ms): 6757.7 | learning rate: 1.339E-04 | global batch size:    32 | lm loss: 1.070397E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     2233/  500000 | consumed samples:        71456 | consumed tokens:    292683776 | elapsed time per iteration (ms): 6756.2 | learning rate: 1.340E-04 | global batch size:    32 | lm loss: 1.126280E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     2234/  500000 | consumed samples:        71488 | consumed tokens:    292814848 | elapsed time per iteration (ms): 6758.4 | learning rate: 1.340E-04 | global batch size:    32 | lm loss: 1.083671E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2235/  500000 | consumed samples:        71520 | consumed tokens:    292945920 | elapsed time per iteration (ms): 6760.7 | learning rate: 1.341E-04 | global batch size:    32 | lm loss: 1.097947E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2236/  500000 | consumed samples:        71552 | consumed tokens:    293076992 | elapsed time per iteration (ms): 6757.9 | learning rate: 1.342E-04 | global batch size:    32 | lm loss: 1.081178E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     2237/  500000 | consumed samples:        71584 | consumed tokens:    293208064 | elapsed time per iteration (ms): 6758.1 | learning rate: 1.342E-04 | global batch size:    32 | lm loss: 1.090351E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2238/  500000 | consumed samples:        71616 | consumed tokens:    293339136 | elapsed time per iteration (ms): 6759.1 | learning rate: 1.343E-04 | global batch size:    32 | lm loss: 1.106663E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2239/  500000 | consumed samples:        71648 | consumed tokens:    293470208 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.343E-04 | global batch size:    32 | lm loss: 1.082026E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
[2023-10-10 19:22:54,836] [INFO] [logging.py:96:log_dist] [Rank 0] step=2240, skipped=0, lr=[0.0001344], mom=[(0.9, 0.95)]
[2023-10-10 19:22:55,082] [INFO] [timer.py:208:stop] epoch=0/micro_step=2240/global_step=2240, RunningAvgSamplesPerSec=4.742798958673746, CurrSamplesPerSec=4.744682247790082, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2240/  500000 | consumed samples:        71680 | consumed tokens:    293601280 | elapsed time per iteration (ms): 6756.1 | learning rate: 1.344E-04 | global batch size:    32 | lm loss: 1.110027E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     2241/  500000 | consumed samples:        71712 | consumed tokens:    293732352 | elapsed time per iteration (ms): 6764.7 | learning rate: 1.345E-04 | global batch size:    32 | lm loss: 1.079521E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration     2242/  500000 | consumed samples:        71744 | consumed tokens:    293863424 | elapsed time per iteration (ms): 6759.2 | learning rate: 1.345E-04 | global batch size:    32 | lm loss: 1.109792E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2243/  500000 | consumed samples:        71776 | consumed tokens:    293994496 | elapsed time per iteration (ms): 6756.3 | learning rate: 1.346E-04 | global batch size:    32 | lm loss: 1.103781E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     2244/  500000 | consumed samples:        71808 | consumed tokens:    294125568 | elapsed time per iteration (ms): 6758.7 | learning rate: 1.346E-04 | global batch size:    32 | lm loss: 1.118017E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2245/  500000 | consumed samples:        71840 | consumed tokens:    294256640 | elapsed time per iteration (ms): 6758.8 | learning rate: 1.347E-04 | global batch size:    32 | lm loss: 1.066921E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2246/  500000 | consumed samples:        71872 | consumed tokens:    294387712 | elapsed time per iteration (ms): 6758.9 | learning rate: 1.348E-04 | global batch size:    32 | lm loss: 1.089031E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2247/  500000 | consumed samples:        71904 | consumed tokens:    294518784 | elapsed time per iteration (ms): 6766.7 | learning rate: 1.348E-04 | global batch size:    32 | lm loss: 1.081794E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.49 |
time (ms)
 iteration     2248/  500000 | consumed samples:        71936 | consumed tokens:    294649856 | elapsed time per iteration (ms): 6763.3 | learning rate: 1.349E-04 | global batch size:    32 | lm loss: 1.117183E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration     2249/  500000 | consumed samples:        71968 | consumed tokens:    294780928 | elapsed time per iteration (ms): 6761.9 | learning rate: 1.349E-04 | global batch size:    32 | lm loss: 1.114901E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
[2023-10-10 19:24:02,492] [INFO] [logging.py:96:log_dist] [Rank 0] step=2250, skipped=0, lr=[0.00013499999999999997], mom=[(0.9, 0.95)]
[2023-10-10 19:24:02,739] [INFO] [timer.py:208:stop] epoch=0/micro_step=2250/global_step=2250, RunningAvgSamplesPerSec=4.742794677283272, CurrSamplesPerSec=4.737982619548629, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2250/  500000 | consumed samples:        72000 | consumed tokens:    294912000 | elapsed time per iteration (ms): 6766.4 | learning rate: 1.350E-04 | global batch size:    32 | lm loss: 1.076401E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.50 |
time (ms)
 iteration     2251/  500000 | consumed samples:        72032 | consumed tokens:    295043072 | elapsed time per iteration (ms): 6763.5 | learning rate: 1.351E-04 | global batch size:    32 | lm loss: 1.115855E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     2252/  500000 | consumed samples:        72064 | consumed tokens:    295174144 | elapsed time per iteration (ms): 6764.0 | learning rate: 1.351E-04 | global batch size:    32 | lm loss: 1.100085E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     2253/  500000 | consumed samples:        72096 | consumed tokens:    295305216 | elapsed time per iteration (ms): 6758.4 | learning rate: 1.352E-04 | global batch size:    32 | lm loss: 1.084110E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2254/  500000 | consumed samples:        72128 | consumed tokens:    295436288 | elapsed time per iteration (ms): 6759.0 | learning rate: 1.352E-04 | global batch size:    32 | lm loss: 1.078160E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2255/  500000 | consumed samples:        72160 | consumed tokens:    295567360 | elapsed time per iteration (ms): 6759.0 | learning rate: 1.353E-04 | global batch size:    32 | lm loss: 1.071908E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2256/  500000 | consumed samples:        72192 | consumed tokens:    295698432 | elapsed time per iteration (ms): 6763.1 | learning rate: 1.354E-04 | global batch size:    32 | lm loss: 1.099006E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration     2257/  500000 | consumed samples:        72224 | consumed tokens:    295829504 | elapsed time per iteration (ms): 6762.8 | learning rate: 1.354E-04 | global batch size:    32 | lm loss: 1.098558E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     2258/  500000 | consumed samples:        72256 | consumed tokens:    295960576 | elapsed time per iteration (ms): 6761.0 | learning rate: 1.355E-04 | global batch size:    32 | lm loss: 1.115306E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2259/  500000 | consumed samples:        72288 | consumed tokens:    296091648 | elapsed time per iteration (ms): 6760.1 | learning rate: 1.355E-04 | global batch size:    32 | lm loss: 1.097880E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
[2023-10-10 19:25:10,136] [INFO] [logging.py:96:log_dist] [Rank 0] step=2260, skipped=0, lr=[0.0001356], mom=[(0.9, 0.95)]
[2023-10-10 19:25:10,398] [INFO] [timer.py:208:stop] epoch=0/micro_step=2260/global_step=2260, RunningAvgSamplesPerSec=4.742790406731278, CurrSamplesPerSec=4.7394421947230425, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2260/  500000 | consumed samples:        72320 | consumed tokens:    296222720 | elapsed time per iteration (ms): 6764.6 | learning rate: 1.356E-04 | global batch size:    32 | lm loss: 1.088287E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration     2261/  500000 | consumed samples:        72352 | consumed tokens:    296353792 | elapsed time per iteration (ms): 6761.7 | learning rate: 1.357E-04 | global batch size:    32 | lm loss: 1.083261E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     2262/  500000 | consumed samples:        72384 | consumed tokens:    296484864 | elapsed time per iteration (ms): 6762.6 | learning rate: 1.357E-04 | global batch size:    32 | lm loss: 1.118324E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     2263/  500000 | consumed samples:        72416 | consumed tokens:    296615936 | elapsed time per iteration (ms): 6759.5 | learning rate: 1.358E-04 | global batch size:    32 | lm loss: 1.068980E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2264/  500000 | consumed samples:        72448 | consumed tokens:    296747008 | elapsed time per iteration (ms): 6762.1 | learning rate: 1.358E-04 | global batch size:    32 | lm loss: 1.090555E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2265/  500000 | consumed samples:        72480 | consumed tokens:    296878080 | elapsed time per iteration (ms): 6761.3 | learning rate: 1.359E-04 | global batch size:    32 | lm loss: 1.087401E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2266/  500000 | consumed samples:        72512 | consumed tokens:    297009152 | elapsed time per iteration (ms): 6765.2 | learning rate: 1.360E-04 | global batch size:    32 | lm loss: 1.081917E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration     2267/  500000 | consumed samples:        72544 | consumed tokens:    297140224 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.360E-04 | global batch size:    32 | lm loss: 1.070546E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2268/  500000 | consumed samples:        72576 | consumed tokens:    297271296 | elapsed time per iteration (ms): 6756.5 | learning rate: 1.361E-04 | global batch size:    32 | lm loss: 1.087782E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     2269/  500000 | consumed samples:        72608 | consumed tokens:    297402368 | elapsed time per iteration (ms): 6760.1 | learning rate: 1.361E-04 | global batch size:    32 | lm loss: 1.115932E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
[2023-10-10 19:26:17,794] [INFO] [logging.py:96:log_dist] [Rank 0] step=2270, skipped=0, lr=[0.00013619999999999998], mom=[(0.9, 0.95)]
[2023-10-10 19:26:18,049] [INFO] [timer.py:208:stop] epoch=0/micro_step=2270/global_step=2270, RunningAvgSamplesPerSec=4.742790177620069, CurrSamplesPerSec=4.743424624657186, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2270/  500000 | consumed samples:        72640 | consumed tokens:    297533440 | elapsed time per iteration (ms): 6758.7 | learning rate: 1.362E-04 | global batch size:    32 | lm loss: 1.083692E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2271/  500000 | consumed samples:        72672 | consumed tokens:    297664512 | elapsed time per iteration (ms): 6758.8 | learning rate: 1.363E-04 | global batch size:    32 | lm loss: 1.093061E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2272/  500000 | consumed samples:        72704 | consumed tokens:    297795584 | elapsed time per iteration (ms): 6755.7 | learning rate: 1.363E-04 | global batch size:    32 | lm loss: 1.104449E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration     2273/  500000 | consumed samples:        72736 | consumed tokens:    297926656 | elapsed time per iteration (ms): 6763.5 | learning rate: 1.364E-04 | global batch size:    32 | lm loss: 1.092884E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     2274/  500000 | consumed samples:        72768 | consumed tokens:    298057728 | elapsed time per iteration (ms): 6760.6 | learning rate: 1.364E-04 | global batch size:    32 | lm loss: 1.104919E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2275/  500000 | consumed samples:        72800 | consumed tokens:    298188800 | elapsed time per iteration (ms): 6758.7 | learning rate: 1.365E-04 | global batch size:    32 | lm loss: 1.099896E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2276/  500000 | consumed samples:        72832 | consumed tokens:    298319872 | elapsed time per iteration (ms): 6759.8 | learning rate: 1.366E-04 | global batch size:    32 | lm loss: 1.111201E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2277/  500000 | consumed samples:        72864 | consumed tokens:    298450944 | elapsed time per iteration (ms): 6759.8 | learning rate: 1.366E-04 | global batch size:    32 | lm loss: 1.088327E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2278/  500000 | consumed samples:        72896 | consumed tokens:    298582016 | elapsed time per iteration (ms): 6758.7 | learning rate: 1.367E-04 | global batch size:    32 | lm loss: 1.074343E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2279/  500000 | consumed samples:        72928 | consumed tokens:    298713088 | elapsed time per iteration (ms): 6761.3 | learning rate: 1.367E-04 | global batch size:    32 | lm loss: 1.102870E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
[2023-10-10 19:27:25,426] [INFO] [logging.py:96:log_dist] [Rank 0] step=2280, skipped=0, lr=[0.0001368], mom=[(0.9, 0.95)]
[2023-10-10 19:27:25,688] [INFO] [timer.py:208:stop] epoch=0/micro_step=2280/global_step=2280, RunningAvgSamplesPerSec=4.742791332323429, CurrSamplesPerSec=4.742400573705209, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2280/  500000 | consumed samples:        72960 | consumed tokens:    298844160 | elapsed time per iteration (ms): 6761.0 | learning rate: 1.368E-04 | global batch size:    32 | lm loss: 1.092424E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2281/  500000 | consumed samples:        72992 | consumed tokens:    298975232 | elapsed time per iteration (ms): 6761.2 | learning rate: 1.369E-04 | global batch size:    32 | lm loss: 1.063768E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2282/  500000 | consumed samples:        73024 | consumed tokens:    299106304 | elapsed time per iteration (ms): 6761.4 | learning rate: 1.369E-04 | global batch size:    32 | lm loss: 1.106144E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2283/  500000 | consumed samples:        73056 | consumed tokens:    299237376 | elapsed time per iteration (ms): 6763.1 | learning rate: 1.370E-04 | global batch size:    32 | lm loss: 1.085562E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration     2284/  500000 | consumed samples:        73088 | consumed tokens:    299368448 | elapsed time per iteration (ms): 6758.5 | learning rate: 1.370E-04 | global batch size:    32 | lm loss: 1.091553E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2285/  500000 | consumed samples:        73120 | consumed tokens:    299499520 | elapsed time per iteration (ms): 6757.2 | learning rate: 1.371E-04 | global batch size:    32 | lm loss: 1.098399E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     2286/  500000 | consumed samples:        73152 | consumed tokens:    299630592 | elapsed time per iteration (ms): 6763.2 | learning rate: 1.372E-04 | global batch size:    32 | lm loss: 1.065945E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration     2287/  500000 | consumed samples:        73184 | consumed tokens:    299761664 | elapsed time per iteration (ms): 6765.4 | learning rate: 1.372E-04 | global batch size:    32 | lm loss: 1.045526E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration     2288/  500000 | consumed samples:        73216 | consumed tokens:    299892736 | elapsed time per iteration (ms): 6759.1 | learning rate: 1.373E-04 | global batch size:    32 | lm loss: 1.109325E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2289/  500000 | consumed samples:        73248 | consumed tokens:    300023808 | elapsed time per iteration (ms): 6757.7 | learning rate: 1.373E-04 | global batch size:    32 | lm loss: 1.121114E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
[2023-10-10 19:28:33,077] [INFO] [logging.py:96:log_dist] [Rank 0] step=2290, skipped=0, lr=[0.00013739999999999998], mom=[(0.9, 0.95)]
[2023-10-10 19:28:33,336] [INFO] [timer.py:208:stop] epoch=0/micro_step=2290/global_step=2290, RunningAvgSamplesPerSec=4.742790035395765, CurrSamplesPerSec=4.743354217474138, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2290/  500000 | consumed samples:        73280 | consumed tokens:    300154880 | elapsed time per iteration (ms): 6758.9 | learning rate: 1.374E-04 | global batch size:    32 | lm loss: 1.100772E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2291/  500000 | consumed samples:        73312 | consumed tokens:    300285952 | elapsed time per iteration (ms): 6758.4 | learning rate: 1.375E-04 | global batch size:    32 | lm loss: 1.088348E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2292/  500000 | consumed samples:        73344 | consumed tokens:    300417024 | elapsed time per iteration (ms): 6767.7 | learning rate: 1.375E-04 | global batch size:    32 | lm loss: 1.102338E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.728 | TFLOPs: 147.47 |
time (ms)
 iteration     2293/  500000 | consumed samples:        73376 | consumed tokens:    300548096 | elapsed time per iteration (ms): 6760.3 | learning rate: 1.376E-04 | global batch size:    32 | lm loss: 1.087636E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration     2294/  500000 | consumed samples:        73408 | consumed tokens:    300679168 | elapsed time per iteration (ms): 6764.4 | learning rate: 1.376E-04 | global batch size:    32 | lm loss: 1.078615E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.54 |
time (ms)
 iteration     2295/  500000 | consumed samples:        73440 | consumed tokens:    300810240 | elapsed time per iteration (ms): 6764.4 | learning rate: 1.377E-04 | global batch size:    32 | lm loss: 1.069749E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.54 |
time (ms)
 iteration     2296/  500000 | consumed samples:        73472 | consumed tokens:    300941312 | elapsed time per iteration (ms): 6761.3 | learning rate: 1.378E-04 | global batch size:    32 | lm loss: 1.094920E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2297/  500000 | consumed samples:        73504 | consumed tokens:    301072384 | elapsed time per iteration (ms): 6759.7 | learning rate: 1.378E-04 | global batch size:    32 | lm loss: 1.145225E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2298/  500000 | consumed samples:        73536 | consumed tokens:    301203456 | elapsed time per iteration (ms): 6766.4 | learning rate: 1.379E-04 | global batch size:    32 | lm loss: 1.093607E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.50 |
time (ms)
 iteration     2299/  500000 | consumed samples:        73568 | consumed tokens:    301334528 | elapsed time per iteration (ms): 6761.2 | learning rate: 1.379E-04 | global batch size:    32 | lm loss: 1.115150E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
[2023-10-10 19:29:40,758] [INFO] [logging.py:96:log_dist] [Rank 0] step=2300, skipped=0, lr=[0.000138], mom=[(0.9, 0.95)]
[2023-10-10 19:29:41,015] [INFO] [timer.py:208:stop] epoch=0/micro_step=2300/global_step=2300, RunningAvgSamplesPerSec=4.742779255935136, CurrSamplesPerSec=4.734142233295156, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2300/  500000 | consumed samples:        73600 | consumed tokens:    301465600 | elapsed time per iteration (ms): 6772.2 | learning rate: 1.380E-04 | global batch size:    32 | lm loss: 1.075265E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.725 | TFLOPs: 147.37 |
time (ms)
 iteration     2301/  500000 | consumed samples:        73632 | consumed tokens:    301596672 | elapsed time per iteration (ms): 6763.9 | learning rate: 1.381E-04 | global batch size:    32 | lm loss: 1.107638E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     2302/  500000 | consumed samples:        73664 | consumed tokens:    301727744 | elapsed time per iteration (ms): 6759.4 | learning rate: 1.381E-04 | global batch size:    32 | lm loss: 1.098116E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2303/  500000 | consumed samples:        73696 | consumed tokens:    301858816 | elapsed time per iteration (ms): 6760.3 | learning rate: 1.382E-04 | global batch size:    32 | lm loss: 1.093700E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration     2304/  500000 | consumed samples:        73728 | consumed tokens:    301989888 | elapsed time per iteration (ms): 6760.8 | learning rate: 1.382E-04 | global batch size:    32 | lm loss: 1.146740E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2305/  500000 | consumed samples:        73760 | consumed tokens:    302120960 | elapsed time per iteration (ms): 6757.9 | learning rate: 1.383E-04 | global batch size:    32 | lm loss: 1.103351E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     2306/  500000 | consumed samples:        73792 | consumed tokens:    302252032 | elapsed time per iteration (ms): 6758.9 | learning rate: 1.384E-04 | global batch size:    32 | lm loss: 1.086035E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2307/  500000 | consumed samples:        73824 | consumed tokens:    302383104 | elapsed time per iteration (ms): 6761.4 | learning rate: 1.384E-04 | global batch size:    32 | lm loss: 1.100855E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2308/  500000 | consumed samples:        73856 | consumed tokens:    302514176 | elapsed time per iteration (ms): 6756.6 | learning rate: 1.385E-04 | global batch size:    32 | lm loss: 1.092476E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     2309/  500000 | consumed samples:        73888 | consumed tokens:    302645248 | elapsed time per iteration (ms): 6754.0 | learning rate: 1.385E-04 | global batch size:    32 | lm loss: 1.102320E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.738 | TFLOPs: 147.77 |
time (ms)
[2023-10-10 19:30:48,394] [INFO] [logging.py:96:log_dist] [Rank 0] step=2310, skipped=0, lr=[0.00013859999999999998], mom=[(0.9, 0.95)]
[2023-10-10 19:30:48,649] [INFO] [timer.py:208:stop] epoch=0/micro_step=2310/global_step=2310, RunningAvgSamplesPerSec=4.742781543047342, CurrSamplesPerSec=4.744065929140793, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2310/  500000 | consumed samples:        73920 | consumed tokens:    302776320 | elapsed time per iteration (ms): 6757.5 | learning rate: 1.386E-04 | global batch size:    32 | lm loss: 1.076792E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     2311/  500000 | consumed samples:        73952 | consumed tokens:    302907392 | elapsed time per iteration (ms): 6758.2 | learning rate: 1.387E-04 | global batch size:    32 | lm loss: 1.105932E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2312/  500000 | consumed samples:        73984 | consumed tokens:    303038464 | elapsed time per iteration (ms): 6759.0 | learning rate: 1.387E-04 | global batch size:    32 | lm loss: 1.091819E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2313/  500000 | consumed samples:        74016 | consumed tokens:    303169536 | elapsed time per iteration (ms): 6758.0 | learning rate: 1.388E-04 | global batch size:    32 | lm loss: 1.069096E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2314/  500000 | consumed samples:        74048 | consumed tokens:    303300608 | elapsed time per iteration (ms): 6759.9 | learning rate: 1.388E-04 | global batch size:    32 | lm loss: 1.074830E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2315/  500000 | consumed samples:        74080 | consumed tokens:    303431680 | elapsed time per iteration (ms): 6756.9 | learning rate: 1.389E-04 | global batch size:    32 | lm loss: 1.107549E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     2316/  500000 | consumed samples:        74112 | consumed tokens:    303562752 | elapsed time per iteration (ms): 6755.5 | learning rate: 1.390E-04 | global batch size:    32 | lm loss: 1.099856E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration     2317/  500000 | consumed samples:        74144 | consumed tokens:    303693824 | elapsed time per iteration (ms): 6760.5 | learning rate: 1.390E-04 | global batch size:    32 | lm loss: 1.108398E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2318/  500000 | consumed samples:        74176 | consumed tokens:    303824896 | elapsed time per iteration (ms): 6755.3 | learning rate: 1.391E-04 | global batch size:    32 | lm loss: 1.080476E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration     2319/  500000 | consumed samples:        74208 | consumed tokens:    303955968 | elapsed time per iteration (ms): 6755.9 | learning rate: 1.391E-04 | global batch size:    32 | lm loss: 1.072111E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
[2023-10-10 19:31:56,022] [INFO] [logging.py:96:log_dist] [Rank 0] step=2320, skipped=0, lr=[0.0001392], mom=[(0.9, 0.95)]
[2023-10-10 19:31:56,271] [INFO] [timer.py:208:stop] epoch=0/micro_step=2320/global_step=2320, RunningAvgSamplesPerSec=4.742787833901087, CurrSamplesPerSec=4.742233348470908, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2320/  500000 | consumed samples:        74240 | consumed tokens:    304087040 | elapsed time per iteration (ms): 6761.2 | learning rate: 1.392E-04 | global batch size:    32 | lm loss: 1.105125E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2321/  500000 | consumed samples:        74272 | consumed tokens:    304218112 | elapsed time per iteration (ms): 6763.6 | learning rate: 1.393E-04 | global batch size:    32 | lm loss: 1.118876E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     2322/  500000 | consumed samples:        74304 | consumed tokens:    304349184 | elapsed time per iteration (ms): 6762.9 | learning rate: 1.393E-04 | global batch size:    32 | lm loss: 1.061537E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     2323/  500000 | consumed samples:        74336 | consumed tokens:    304480256 | elapsed time per iteration (ms): 6759.1 | learning rate: 1.394E-04 | global batch size:    32 | lm loss: 1.093079E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2324/  500000 | consumed samples:        74368 | consumed tokens:    304611328 | elapsed time per iteration (ms): 6760.7 | learning rate: 1.394E-04 | global batch size:    32 | lm loss: 1.068380E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2325/  500000 | consumed samples:        74400 | consumed tokens:    304742400 | elapsed time per iteration (ms): 6760.3 | learning rate: 1.395E-04 | global batch size:    32 | lm loss: 1.072950E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration     2326/  500000 | consumed samples:        74432 | consumed tokens:    304873472 | elapsed time per iteration (ms): 6757.7 | learning rate: 1.396E-04 | global batch size:    32 | lm loss: 1.077539E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     2327/  500000 | consumed samples:        74464 | consumed tokens:    305004544 | elapsed time per iteration (ms): 6760.2 | learning rate: 1.396E-04 | global batch size:    32 | lm loss: 1.086281E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2328/  500000 | consumed samples:        74496 | consumed tokens:    305135616 | elapsed time per iteration (ms): 6760.7 | learning rate: 1.397E-04 | global batch size:    32 | lm loss: 1.108670E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2329/  500000 | consumed samples:        74528 | consumed tokens:    305266688 | elapsed time per iteration (ms): 6760.7 | learning rate: 1.397E-04 | global batch size:    32 | lm loss: 1.112865E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
[2023-10-10 19:33:03,659] [INFO] [logging.py:96:log_dist] [Rank 0] step=2330, skipped=0, lr=[0.00013979999999999998], mom=[(0.9, 0.95)]
[2023-10-10 19:33:03,918] [INFO] [timer.py:208:stop] epoch=0/micro_step=2330/global_step=2330, RunningAvgSamplesPerSec=4.742786167901337, CurrSamplesPerSec=4.743008079223075, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2330/  500000 | consumed samples:        74560 | consumed tokens:    305397760 | elapsed time per iteration (ms): 6759.6 | learning rate: 1.398E-04 | global batch size:    32 | lm loss: 1.118331E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2331/  500000 | consumed samples:        74592 | consumed tokens:    305528832 | elapsed time per iteration (ms): 6757.6 | learning rate: 1.399E-04 | global batch size:    32 | lm loss: 1.040654E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     2332/  500000 | consumed samples:        74624 | consumed tokens:    305659904 | elapsed time per iteration (ms): 6754.7 | learning rate: 1.399E-04 | global batch size:    32 | lm loss: 1.116131E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.75 |
time (ms)
 iteration     2333/  500000 | consumed samples:        74656 | consumed tokens:    305790976 | elapsed time per iteration (ms): 6756.5 | learning rate: 1.400E-04 | global batch size:    32 | lm loss: 1.091848E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     2334/  500000 | consumed samples:        74688 | consumed tokens:    305922048 | elapsed time per iteration (ms): 6756.9 | learning rate: 1.400E-04 | global batch size:    32 | lm loss: 1.082274E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     2335/  500000 | consumed samples:        74720 | consumed tokens:    306053120 | elapsed time per iteration (ms): 6760.0 | learning rate: 1.401E-04 | global batch size:    32 | lm loss: 1.085335E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2336/  500000 | consumed samples:        74752 | consumed tokens:    306184192 | elapsed time per iteration (ms): 6758.1 | learning rate: 1.402E-04 | global batch size:    32 | lm loss: 1.074397E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2337/  500000 | consumed samples:        74784 | consumed tokens:    306315264 | elapsed time per iteration (ms): 6763.1 | learning rate: 1.402E-04 | global batch size:    32 | lm loss: 1.090054E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration     2338/  500000 | consumed samples:        74816 | consumed tokens:    306446336 | elapsed time per iteration (ms): 6762.9 | learning rate: 1.403E-04 | global batch size:    32 | lm loss: 1.122448E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     2339/  500000 | consumed samples:        74848 | consumed tokens:    306577408 | elapsed time per iteration (ms): 6758.4 | learning rate: 1.403E-04 | global batch size:    32 | lm loss: 1.096498E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
[2023-10-10 19:34:11,290] [INFO] [logging.py:96:log_dist] [Rank 0] step=2340, skipped=0, lr=[0.0001404], mom=[(0.9, 0.95)]
[2023-10-10 19:34:11,548] [INFO] [timer.py:208:stop] epoch=0/micro_step=2340/global_step=2340, RunningAvgSamplesPerSec=4.742791115314709, CurrSamplesPerSec=4.744242506933826, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2340/  500000 | consumed samples:        74880 | consumed tokens:    306708480 | elapsed time per iteration (ms): 6757.7 | learning rate: 1.404E-04 | global batch size:    32 | lm loss: 1.043085E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     2341/  500000 | consumed samples:        74912 | consumed tokens:    306839552 | elapsed time per iteration (ms): 6756.8 | learning rate: 1.405E-04 | global batch size:    32 | lm loss: 1.108124E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     2342/  500000 | consumed samples:        74944 | consumed tokens:    306970624 | elapsed time per iteration (ms): 6761.7 | learning rate: 1.405E-04 | global batch size:    32 | lm loss: 1.077707E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     2343/  500000 | consumed samples:        74976 | consumed tokens:    307101696 | elapsed time per iteration (ms): 6759.0 | learning rate: 1.406E-04 | global batch size:    32 | lm loss: 1.050467E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2344/  500000 | consumed samples:        75008 | consumed tokens:    307232768 | elapsed time per iteration (ms): 6760.2 | learning rate: 1.406E-04 | global batch size:    32 | lm loss: 1.028747E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2345/  500000 | consumed samples:        75040 | consumed tokens:    307363840 | elapsed time per iteration (ms): 6763.9 | learning rate: 1.407E-04 | global batch size:    32 | lm loss: 1.078836E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     2346/  500000 | consumed samples:        75072 | consumed tokens:    307494912 | elapsed time per iteration (ms): 6764.3 | learning rate: 1.408E-04 | global batch size:    32 | lm loss: 1.125713E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     2347/  500000 | consumed samples:        75104 | consumed tokens:    307625984 | elapsed time per iteration (ms): 6764.4 | learning rate: 1.408E-04 | global batch size:    32 | lm loss: 1.091812E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.54 |
time (ms)
 iteration     2348/  500000 | consumed samples:        75136 | consumed tokens:    307757056 | elapsed time per iteration (ms): 6764.1 | learning rate: 1.409E-04 | global batch size:    32 | lm loss: 1.106892E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     2349/  500000 | consumed samples:        75168 | consumed tokens:    307888128 | elapsed time per iteration (ms): 6761.1 | learning rate: 1.409E-04 | global batch size:    32 | lm loss: 1.129713E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
[2023-10-10 19:35:18,962] [INFO] [logging.py:96:log_dist] [Rank 0] step=2350, skipped=0, lr=[0.00014099999999999998], mom=[(0.9, 0.95)]
[2023-10-10 19:35:19,209] [INFO] [timer.py:208:stop] epoch=0/micro_step=2350/global_step=2350, RunningAvgSamplesPerSec=4.742788105423797, CurrSamplesPerSec=4.741023076548649, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2350/  500000 | consumed samples:        75200 | consumed tokens:    308019200 | elapsed time per iteration (ms): 6762.7 | learning rate: 1.410E-04 | global batch size:    32 | lm loss: 1.050276E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     2351/  500000 | consumed samples:        75232 | consumed tokens:    308150272 | elapsed time per iteration (ms): 6761.0 | learning rate: 1.411E-04 | global batch size:    32 | lm loss: 1.056677E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2352/  500000 | consumed samples:        75264 | consumed tokens:    308281344 | elapsed time per iteration (ms): 6759.0 | learning rate: 1.411E-04 | global batch size:    32 | lm loss: 1.099202E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2353/  500000 | consumed samples:        75296 | consumed tokens:    308412416 | elapsed time per iteration (ms): 6760.0 | learning rate: 1.412E-04 | global batch size:    32 | lm loss: 1.076350E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2354/  500000 | consumed samples:        75328 | consumed tokens:    308543488 | elapsed time per iteration (ms): 6768.5 | learning rate: 1.412E-04 | global batch size:    32 | lm loss: 1.083936E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.728 | TFLOPs: 147.45 |
time (ms)
 iteration     2355/  500000 | consumed samples:        75360 | consumed tokens:    308674560 | elapsed time per iteration (ms): 6759.4 | learning rate: 1.413E-04 | global batch size:    32 | lm loss: 1.093962E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2356/  500000 | consumed samples:        75392 | consumed tokens:    308805632 | elapsed time per iteration (ms): 6763.2 | learning rate: 1.414E-04 | global batch size:    32 | lm loss: 1.092825E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration     2357/  500000 | consumed samples:        75424 | consumed tokens:    308936704 | elapsed time per iteration (ms): 6761.4 | learning rate: 1.414E-04 | global batch size:    32 | lm loss: 1.086365E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2358/  500000 | consumed samples:        75456 | consumed tokens:    309067776 | elapsed time per iteration (ms): 6758.3 | learning rate: 1.415E-04 | global batch size:    32 | lm loss: 1.093133E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2359/  500000 | consumed samples:        75488 | consumed tokens:    309198848 | elapsed time per iteration (ms): 6759.8 | learning rate: 1.415E-04 | global batch size:    32 | lm loss: 1.081731E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
[2023-10-10 19:36:26,606] [INFO] [logging.py:96:log_dist] [Rank 0] step=2360, skipped=0, lr=[0.0001416], mom=[(0.9, 0.95)]
[2023-10-10 19:36:26,868] [INFO] [timer.py:208:stop] epoch=0/micro_step=2360/global_step=2360, RunningAvgSamplesPerSec=4.742784327235978, CurrSamplesPerSec=4.740522062449506, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2360/  500000 | consumed samples:        75520 | consumed tokens:    309329920 | elapsed time per iteration (ms): 6764.0 | learning rate: 1.416E-04 | global batch size:    32 | lm loss: 1.087948E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     2361/  500000 | consumed samples:        75552 | consumed tokens:    309460992 | elapsed time per iteration (ms): 6759.9 | learning rate: 1.417E-04 | global batch size:    32 | lm loss: 1.091735E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2362/  500000 | consumed samples:        75584 | consumed tokens:    309592064 | elapsed time per iteration (ms): 6760.0 | learning rate: 1.417E-04 | global batch size:    32 | lm loss: 1.049442E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2363/  500000 | consumed samples:        75616 | consumed tokens:    309723136 | elapsed time per iteration (ms): 6765.3 | learning rate: 1.418E-04 | global batch size:    32 | lm loss: 1.094129E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration     2364/  500000 | consumed samples:        75648 | consumed tokens:    309854208 | elapsed time per iteration (ms): 6758.3 | learning rate: 1.418E-04 | global batch size:    32 | lm loss: 1.065781E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2365/  500000 | consumed samples:        75680 | consumed tokens:    309985280 | elapsed time per iteration (ms): 6761.1 | learning rate: 1.419E-04 | global batch size:    32 | lm loss: 1.054618E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2366/  500000 | consumed samples:        75712 | consumed tokens:    310116352 | elapsed time per iteration (ms): 6759.4 | learning rate: 1.420E-04 | global batch size:    32 | lm loss: 1.123218E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2367/  500000 | consumed samples:        75744 | consumed tokens:    310247424 | elapsed time per iteration (ms): 6761.3 | learning rate: 1.420E-04 | global batch size:    32 | lm loss: 1.081801E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2368/  500000 | consumed samples:        75776 | consumed tokens:    310378496 | elapsed time per iteration (ms): 6761.8 | learning rate: 1.421E-04 | global batch size:    32 | lm loss: 1.115644E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     2369/  500000 | consumed samples:        75808 | consumed tokens:    310509568 | elapsed time per iteration (ms): 6760.0 | learning rate: 1.421E-04 | global batch size:    32 | lm loss: 1.096185E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
[2023-10-10 19:37:34,268] [INFO] [logging.py:96:log_dist] [Rank 0] step=2370, skipped=0, lr=[0.0001422], mom=[(0.9, 0.95)]
[2023-10-10 19:37:34,519] [INFO] [timer.py:208:stop] epoch=0/micro_step=2370/global_step=2370, RunningAvgSamplesPerSec=4.7427820979374715, CurrSamplesPerSec=4.741206629606302, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2370/  500000 | consumed samples:        75840 | consumed tokens:    310640640 | elapsed time per iteration (ms): 6762.2 | learning rate: 1.422E-04 | global batch size:    32 | lm loss: 1.152516E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2371/  500000 | consumed samples:        75872 | consumed tokens:    310771712 | elapsed time per iteration (ms): 6762.2 | learning rate: 1.423E-04 | global batch size:    32 | lm loss: 1.076875E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2372/  500000 | consumed samples:        75904 | consumed tokens:    310902784 | elapsed time per iteration (ms): 6763.7 | learning rate: 1.423E-04 | global batch size:    32 | lm loss: 1.126596E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     2373/  500000 | consumed samples:        75936 | consumed tokens:    311033856 | elapsed time per iteration (ms): 6756.3 | learning rate: 1.424E-04 | global batch size:    32 | lm loss: 1.150220E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     2374/  500000 | consumed samples:        75968 | consumed tokens:    311164928 | elapsed time per iteration (ms): 6762.4 | learning rate: 1.424E-04 | global batch size:    32 | lm loss: 1.090985E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2375/  500000 | consumed samples:        76000 | consumed tokens:    311296000 | elapsed time per iteration (ms): 6763.3 | learning rate: 1.425E-04 | global batch size:    32 | lm loss: 1.142456E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration     2376/  500000 | consumed samples:        76032 | consumed tokens:    311427072 | elapsed time per iteration (ms): 6762.0 | learning rate: 1.426E-04 | global batch size:    32 | lm loss: 1.070233E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     2377/  500000 | consumed samples:        76064 | consumed tokens:    311558144 | elapsed time per iteration (ms): 6763.9 | learning rate: 1.426E-04 | global batch size:    32 | lm loss: 1.121481E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     2378/  500000 | consumed samples:        76096 | consumed tokens:    311689216 | elapsed time per iteration (ms): 6759.8 | learning rate: 1.427E-04 | global batch size:    32 | lm loss: 1.147013E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2379/  500000 | consumed samples:        76128 | consumed tokens:    311820288 | elapsed time per iteration (ms): 6765.4 | learning rate: 1.427E-04 | global batch size:    32 | lm loss: 1.119412E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
[2023-10-10 19:38:41,928] [INFO] [logging.py:96:log_dist] [Rank 0] step=2380, skipped=0, lr=[0.0001428], mom=[(0.9, 0.95)]
[2023-10-10 19:38:42,184] [INFO] [timer.py:208:stop] epoch=0/micro_step=2380/global_step=2380, RunningAvgSamplesPerSec=4.742775767761797, CurrSamplesPerSec=4.740209986875379, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2380/  500000 | consumed samples:        76160 | consumed tokens:    311951360 | elapsed time per iteration (ms): 6764.0 | learning rate: 1.428E-04 | global batch size:    32 | lm loss: 1.086164E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     2381/  500000 | consumed samples:        76192 | consumed tokens:    312082432 | elapsed time per iteration (ms): 6760.6 | learning rate: 1.429E-04 | global batch size:    32 | lm loss: 1.140975E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2382/  500000 | consumed samples:        76224 | consumed tokens:    312213504 | elapsed time per iteration (ms): 6761.7 | learning rate: 1.429E-04 | global batch size:    32 | lm loss: 1.116362E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     2383/  500000 | consumed samples:        76256 | consumed tokens:    312344576 | elapsed time per iteration (ms): 6765.8 | learning rate: 1.430E-04 | global batch size:    32 | lm loss: 1.103293E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.51 |
time (ms)
 iteration     2384/  500000 | consumed samples:        76288 | consumed tokens:    312475648 | elapsed time per iteration (ms): 6767.9 | learning rate: 1.430E-04 | global batch size:    32 | lm loss: 1.101784E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.728 | TFLOPs: 147.47 |
time (ms)
 iteration     2385/  500000 | consumed samples:        76320 | consumed tokens:    312606720 | elapsed time per iteration (ms): 6763.3 | learning rate: 1.431E-04 | global batch size:    32 | lm loss: 1.066644E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration     2386/  500000 | consumed samples:        76352 | consumed tokens:    312737792 | elapsed time per iteration (ms): 6764.0 | learning rate: 1.432E-04 | global batch size:    32 | lm loss: 1.107583E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     2387/  500000 | consumed samples:        76384 | consumed tokens:    312868864 | elapsed time per iteration (ms): 6760.7 | learning rate: 1.432E-04 | global batch size:    32 | lm loss: 1.106684E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2388/  500000 | consumed samples:        76416 | consumed tokens:    312999936 | elapsed time per iteration (ms): 6761.4 | learning rate: 1.433E-04 | global batch size:    32 | lm loss: 1.081789E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2389/  500000 | consumed samples:        76448 | consumed tokens:    313131008 | elapsed time per iteration (ms): 6764.1 | learning rate: 1.433E-04 | global batch size:    32 | lm loss: 1.086028E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
[2023-10-10 19:39:49,598] [INFO] [logging.py:96:log_dist] [Rank 0] step=2390, skipped=0, lr=[0.0001434], mom=[(0.9, 0.95)]
[2023-10-10 19:39:49,856] [INFO] [timer.py:208:stop] epoch=0/micro_step=2390/global_step=2390, RunningAvgSamplesPerSec=4.742768146091281, CurrSamplesPerSec=4.743655977261451, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2390/  500000 | consumed samples:        76480 | consumed tokens:    313262080 | elapsed time per iteration (ms): 6758.4 | learning rate: 1.434E-04 | global batch size:    32 | lm loss: 1.099283E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2391/  500000 | consumed samples:        76512 | consumed tokens:    313393152 | elapsed time per iteration (ms): 6757.6 | learning rate: 1.435E-04 | global batch size:    32 | lm loss: 1.081275E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     2392/  500000 | consumed samples:        76544 | consumed tokens:    313524224 | elapsed time per iteration (ms): 6760.6 | learning rate: 1.435E-04 | global batch size:    32 | lm loss: 1.081161E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2393/  500000 | consumed samples:        76576 | consumed tokens:    313655296 | elapsed time per iteration (ms): 6761.3 | learning rate: 1.436E-04 | global batch size:    32 | lm loss: 1.096419E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2394/  500000 | consumed samples:        76608 | consumed tokens:    313786368 | elapsed time per iteration (ms): 6756.7 | learning rate: 1.436E-04 | global batch size:    32 | lm loss: 1.058860E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     2395/  500000 | consumed samples:        76640 | consumed tokens:    313917440 | elapsed time per iteration (ms): 6758.1 | learning rate: 1.437E-04 | global batch size:    32 | lm loss: 1.070366E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2396/  500000 | consumed samples:        76672 | consumed tokens:    314048512 | elapsed time per iteration (ms): 6758.8 | learning rate: 1.438E-04 | global batch size:    32 | lm loss: 1.107426E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2397/  500000 | consumed samples:        76704 | consumed tokens:    314179584 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.438E-04 | global batch size:    32 | lm loss: 1.080786E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2398/  500000 | consumed samples:        76736 | consumed tokens:    314310656 | elapsed time per iteration (ms): 6763.0 | learning rate: 1.439E-04 | global batch size:    32 | lm loss: 1.076229E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration     2399/  500000 | consumed samples:        76768 | consumed tokens:    314441728 | elapsed time per iteration (ms): 6759.2 | learning rate: 1.439E-04 | global batch size:    32 | lm loss: 1.063756E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
[2023-10-10 19:40:57,245] [INFO] [logging.py:96:log_dist] [Rank 0] step=2400, skipped=0, lr=[0.000144], mom=[(0.9, 0.95)]
[2023-10-10 19:40:57,493] [INFO] [timer.py:208:stop] epoch=0/micro_step=2400/global_step=2400, RunningAvgSamplesPerSec=4.742769085373845, CurrSamplesPerSec=4.742004647681322, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2400/  500000 | consumed samples:        76800 | consumed tokens:    314572800 | elapsed time per iteration (ms): 6760.1 | learning rate: 1.440E-04 | global batch size:    32 | lm loss: 1.091128E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2401/  500000 | consumed samples:        76832 | consumed tokens:    314703872 | elapsed time per iteration (ms): 6761.1 | learning rate: 1.441E-04 | global batch size:    32 | lm loss: 1.086012E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2402/  500000 | consumed samples:        76864 | consumed tokens:    314834944 | elapsed time per iteration (ms): 6759.2 | learning rate: 1.441E-04 | global batch size:    32 | lm loss: 1.136867E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2403/  500000 | consumed samples:        76896 | consumed tokens:    314966016 | elapsed time per iteration (ms): 6760.0 | learning rate: 1.442E-04 | global batch size:    32 | lm loss: 1.126088E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2404/  500000 | consumed samples:        76928 | consumed tokens:    315097088 | elapsed time per iteration (ms): 6763.0 | learning rate: 1.442E-04 | global batch size:    32 | lm loss: 1.057505E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration     2405/  500000 | consumed samples:        76960 | consumed tokens:    315228160 | elapsed time per iteration (ms): 6760.1 | learning rate: 1.443E-04 | global batch size:    32 | lm loss: 1.094889E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2406/  500000 | consumed samples:        76992 | consumed tokens:    315359232 | elapsed time per iteration (ms): 6761.9 | learning rate: 1.444E-04 | global batch size:    32 | lm loss: 1.079987E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     2407/  500000 | consumed samples:        77024 | consumed tokens:    315490304 | elapsed time per iteration (ms): 6759.6 | learning rate: 1.444E-04 | global batch size:    32 | lm loss: 1.096104E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2408/  500000 | consumed samples:        77056 | consumed tokens:    315621376 | elapsed time per iteration (ms): 6758.9 | learning rate: 1.445E-04 | global batch size:    32 | lm loss: 1.073135E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2409/  500000 | consumed samples:        77088 | consumed tokens:    315752448 | elapsed time per iteration (ms): 6755.9 | learning rate: 1.445E-04 | global batch size:    32 | lm loss: 1.059977E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
[2023-10-10 19:42:04,878] [INFO] [logging.py:96:log_dist] [Rank 0] step=2410, skipped=0, lr=[0.0001446], mom=[(0.9, 0.95)]
[2023-10-10 19:42:05,136] [INFO] [timer.py:208:stop] epoch=0/micro_step=2410/global_step=2410, RunningAvgSamplesPerSec=4.742769126486316, CurrSamplesPerSec=4.742318467657544, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2410/  500000 | consumed samples:        77120 | consumed tokens:    315883520 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.446E-04 | global batch size:    32 | lm loss: 1.105268E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2411/  500000 | consumed samples:        77152 | consumed tokens:    316014592 | elapsed time per iteration (ms): 6764.0 | learning rate: 1.447E-04 | global batch size:    32 | lm loss: 1.092929E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     2412/  500000 | consumed samples:        77184 | consumed tokens:    316145664 | elapsed time per iteration (ms): 6765.7 | learning rate: 1.447E-04 | global batch size:    32 | lm loss: 1.102076E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration     2413/  500000 | consumed samples:        77216 | consumed tokens:    316276736 | elapsed time per iteration (ms): 6760.1 | learning rate: 1.448E-04 | global batch size:    32 | lm loss: 1.093578E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2414/  500000 | consumed samples:        77248 | consumed tokens:    316407808 | elapsed time per iteration (ms): 6764.1 | learning rate: 1.448E-04 | global batch size:    32 | lm loss: 1.060002E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     2415/  500000 | consumed samples:        77280 | consumed tokens:    316538880 | elapsed time per iteration (ms): 6758.3 | learning rate: 1.449E-04 | global batch size:    32 | lm loss: 1.099973E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2416/  500000 | consumed samples:        77312 | consumed tokens:    316669952 | elapsed time per iteration (ms): 6759.0 | learning rate: 1.450E-04 | global batch size:    32 | lm loss: 1.117312E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2417/  500000 | consumed samples:        77344 | consumed tokens:    316801024 | elapsed time per iteration (ms): 6760.0 | learning rate: 1.450E-04 | global batch size:    32 | lm loss: 1.092234E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2418/  500000 | consumed samples:        77376 | consumed tokens:    316932096 | elapsed time per iteration (ms): 6757.4 | learning rate: 1.451E-04 | global batch size:    32 | lm loss: 1.108452E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     2419/  500000 | consumed samples:        77408 | consumed tokens:    317063168 | elapsed time per iteration (ms): 6762.0 | learning rate: 1.451E-04 | global batch size:    32 | lm loss: 1.111161E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
[2023-10-10 19:43:12,529] [INFO] [logging.py:96:log_dist] [Rank 0] step=2420, skipped=0, lr=[0.0001452], mom=[(0.9, 0.95)]
[2023-10-10 19:43:12,791] [INFO] [timer.py:208:stop] epoch=0/micro_step=2420/global_step=2420, RunningAvgSamplesPerSec=4.74276593636117, CurrSamplesPerSec=4.740655008409136, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2420/  500000 | consumed samples:        77440 | consumed tokens:    317194240 | elapsed time per iteration (ms): 6762.3 | learning rate: 1.452E-04 | global batch size:    32 | lm loss: 1.084115E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2421/  500000 | consumed samples:        77472 | consumed tokens:    317325312 | elapsed time per iteration (ms): 6759.5 | learning rate: 1.453E-04 | global batch size:    32 | lm loss: 1.136935E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2422/  500000 | consumed samples:        77504 | consumed tokens:    317456384 | elapsed time per iteration (ms): 6762.7 | learning rate: 1.453E-04 | global batch size:    32 | lm loss: 1.123391E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     2423/  500000 | consumed samples:        77536 | consumed tokens:    317587456 | elapsed time per iteration (ms): 6760.2 | learning rate: 1.454E-04 | global batch size:    32 | lm loss: 1.090066E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2424/  500000 | consumed samples:        77568 | consumed tokens:    317718528 | elapsed time per iteration (ms): 6756.7 | learning rate: 1.454E-04 | global batch size:    32 | lm loss: 1.080511E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     2425/  500000 | consumed samples:        77600 | consumed tokens:    317849600 | elapsed time per iteration (ms): 6760.7 | learning rate: 1.455E-04 | global batch size:    32 | lm loss: 1.053006E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2426/  500000 | consumed samples:        77632 | consumed tokens:    317980672 | elapsed time per iteration (ms): 6764.9 | learning rate: 1.456E-04 | global batch size:    32 | lm loss: 1.099941E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration     2427/  500000 | consumed samples:        77664 | consumed tokens:    318111744 | elapsed time per iteration (ms): 6760.0 | learning rate: 1.456E-04 | global batch size:    32 | lm loss: 1.075999E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2428/  500000 | consumed samples:        77696 | consumed tokens:    318242816 | elapsed time per iteration (ms): 6759.2 | learning rate: 1.457E-04 | global batch size:    32 | lm loss: 1.071794E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2429/  500000 | consumed samples:        77728 | consumed tokens:    318373888 | elapsed time per iteration (ms): 6755.7 | learning rate: 1.457E-04 | global batch size:    32 | lm loss: 1.088240E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
[2023-10-10 19:44:20,181] [INFO] [logging.py:96:log_dist] [Rank 0] step=2430, skipped=0, lr=[0.0001458], mom=[(0.9, 0.95)]
[2023-10-10 19:44:20,429] [INFO] [timer.py:208:stop] epoch=0/micro_step=2430/global_step=2430, RunningAvgSamplesPerSec=4.7427670586078365, CurrSamplesPerSec=4.745337314270392, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2430/  500000 | consumed samples:        77760 | consumed tokens:    318504960 | elapsed time per iteration (ms): 6755.9 | learning rate: 1.458E-04 | global batch size:    32 | lm loss: 1.068089E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration     2431/  500000 | consumed samples:        77792 | consumed tokens:    318636032 | elapsed time per iteration (ms): 6761.8 | learning rate: 1.459E-04 | global batch size:    32 | lm loss: 1.109625E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     2432/  500000 | consumed samples:        77824 | consumed tokens:    318767104 | elapsed time per iteration (ms): 6762.7 | learning rate: 1.459E-04 | global batch size:    32 | lm loss: 1.096855E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     2433/  500000 | consumed samples:        77856 | consumed tokens:    318898176 | elapsed time per iteration (ms): 6765.0 | learning rate: 1.460E-04 | global batch size:    32 | lm loss: 1.071007E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration     2434/  500000 | consumed samples:        77888 | consumed tokens:    319029248 | elapsed time per iteration (ms): 6767.8 | learning rate: 1.460E-04 | global batch size:    32 | lm loss: 1.067979E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.728 | TFLOPs: 147.47 |
time (ms)
 iteration     2435/  500000 | consumed samples:        77920 | consumed tokens:    319160320 | elapsed time per iteration (ms): 6764.9 | learning rate: 1.461E-04 | global batch size:    32 | lm loss: 1.083709E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
 iteration     2436/  500000 | consumed samples:        77952 | consumed tokens:    319291392 | elapsed time per iteration (ms): 6766.0 | learning rate: 1.462E-04 | global batch size:    32 | lm loss: 1.102095E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.51 |
time (ms)
 iteration     2437/  500000 | consumed samples:        77984 | consumed tokens:    319422464 | elapsed time per iteration (ms): 6762.1 | learning rate: 1.462E-04 | global batch size:    32 | lm loss: 1.064660E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2438/  500000 | consumed samples:        78016 | consumed tokens:    319553536 | elapsed time per iteration (ms): 6761.6 | learning rate: 1.463E-04 | global batch size:    32 | lm loss: 1.097458E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     2439/  500000 | consumed samples:        78048 | consumed tokens:    319684608 | elapsed time per iteration (ms): 6766.7 | learning rate: 1.463E-04 | global batch size:    32 | lm loss: 1.076103E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.49 |
time (ms)
[2023-10-10 19:45:27,865] [INFO] [logging.py:96:log_dist] [Rank 0] step=2440, skipped=0, lr=[0.0001464], mom=[(0.9, 0.95)]
[2023-10-10 19:45:28,118] [INFO] [timer.py:208:stop] epoch=0/micro_step=2440/global_step=2440, RunningAvgSamplesPerSec=4.742756292701895, CurrSamplesPerSec=4.737648301985681, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2440/  500000 | consumed samples:        78080 | consumed tokens:    319815680 | elapsed time per iteration (ms): 6767.9 | learning rate: 1.464E-04 | global batch size:    32 | lm loss: 1.100056E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.728 | TFLOPs: 147.47 |
time (ms)
 iteration     2441/  500000 | consumed samples:        78112 | consumed tokens:    319946752 | elapsed time per iteration (ms): 6759.9 | learning rate: 1.465E-04 | global batch size:    32 | lm loss: 1.089450E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2442/  500000 | consumed samples:        78144 | consumed tokens:    320077824 | elapsed time per iteration (ms): 6760.5 | learning rate: 1.465E-04 | global batch size:    32 | lm loss: 1.065180E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2443/  500000 | consumed samples:        78176 | consumed tokens:    320208896 | elapsed time per iteration (ms): 6762.6 | learning rate: 1.466E-04 | global batch size:    32 | lm loss: 1.091634E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     2444/  500000 | consumed samples:        78208 | consumed tokens:    320339968 | elapsed time per iteration (ms): 6764.5 | learning rate: 1.466E-04 | global batch size:    32 | lm loss: 1.086465E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.54 |
time (ms)
 iteration     2445/  500000 | consumed samples:        78240 | consumed tokens:    320471040 | elapsed time per iteration (ms): 6760.9 | learning rate: 1.467E-04 | global batch size:    32 | lm loss: 1.088011E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2446/  500000 | consumed samples:        78272 | consumed tokens:    320602112 | elapsed time per iteration (ms): 6761.4 | learning rate: 1.468E-04 | global batch size:    32 | lm loss: 1.085033E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2447/  500000 | consumed samples:        78304 | consumed tokens:    320733184 | elapsed time per iteration (ms): 6756.3 | learning rate: 1.468E-04 | global batch size:    32 | lm loss: 1.084874E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     2448/  500000 | consumed samples:        78336 | consumed tokens:    320864256 | elapsed time per iteration (ms): 6758.1 | learning rate: 1.469E-04 | global batch size:    32 | lm loss: 1.086765E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2449/  500000 | consumed samples:        78368 | consumed tokens:    320995328 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.469E-04 | global batch size:    32 | lm loss: 1.108330E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
[2023-10-10 19:46:35,508] [INFO] [logging.py:96:log_dist] [Rank 0] step=2450, skipped=0, lr=[0.000147], mom=[(0.9, 0.95)]
[2023-10-10 19:46:35,765] [INFO] [timer.py:208:stop] epoch=0/micro_step=2450/global_step=2450, RunningAvgSamplesPerSec=4.74275465040498, CurrSamplesPerSec=4.74192791638803, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2450/  500000 | consumed samples:        78400 | consumed tokens:    321126400 | elapsed time per iteration (ms): 6760.9 | learning rate: 1.470E-04 | global batch size:    32 | lm loss: 1.061789E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2451/  500000 | consumed samples:        78432 | consumed tokens:    321257472 | elapsed time per iteration (ms): 6758.4 | learning rate: 1.471E-04 | global batch size:    32 | lm loss: 1.097055E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2452/  500000 | consumed samples:        78464 | consumed tokens:    321388544 | elapsed time per iteration (ms): 6761.3 | learning rate: 1.471E-04 | global batch size:    32 | lm loss: 1.102030E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2453/  500000 | consumed samples:        78496 | consumed tokens:    321519616 | elapsed time per iteration (ms): 6763.1 | learning rate: 1.472E-04 | global batch size:    32 | lm loss: 1.087748E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration     2454/  500000 | consumed samples:        78528 | consumed tokens:    321650688 | elapsed time per iteration (ms): 6759.8 | learning rate: 1.472E-04 | global batch size:    32 | lm loss: 1.095976E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2455/  500000 | consumed samples:        78560 | consumed tokens:    321781760 | elapsed time per iteration (ms): 6759.9 | learning rate: 1.473E-04 | global batch size:    32 | lm loss: 1.094560E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2456/  500000 | consumed samples:        78592 | consumed tokens:    321912832 | elapsed time per iteration (ms): 6756.9 | learning rate: 1.474E-04 | global batch size:    32 | lm loss: 1.093972E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     2457/  500000 | consumed samples:        78624 | consumed tokens:    322043904 | elapsed time per iteration (ms): 6757.7 | learning rate: 1.474E-04 | global batch size:    32 | lm loss: 1.076900E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     2458/  500000 | consumed samples:        78656 | consumed tokens:    322174976 | elapsed time per iteration (ms): 6757.7 | learning rate: 1.475E-04 | global batch size:    32 | lm loss: 1.084684E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     2459/  500000 | consumed samples:        78688 | consumed tokens:    322306048 | elapsed time per iteration (ms): 6758.6 | learning rate: 1.475E-04 | global batch size:    32 | lm loss: 1.094470E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
[2023-10-10 19:47:43,142] [INFO] [logging.py:96:log_dist] [Rank 0] step=2460, skipped=0, lr=[0.0001476], mom=[(0.9, 0.95)]
[2023-10-10 19:47:43,400] [INFO] [timer.py:208:stop] epoch=0/micro_step=2460/global_step=2460, RunningAvgSamplesPerSec=4.7427566651169215, CurrSamplesPerSec=4.743051658014744, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2460/  500000 | consumed samples:        78720 | consumed tokens:    322437120 | elapsed time per iteration (ms): 6759.2 | learning rate: 1.476E-04 | global batch size:    32 | lm loss: 1.083030E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2461/  500000 | consumed samples:        78752 | consumed tokens:    322568192 | elapsed time per iteration (ms): 6758.3 | learning rate: 1.477E-04 | global batch size:    32 | lm loss: 1.086295E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2462/  500000 | consumed samples:        78784 | consumed tokens:    322699264 | elapsed time per iteration (ms): 6759.7 | learning rate: 1.477E-04 | global batch size:    32 | lm loss: 1.094300E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2463/  500000 | consumed samples:        78816 | consumed tokens:    322830336 | elapsed time per iteration (ms): 6756.8 | learning rate: 1.478E-04 | global batch size:    32 | lm loss: 1.079105E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     2464/  500000 | consumed samples:        78848 | consumed tokens:    322961408 | elapsed time per iteration (ms): 6761.2 | learning rate: 1.478E-04 | global batch size:    32 | lm loss: 1.105766E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2465/  500000 | consumed samples:        78880 | consumed tokens:    323092480 | elapsed time per iteration (ms): 6760.5 | learning rate: 1.479E-04 | global batch size:    32 | lm loss: 1.085444E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2466/  500000 | consumed samples:        78912 | consumed tokens:    323223552 | elapsed time per iteration (ms): 6757.8 | learning rate: 1.480E-04 | global batch size:    32 | lm loss: 1.100823E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     2467/  500000 | consumed samples:        78944 | consumed tokens:    323354624 | elapsed time per iteration (ms): 6757.9 | learning rate: 1.480E-04 | global batch size:    32 | lm loss: 1.093344E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     2468/  500000 | consumed samples:        78976 | consumed tokens:    323485696 | elapsed time per iteration (ms): 6757.5 | learning rate: 1.481E-04 | global batch size:    32 | lm loss: 1.084009E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     2469/  500000 | consumed samples:        79008 | consumed tokens:    323616768 | elapsed time per iteration (ms): 6764.1 | learning rate: 1.481E-04 | global batch size:    32 | lm loss: 1.070606E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
[2023-10-10 19:48:50,784] [INFO] [logging.py:96:log_dist] [Rank 0] step=2470, skipped=0, lr=[0.00014819999999999997], mom=[(0.9, 0.95)]
[2023-10-10 19:48:51,039] [INFO] [timer.py:208:stop] epoch=0/micro_step=2470/global_step=2470, RunningAvgSamplesPerSec=4.742757999996177, CurrSamplesPerSec=4.740630394425924, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2470/  500000 | consumed samples:        79040 | consumed tokens:    323747840 | elapsed time per iteration (ms): 6762.7 | learning rate: 1.482E-04 | global batch size:    32 | lm loss: 1.084335E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     2471/  500000 | consumed samples:        79072 | consumed tokens:    323878912 | elapsed time per iteration (ms): 6758.6 | learning rate: 1.483E-04 | global batch size:    32 | lm loss: 1.077866E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2472/  500000 | consumed samples:        79104 | consumed tokens:    324009984 | elapsed time per iteration (ms): 6760.8 | learning rate: 1.483E-04 | global batch size:    32 | lm loss: 1.088577E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2473/  500000 | consumed samples:        79136 | consumed tokens:    324141056 | elapsed time per iteration (ms): 6764.5 | learning rate: 1.484E-04 | global batch size:    32 | lm loss: 1.043672E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.54 |
time (ms)
 iteration     2474/  500000 | consumed samples:        79168 | consumed tokens:    324272128 | elapsed time per iteration (ms): 6762.4 | learning rate: 1.484E-04 | global batch size:    32 | lm loss: 1.078054E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2475/  500000 | consumed samples:        79200 | consumed tokens:    324403200 | elapsed time per iteration (ms): 6759.2 | learning rate: 1.485E-04 | global batch size:    32 | lm loss: 1.097530E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2476/  500000 | consumed samples:        79232 | consumed tokens:    324534272 | elapsed time per iteration (ms): 6765.4 | learning rate: 1.486E-04 | global batch size:    32 | lm loss: 1.133216E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration     2477/  500000 | consumed samples:        79264 | consumed tokens:    324665344 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.486E-04 | global batch size:    32 | lm loss: 1.077792E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2478/  500000 | consumed samples:        79296 | consumed tokens:    324796416 | elapsed time per iteration (ms): 6761.6 | learning rate: 1.487E-04 | global batch size:    32 | lm loss: 1.086132E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2479/  500000 | consumed samples:        79328 | consumed tokens:    324927488 | elapsed time per iteration (ms): 6760.7 | learning rate: 1.487E-04 | global batch size:    32 | lm loss: 1.062262E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
[2023-10-10 19:49:58,444] [INFO] [logging.py:96:log_dist] [Rank 0] step=2480, skipped=0, lr=[0.00014879999999999998], mom=[(0.9, 0.95)]
[2023-10-10 19:49:58,698] [INFO] [timer.py:208:stop] epoch=0/micro_step=2480/global_step=2480, RunningAvgSamplesPerSec=4.742753762339613, CurrSamplesPerSec=4.741878829767025, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2480/  500000 | consumed samples:        79360 | consumed tokens:    325058560 | elapsed time per iteration (ms): 6761.8 | learning rate: 1.488E-04 | global batch size:    32 | lm loss: 1.087865E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     2481/  500000 | consumed samples:        79392 | consumed tokens:    325189632 | elapsed time per iteration (ms): 6759.4 | learning rate: 1.489E-04 | global batch size:    32 | lm loss: 1.107463E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2482/  500000 | consumed samples:        79424 | consumed tokens:    325320704 | elapsed time per iteration (ms): 6760.9 | learning rate: 1.489E-04 | global batch size:    32 | lm loss: 1.086688E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2483/  500000 | consumed samples:        79456 | consumed tokens:    325451776 | elapsed time per iteration (ms): 6759.4 | learning rate: 1.490E-04 | global batch size:    32 | lm loss: 1.088348E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2484/  500000 | consumed samples:        79488 | consumed tokens:    325582848 | elapsed time per iteration (ms): 6758.0 | learning rate: 1.490E-04 | global batch size:    32 | lm loss: 1.085986E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2485/  500000 | consumed samples:        79520 | consumed tokens:    325713920 | elapsed time per iteration (ms): 6761.9 | learning rate: 1.491E-04 | global batch size:    32 | lm loss: 1.076936E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     2486/  500000 | consumed samples:        79552 | consumed tokens:    325844992 | elapsed time per iteration (ms): 6763.0 | learning rate: 1.492E-04 | global batch size:    32 | lm loss: 1.111468E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     2487/  500000 | consumed samples:        79584 | consumed tokens:    325976064 | elapsed time per iteration (ms): 6756.7 | learning rate: 1.492E-04 | global batch size:    32 | lm loss: 1.082379E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     2488/  500000 | consumed samples:        79616 | consumed tokens:    326107136 | elapsed time per iteration (ms): 6758.4 | learning rate: 1.493E-04 | global batch size:    32 | lm loss: 1.093157E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2489/  500000 | consumed samples:        79648 | consumed tokens:    326238208 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.493E-04 | global batch size:    32 | lm loss: 1.083944E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
[2023-10-10 19:51:06,083] [INFO] [logging.py:96:log_dist] [Rank 0] step=2490, skipped=0, lr=[0.00014939999999999997], mom=[(0.9, 0.95)]
[2023-10-10 19:51:06,342] [INFO] [timer.py:208:stop] epoch=0/micro_step=2490/global_step=2490, RunningAvgSamplesPerSec=4.742755884849686, CurrSamplesPerSec=4.743678778449875, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2490/  500000 | consumed samples:        79680 | consumed tokens:    326369280 | elapsed time per iteration (ms): 6759.2 | learning rate: 1.494E-04 | global batch size:    32 | lm loss: 1.076430E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2491/  500000 | consumed samples:        79712 | consumed tokens:    326500352 | elapsed time per iteration (ms): 6760.0 | learning rate: 1.495E-04 | global batch size:    32 | lm loss: 1.113960E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2492/  500000 | consumed samples:        79744 | consumed tokens:    326631424 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.495E-04 | global batch size:    32 | lm loss: 1.076328E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2493/  500000 | consumed samples:        79776 | consumed tokens:    326762496 | elapsed time per iteration (ms): 6761.7 | learning rate: 1.496E-04 | global batch size:    32 | lm loss: 1.036603E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.60 |
time (ms)
 iteration     2494/  500000 | consumed samples:        79808 | consumed tokens:    326893568 | elapsed time per iteration (ms): 6761.8 | learning rate: 1.496E-04 | global batch size:    32 | lm loss: 1.077260E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     2495/  500000 | consumed samples:        79840 | consumed tokens:    327024640 | elapsed time per iteration (ms): 6756.6 | learning rate: 1.497E-04 | global batch size:    32 | lm loss: 1.069045E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     2496/  500000 | consumed samples:        79872 | consumed tokens:    327155712 | elapsed time per iteration (ms): 6759.8 | learning rate: 1.498E-04 | global batch size:    32 | lm loss: 1.098817E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2497/  500000 | consumed samples:        79904 | consumed tokens:    327286784 | elapsed time per iteration (ms): 6757.2 | learning rate: 1.498E-04 | global batch size:    32 | lm loss: 1.093539E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     2498/  500000 | consumed samples:        79936 | consumed tokens:    327417856 | elapsed time per iteration (ms): 6764.7 | learning rate: 1.499E-04 | global batch size:    32 | lm loss: 1.083934E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.54 |
time (ms)
 iteration     2499/  500000 | consumed samples:        79968 | consumed tokens:    327548928 | elapsed time per iteration (ms): 6762.6 | learning rate: 1.499E-04 | global batch size:    32 | lm loss: 1.099484E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
[2023-10-10 19:52:13,732] [INFO] [logging.py:96:log_dist] [Rank 0] step=2500, skipped=0, lr=[0.00015], mom=[(0.9, 0.95)]
[2023-10-10 19:52:13,992] [INFO] [timer.py:208:stop] epoch=0/micro_step=2500/global_step=2500, RunningAvgSamplesPerSec=4.742753138336702, CurrSamplesPerSec=4.740250668218193, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2500/  500000 | consumed samples:        80000 | consumed tokens:    327680000 | elapsed time per iteration (ms): 6763.5 | learning rate: 1.500E-04 | global batch size:    32 | lm loss: 1.067905E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     2501/  500000 | consumed samples:        80032 | consumed tokens:    327811072 | elapsed time per iteration (ms): 6758.0 | learning rate: 1.501E-04 | global batch size:    32 | lm loss: 1.088407E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2502/  500000 | consumed samples:        80064 | consumed tokens:    327942144 | elapsed time per iteration (ms): 6760.9 | learning rate: 1.501E-04 | global batch size:    32 | lm loss: 1.089665E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2503/  500000 | consumed samples:        80096 | consumed tokens:    328073216 | elapsed time per iteration (ms): 6759.2 | learning rate: 1.502E-04 | global batch size:    32 | lm loss: 1.117304E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2504/  500000 | consumed samples:        80128 | consumed tokens:    328204288 | elapsed time per iteration (ms): 6761.6 | learning rate: 1.502E-04 | global batch size:    32 | lm loss: 1.086056E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2505/  500000 | consumed samples:        80160 | consumed tokens:    328335360 | elapsed time per iteration (ms): 6761.4 | learning rate: 1.503E-04 | global batch size:    32 | lm loss: 1.083669E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2506/  500000 | consumed samples:        80192 | consumed tokens:    328466432 | elapsed time per iteration (ms): 6763.8 | learning rate: 1.504E-04 | global batch size:    32 | lm loss: 1.105009E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     2507/  500000 | consumed samples:        80224 | consumed tokens:    328597504 | elapsed time per iteration (ms): 6764.1 | learning rate: 1.504E-04 | global batch size:    32 | lm loss: 1.026038E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     2508/  500000 | consumed samples:        80256 | consumed tokens:    328728576 | elapsed time per iteration (ms): 6762.4 | learning rate: 1.505E-04 | global batch size:    32 | lm loss: 1.115730E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2509/  500000 | consumed samples:        80288 | consumed tokens:    328859648 | elapsed time per iteration (ms): 6762.9 | learning rate: 1.505E-04 | global batch size:    32 | lm loss: 1.087792E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
[2023-10-10 19:53:21,399] [INFO] [logging.py:96:log_dist] [Rank 0] step=2510, skipped=0, lr=[0.00015059999999999997], mom=[(0.9, 0.95)]
[2023-10-10 19:53:21,654] [INFO] [timer.py:208:stop] epoch=0/micro_step=2510/global_step=2510, RunningAvgSamplesPerSec=4.7427479994309225, CurrSamplesPerSec=4.739689561675822, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2510/  500000 | consumed samples:        80320 | consumed tokens:    328990720 | elapsed time per iteration (ms): 6764.3 | learning rate: 1.506E-04 | global batch size:    32 | lm loss: 1.083242E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     2511/  500000 | consumed samples:        80352 | consumed tokens:    329121792 | elapsed time per iteration (ms): 6758.2 | learning rate: 1.507E-04 | global batch size:    32 | lm loss: 1.076200E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2512/  500000 | consumed samples:        80384 | consumed tokens:    329252864 | elapsed time per iteration (ms): 6757.1 | learning rate: 1.507E-04 | global batch size:    32 | lm loss: 1.121380E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     2513/  500000 | consumed samples:        80416 | consumed tokens:    329383936 | elapsed time per iteration (ms): 6762.1 | learning rate: 1.508E-04 | global batch size:    32 | lm loss: 1.099410E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2514/  500000 | consumed samples:        80448 | consumed tokens:    329515008 | elapsed time per iteration (ms): 6759.7 | learning rate: 1.508E-04 | global batch size:    32 | lm loss: 1.070395E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2515/  500000 | consumed samples:        80480 | consumed tokens:    329646080 | elapsed time per iteration (ms): 6754.6 | learning rate: 1.509E-04 | global batch size:    32 | lm loss: 1.082196E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.738 | TFLOPs: 147.76 |
time (ms)
 iteration     2516/  500000 | consumed samples:        80512 | consumed tokens:    329777152 | elapsed time per iteration (ms): 6759.8 | learning rate: 1.510E-04 | global batch size:    32 | lm loss: 1.076035E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2517/  500000 | consumed samples:        80544 | consumed tokens:    329908224 | elapsed time per iteration (ms): 6758.5 | learning rate: 1.510E-04 | global batch size:    32 | lm loss: 1.081409E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2518/  500000 | consumed samples:        80576 | consumed tokens:    330039296 | elapsed time per iteration (ms): 6757.4 | learning rate: 1.511E-04 | global batch size:    32 | lm loss: 1.074518E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     2519/  500000 | consumed samples:        80608 | consumed tokens:    330170368 | elapsed time per iteration (ms): 6763.4 | learning rate: 1.511E-04 | global batch size:    32 | lm loss: 1.099022E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
[2023-10-10 19:54:29,027] [INFO] [logging.py:96:log_dist] [Rank 0] step=2520, skipped=0, lr=[0.0001512], mom=[(0.9, 0.95)]
[2023-10-10 19:54:29,290] [INFO] [timer.py:208:stop] epoch=0/micro_step=2520/global_step=2520, RunningAvgSamplesPerSec=4.742751269110484, CurrSamplesPerSec=4.742124105488362, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2520/  500000 | consumed samples:        80640 | consumed tokens:    330301440 | elapsed time per iteration (ms): 6760.5 | learning rate: 1.512E-04 | global batch size:    32 | lm loss: 1.108598E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2521/  500000 | consumed samples:        80672 | consumed tokens:    330432512 | elapsed time per iteration (ms): 6758.0 | learning rate: 1.513E-04 | global batch size:    32 | lm loss: 1.075844E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2522/  500000 | consumed samples:        80704 | consumed tokens:    330563584 | elapsed time per iteration (ms): 6759.8 | learning rate: 1.513E-04 | global batch size:    32 | lm loss: 1.116829E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2523/  500000 | consumed samples:        80736 | consumed tokens:    330694656 | elapsed time per iteration (ms): 6760.2 | learning rate: 1.514E-04 | global batch size:    32 | lm loss: 1.075734E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2524/  500000 | consumed samples:        80768 | consumed tokens:    330825728 | elapsed time per iteration (ms): 6759.8 | learning rate: 1.514E-04 | global batch size:    32 | lm loss: 1.054313E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2525/  500000 | consumed samples:        80800 | consumed tokens:    330956800 | elapsed time per iteration (ms): 6759.0 | learning rate: 1.515E-04 | global batch size:    32 | lm loss: 1.073815E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2526/  500000 | consumed samples:        80832 | consumed tokens:    331087872 | elapsed time per iteration (ms): 6759.5 | learning rate: 1.516E-04 | global batch size:    32 | lm loss: 1.088165E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2527/  500000 | consumed samples:        80864 | consumed tokens:    331218944 | elapsed time per iteration (ms): 6763.1 | learning rate: 1.516E-04 | global batch size:    32 | lm loss: 1.077526E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration     2528/  500000 | consumed samples:        80896 | consumed tokens:    331350016 | elapsed time per iteration (ms): 6763.4 | learning rate: 1.517E-04 | global batch size:    32 | lm loss: 1.085442E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration     2529/  500000 | consumed samples:        80928 | consumed tokens:    331481088 | elapsed time per iteration (ms): 6761.8 | learning rate: 1.517E-04 | global batch size:    32 | lm loss: 1.080466E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
[2023-10-10 19:55:36,686] [INFO] [logging.py:96:log_dist] [Rank 0] step=2530, skipped=0, lr=[0.00015179999999999998], mom=[(0.9, 0.95)]
[2023-10-10 19:55:36,941] [INFO] [timer.py:208:stop] epoch=0/micro_step=2530/global_step=2530, RunningAvgSamplesPerSec=4.74275094127298, CurrSamplesPerSec=4.742460898327471, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2530/  500000 | consumed samples:        80960 | consumed tokens:    331612160 | elapsed time per iteration (ms): 6761.8 | learning rate: 1.518E-04 | global batch size:    32 | lm loss: 1.089743E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.60 |
time (ms)
 iteration     2531/  500000 | consumed samples:        80992 | consumed tokens:    331743232 | elapsed time per iteration (ms): 6763.4 | learning rate: 1.519E-04 | global batch size:    32 | lm loss: 1.087816E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.57 |
time (ms)
 iteration     2532/  500000 | consumed samples:        81024 | consumed tokens:    331874304 | elapsed time per iteration (ms): 6758.6 | learning rate: 1.519E-04 | global batch size:    32 | lm loss: 1.110591E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2533/  500000 | consumed samples:        81056 | consumed tokens:    332005376 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.520E-04 | global batch size:    32 | lm loss: 1.062581E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2534/  500000 | consumed samples:        81088 | consumed tokens:    332136448 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.520E-04 | global batch size:    32 | lm loss: 1.083607E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2535/  500000 | consumed samples:        81120 | consumed tokens:    332267520 | elapsed time per iteration (ms): 6756.4 | learning rate: 1.521E-04 | global batch size:    32 | lm loss: 1.066117E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     2536/  500000 | consumed samples:        81152 | consumed tokens:    332398592 | elapsed time per iteration (ms): 6757.7 | learning rate: 1.522E-04 | global batch size:    32 | lm loss: 1.089272E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     2537/  500000 | consumed samples:        81184 | consumed tokens:    332529664 | elapsed time per iteration (ms): 6758.4 | learning rate: 1.522E-04 | global batch size:    32 | lm loss: 1.090255E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2538/  500000 | consumed samples:        81216 | consumed tokens:    332660736 | elapsed time per iteration (ms): 6757.3 | learning rate: 1.523E-04 | global batch size:    32 | lm loss: 1.082794E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     2539/  500000 | consumed samples:        81248 | consumed tokens:    332791808 | elapsed time per iteration (ms): 6756.4 | learning rate: 1.523E-04 | global batch size:    32 | lm loss: 1.072281E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
[2023-10-10 19:56:44,312] [INFO] [logging.py:96:log_dist] [Rank 0] step=2540, skipped=0, lr=[0.0001524], mom=[(0.9, 0.95)]
[2023-10-10 19:56:44,569] [INFO] [timer.py:208:stop] epoch=0/micro_step=2540/global_step=2540, RunningAvgSamplesPerSec=4.742755005216805, CurrSamplesPerSec=4.74523111579412, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2540/  500000 | consumed samples:        81280 | consumed tokens:    332922880 | elapsed time per iteration (ms): 6757.9 | learning rate: 1.524E-04 | global batch size:    32 | lm loss: 1.064122E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     2541/  500000 | consumed samples:        81312 | consumed tokens:    333053952 | elapsed time per iteration (ms): 6759.8 | learning rate: 1.525E-04 | global batch size:    32 | lm loss: 1.065275E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2542/  500000 | consumed samples:        81344 | consumed tokens:    333185024 | elapsed time per iteration (ms): 6756.8 | learning rate: 1.525E-04 | global batch size:    32 | lm loss: 1.070397E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     2543/  500000 | consumed samples:        81376 | consumed tokens:    333316096 | elapsed time per iteration (ms): 6756.6 | learning rate: 1.526E-04 | global batch size:    32 | lm loss: 1.081883E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     2544/  500000 | consumed samples:        81408 | consumed tokens:    333447168 | elapsed time per iteration (ms): 6758.3 | learning rate: 1.526E-04 | global batch size:    32 | lm loss: 1.070150E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2545/  500000 | consumed samples:        81440 | consumed tokens:    333578240 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.527E-04 | global batch size:    32 | lm loss: 1.100103E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2546/  500000 | consumed samples:        81472 | consumed tokens:    333709312 | elapsed time per iteration (ms): 6760.6 | learning rate: 1.528E-04 | global batch size:    32 | lm loss: 1.062465E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2547/  500000 | consumed samples:        81504 | consumed tokens:    333840384 | elapsed time per iteration (ms): 6760.6 | learning rate: 1.528E-04 | global batch size:    32 | lm loss: 1.101503E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2548/  500000 | consumed samples:        81536 | consumed tokens:    333971456 | elapsed time per iteration (ms): 6758.9 | learning rate: 1.529E-04 | global batch size:    32 | lm loss: 1.098184E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2549/  500000 | consumed samples:        81568 | consumed tokens:    334102528 | elapsed time per iteration (ms): 6766.3 | learning rate: 1.529E-04 | global batch size:    32 | lm loss: 1.082986E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.729 | TFLOPs: 147.50 |
time (ms)
[2023-10-10 19:57:51,961] [INFO] [logging.py:96:log_dist] [Rank 0] step=2550, skipped=0, lr=[0.00015299999999999998], mom=[(0.9, 0.95)]
[2023-10-10 19:57:52,211] [INFO] [timer.py:208:stop] epoch=0/micro_step=2550/global_step=2550, RunningAvgSamplesPerSec=4.742756448150688, CurrSamplesPerSec=4.742795225095416, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2550/  500000 | consumed samples:        81600 | consumed tokens:    334233600 | elapsed time per iteration (ms): 6761.5 | learning rate: 1.530E-04 | global batch size:    32 | lm loss: 1.071242E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2551/  500000 | consumed samples:        81632 | consumed tokens:    334364672 | elapsed time per iteration (ms): 6756.8 | learning rate: 1.531E-04 | global batch size:    32 | lm loss: 1.107945E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     2552/  500000 | consumed samples:        81664 | consumed tokens:    334495744 | elapsed time per iteration (ms): 6761.5 | learning rate: 1.531E-04 | global batch size:    32 | lm loss: 1.056769E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2553/  500000 | consumed samples:        81696 | consumed tokens:    334626816 | elapsed time per iteration (ms): 6763.0 | learning rate: 1.532E-04 | global batch size:    32 | lm loss: 1.083434E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     2554/  500000 | consumed samples:        81728 | consumed tokens:    334757888 | elapsed time per iteration (ms): 6759.9 | learning rate: 1.532E-04 | global batch size:    32 | lm loss: 1.088409E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2555/  500000 | consumed samples:        81760 | consumed tokens:    334888960 | elapsed time per iteration (ms): 6761.4 | learning rate: 1.533E-04 | global batch size:    32 | lm loss: 1.069107E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2556/  500000 | consumed samples:        81792 | consumed tokens:    335020032 | elapsed time per iteration (ms): 6757.2 | learning rate: 1.534E-04 | global batch size:    32 | lm loss: 1.107249E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     2557/  500000 | consumed samples:        81824 | consumed tokens:    335151104 | elapsed time per iteration (ms): 6760.7 | learning rate: 1.534E-04 | global batch size:    32 | lm loss: 1.067966E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2558/  500000 | consumed samples:        81856 | consumed tokens:    335282176 | elapsed time per iteration (ms): 6760.5 | learning rate: 1.535E-04 | global batch size:    32 | lm loss: 1.065446E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2559/  500000 | consumed samples:        81888 | consumed tokens:    335413248 | elapsed time per iteration (ms): 6757.9 | learning rate: 1.535E-04 | global batch size:    32 | lm loss: 1.070838E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
[2023-10-10 19:58:59,593] [INFO] [logging.py:96:log_dist] [Rank 0] step=2560, skipped=0, lr=[0.0001536], mom=[(0.9, 0.95)]
[2023-10-10 19:58:59,852] [INFO] [timer.py:208:stop] epoch=0/micro_step=2560/global_step=2560, RunningAvgSamplesPerSec=4.742757694653743, CurrSamplesPerSec=4.742899973754944, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2560/  500000 | consumed samples:        81920 | consumed tokens:    335544320 | elapsed time per iteration (ms): 6759.7 | learning rate: 1.536E-04 | global batch size:    32 | lm loss: 1.064281E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2561/  500000 | consumed samples:        81952 | consumed tokens:    335675392 | elapsed time per iteration (ms): 6758.7 | learning rate: 1.537E-04 | global batch size:    32 | lm loss: 1.105373E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2562/  500000 | consumed samples:        81984 | consumed tokens:    335806464 | elapsed time per iteration (ms): 6756.7 | learning rate: 1.537E-04 | global batch size:    32 | lm loss: 1.042710E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     2563/  500000 | consumed samples:        82016 | consumed tokens:    335937536 | elapsed time per iteration (ms): 6759.2 | learning rate: 1.538E-04 | global batch size:    32 | lm loss: 1.062642E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2564/  500000 | consumed samples:        82048 | consumed tokens:    336068608 | elapsed time per iteration (ms): 6755.6 | learning rate: 1.538E-04 | global batch size:    32 | lm loss: 1.100437E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration     2565/  500000 | consumed samples:        82080 | consumed tokens:    336199680 | elapsed time per iteration (ms): 6762.3 | learning rate: 1.539E-04 | global batch size:    32 | lm loss: 1.086651E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2566/  500000 | consumed samples:        82112 | consumed tokens:    336330752 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.540E-04 | global batch size:    32 | lm loss: 1.095796E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2567/  500000 | consumed samples:        82144 | consumed tokens:    336461824 | elapsed time per iteration (ms): 6758.5 | learning rate: 1.540E-04 | global batch size:    32 | lm loss: 1.088832E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2568/  500000 | consumed samples:        82176 | consumed tokens:    336592896 | elapsed time per iteration (ms): 6767.7 | learning rate: 1.541E-04 | global batch size:    32 | lm loss: 1.084333E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.728 | TFLOPs: 147.47 |
time (ms)
 iteration     2569/  500000 | consumed samples:        82208 | consumed tokens:    336723968 | elapsed time per iteration (ms): 6768.5 | learning rate: 1.541E-04 | global batch size:    32 | lm loss: 1.106414E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.728 | TFLOPs: 147.45 |
time (ms)
[2023-10-10 20:00:07,251] [INFO] [logging.py:96:log_dist] [Rank 0] step=2570, skipped=0, lr=[0.00015419999999999998], mom=[(0.9, 0.95)]
[2023-10-10 20:00:07,499] [INFO] [timer.py:208:stop] epoch=0/micro_step=2570/global_step=2570, RunningAvgSamplesPerSec=4.742757446358746, CurrSamplesPerSec=4.743553039330559, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2570/  500000 | consumed samples:        82240 | consumed tokens:    336855040 | elapsed time per iteration (ms): 6758.3 | learning rate: 1.542E-04 | global batch size:    32 | lm loss: 1.043997E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2571/  500000 | consumed samples:        82272 | consumed tokens:    336986112 | elapsed time per iteration (ms): 6758.6 | learning rate: 1.543E-04 | global batch size:    32 | lm loss: 1.103614E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2572/  500000 | consumed samples:        82304 | consumed tokens:    337117184 | elapsed time per iteration (ms): 6759.4 | learning rate: 1.543E-04 | global batch size:    32 | lm loss: 1.067891E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2573/  500000 | consumed samples:        82336 | consumed tokens:    337248256 | elapsed time per iteration (ms): 6756.7 | learning rate: 1.544E-04 | global batch size:    32 | lm loss: 1.055743E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     2574/  500000 | consumed samples:        82368 | consumed tokens:    337379328 | elapsed time per iteration (ms): 6756.9 | learning rate: 1.544E-04 | global batch size:    32 | lm loss: 1.073975E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.71 |
time (ms)
 iteration     2575/  500000 | consumed samples:        82400 | consumed tokens:    337510400 | elapsed time per iteration (ms): 6760.4 | learning rate: 1.545E-04 | global batch size:    32 | lm loss: 1.062087E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2576/  500000 | consumed samples:        82432 | consumed tokens:    337641472 | elapsed time per iteration (ms): 6758.4 | learning rate: 1.546E-04 | global batch size:    32 | lm loss: 1.060000E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2577/  500000 | consumed samples:        82464 | consumed tokens:    337772544 | elapsed time per iteration (ms): 6761.4 | learning rate: 1.546E-04 | global batch size:    32 | lm loss: 1.074506E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2578/  500000 | consumed samples:        82496 | consumed tokens:    337903616 | elapsed time per iteration (ms): 6758.6 | learning rate: 1.547E-04 | global batch size:    32 | lm loss: 1.072337E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2579/  500000 | consumed samples:        82528 | consumed tokens:    338034688 | elapsed time per iteration (ms): 6757.7 | learning rate: 1.547E-04 | global batch size:    32 | lm loss: 1.051410E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
[2023-10-10 20:01:14,875] [INFO] [logging.py:96:log_dist] [Rank 0] step=2580, skipped=0, lr=[0.0001548], mom=[(0.9, 0.95)]
[2023-10-10 20:01:15,132] [INFO] [timer.py:208:stop] epoch=0/micro_step=2580/global_step=2580, RunningAvgSamplesPerSec=4.742759889386038, CurrSamplesPerSec=4.74013448549299, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2580/  500000 | consumed samples:        82560 | consumed tokens:    338165760 | elapsed time per iteration (ms): 6763.6 | learning rate: 1.548E-04 | global batch size:    32 | lm loss: 1.080864E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     2581/  500000 | consumed samples:        82592 | consumed tokens:    338296832 | elapsed time per iteration (ms): 6759.0 | learning rate: 1.549E-04 | global batch size:    32 | lm loss: 1.083106E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2582/  500000 | consumed samples:        82624 | consumed tokens:    338427904 | elapsed time per iteration (ms): 6756.6 | learning rate: 1.549E-04 | global batch size:    32 | lm loss: 1.069040E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.72 |
time (ms)
 iteration     2583/  500000 | consumed samples:        82656 | consumed tokens:    338558976 | elapsed time per iteration (ms): 6763.5 | learning rate: 1.550E-04 | global batch size:    32 | lm loss: 1.074554E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.56 |
time (ms)
 iteration     2584/  500000 | consumed samples:        82688 | consumed tokens:    338690048 | elapsed time per iteration (ms): 6758.1 | learning rate: 1.550E-04 | global batch size:    32 | lm loss: 1.088979E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2585/  500000 | consumed samples:        82720 | consumed tokens:    338821120 | elapsed time per iteration (ms): 6760.8 | learning rate: 1.551E-04 | global batch size:    32 | lm loss: 1.054171E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2586/  500000 | consumed samples:        82752 | consumed tokens:    338952192 | elapsed time per iteration (ms): 6755.7 | learning rate: 1.552E-04 | global batch size:    32 | lm loss: 1.059244E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.74 |
time (ms)
 iteration     2587/  500000 | consumed samples:        82784 | consumed tokens:    339083264 | elapsed time per iteration (ms): 6757.7 | learning rate: 1.552E-04 | global batch size:    32 | lm loss: 1.079631E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     2588/  500000 | consumed samples:        82816 | consumed tokens:    339214336 | elapsed time per iteration (ms): 6758.7 | learning rate: 1.553E-04 | global batch size:    32 | lm loss: 1.088081E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2589/  500000 | consumed samples:        82848 | consumed tokens:    339345408 | elapsed time per iteration (ms): 6762.2 | learning rate: 1.553E-04 | global batch size:    32 | lm loss: 1.075841E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
[2023-10-10 20:02:22,512] [INFO] [logging.py:96:log_dist] [Rank 0] step=2590, skipped=0, lr=[0.00015539999999999998], mom=[(0.9, 0.95)]
[2023-10-10 20:02:22,767] [INFO] [timer.py:208:stop] epoch=0/micro_step=2590/global_step=2590, RunningAvgSamplesPerSec=4.742761572648296, CurrSamplesPerSec=4.742310759888841, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2590/  500000 | consumed samples:        82880 | consumed tokens:    339476480 | elapsed time per iteration (ms): 6759.9 | learning rate: 1.554E-04 | global batch size:    32 | lm loss: 1.064188E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.64 |
time (ms)
 iteration     2591/  500000 | consumed samples:        82912 | consumed tokens:    339607552 | elapsed time per iteration (ms): 6759.5 | learning rate: 1.555E-04 | global batch size:    32 | lm loss: 1.090127E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2592/  500000 | consumed samples:        82944 | consumed tokens:    339738624 | elapsed time per iteration (ms): 6759.0 | learning rate: 1.555E-04 | global batch size:    32 | lm loss: 1.073002E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2593/  500000 | consumed samples:        82976 | consumed tokens:    339869696 | elapsed time per iteration (ms): 6756.0 | learning rate: 1.556E-04 | global batch size:    32 | lm loss: 1.084252E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.73 |
time (ms)
 iteration     2594/  500000 | consumed samples:        83008 | consumed tokens:    340000768 | elapsed time per iteration (ms): 6760.3 | learning rate: 1.556E-04 | global batch size:    32 | lm loss: 1.106956E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration     2595/  500000 | consumed samples:        83040 | consumed tokens:    340131840 | elapsed time per iteration (ms): 6760.5 | learning rate: 1.557E-04 | global batch size:    32 | lm loss: 1.039737E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.63 |
time (ms)
 iteration     2596/  500000 | consumed samples:        83072 | consumed tokens:    340262912 | elapsed time per iteration (ms): 6760.8 | learning rate: 1.558E-04 | global batch size:    32 | lm loss: 1.093148E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
 iteration     2597/  500000 | consumed samples:        83104 | consumed tokens:    340393984 | elapsed time per iteration (ms): 6764.0 | learning rate: 1.558E-04 | global batch size:    32 | lm loss: 1.098919E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.731 | TFLOPs: 147.55 |
time (ms)
 iteration     2598/  500000 | consumed samples:        83136 | consumed tokens:    340525056 | elapsed time per iteration (ms): 6762.8 | learning rate: 1.559E-04 | global batch size:    32 | lm loss: 1.078150E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.58 |
time (ms)
 iteration     2599/  500000 | consumed samples:        83168 | consumed tokens:    340656128 | elapsed time per iteration (ms): 6765.0 | learning rate: 1.559E-04 | global batch size:    32 | lm loss: 1.057744E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.53 |
time (ms)
[2023-10-10 20:03:30,184] [INFO] [logging.py:96:log_dist] [Rank 0] step=2600, skipped=0, lr=[0.00015599999999999997], mom=[(0.9, 0.95)]
[2023-10-10 20:03:30,422] [INFO] [timer.py:208:stop] epoch=0/micro_step=2600/global_step=2600, RunningAvgSamplesPerSec=4.74275720397641, CurrSamplesPerSec=4.738598529583255, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2600/  500000 | consumed samples:        83200 | consumed tokens:    340787200 | elapsed time per iteration (ms): 6765.8 | learning rate: 1.560E-04 | global batch size:    32 | lm loss: 1.088337E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.51 |
time (ms)
 iteration     2601/  500000 | consumed samples:        83232 | consumed tokens:    340918272 | elapsed time per iteration (ms): 6759.5 | learning rate: 1.561E-04 | global batch size:    32 | lm loss: 1.070263E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2602/  500000 | consumed samples:        83264 | consumed tokens:    341049344 | elapsed time per iteration (ms): 6759.3 | learning rate: 1.561E-04 | global batch size:    32 | lm loss: 1.095634E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2603/  500000 | consumed samples:        83296 | consumed tokens:    341180416 | elapsed time per iteration (ms): 6758.5 | learning rate: 1.562E-04 | global batch size:    32 | lm loss: 1.096131E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2604/  500000 | consumed samples:        83328 | consumed tokens:    341311488 | elapsed time per iteration (ms): 6759.5 | learning rate: 1.562E-04 | global batch size:    32 | lm loss: 1.028484E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2605/  500000 | consumed samples:        83360 | consumed tokens:    341442560 | elapsed time per iteration (ms): 6759.6 | learning rate: 1.563E-04 | global batch size:    32 | lm loss: 1.074274E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2606/  500000 | consumed samples:        83392 | consumed tokens:    341573632 | elapsed time per iteration (ms): 6761.4 | learning rate: 1.564E-04 | global batch size:    32 | lm loss: 1.073337E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2607/  500000 | consumed samples:        83424 | consumed tokens:    341704704 | elapsed time per iteration (ms): 6757.5 | learning rate: 1.564E-04 | global batch size:    32 | lm loss: 1.098746E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.69 |
time (ms)
 iteration     2608/  500000 | consumed samples:        83456 | consumed tokens:    341835776 | elapsed time per iteration (ms): 6763.2 | learning rate: 1.565E-04 | global batch size:    32 | lm loss: 1.055058E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration     2609/  500000 | consumed samples:        83488 | consumed tokens:    341966848 | elapsed time per iteration (ms): 6761.1 | learning rate: 1.565E-04 | global batch size:    32 | lm loss: 1.072279E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.62 |
time (ms)
[2023-10-10 20:04:37,813] [INFO] [logging.py:96:log_dist] [Rank 0] step=2610, skipped=0, lr=[0.00015659999999999998], mom=[(0.9, 0.95)]
[2023-10-10 20:04:38,063] [INFO] [timer.py:208:stop] epoch=0/micro_step=2610/global_step=2610, RunningAvgSamplesPerSec=4.7427577058294, CurrSamplesPerSec=4.7429418745143055, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2610/  500000 | consumed samples:        83520 | consumed tokens:    342097920 | elapsed time per iteration (ms): 6759.6 | learning rate: 1.566E-04 | global batch size:    32 | lm loss: 1.083401E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2611/  500000 | consumed samples:        83552 | consumed tokens:    342228992 | elapsed time per iteration (ms): 6758.0 | learning rate: 1.567E-04 | global batch size:    32 | lm loss: 1.112584E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2612/  500000 | consumed samples:        83584 | consumed tokens:    342360064 | elapsed time per iteration (ms): 6765.7 | learning rate: 1.567E-04 | global batch size:    32 | lm loss: 1.126180E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.730 | TFLOPs: 147.52 |
time (ms)
 iteration     2613/  500000 | consumed samples:        83616 | consumed tokens:    342491136 | elapsed time per iteration (ms): 6759.1 | learning rate: 1.568E-04 | global batch size:    32 | lm loss: 1.068748E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
 iteration     2614/  500000 | consumed samples:        83648 | consumed tokens:    342622208 | elapsed time per iteration (ms): 6762.3 | learning rate: 1.568E-04 | global batch size:    32 | lm loss: 1.067588E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.59 |
time (ms)
 iteration     2615/  500000 | consumed samples:        83680 | consumed tokens:    342753280 | elapsed time per iteration (ms): 6759.4 | learning rate: 1.569E-04 | global batch size:    32 | lm loss: 1.108473E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2616/  500000 | consumed samples:        83712 | consumed tokens:    342884352 | elapsed time per iteration (ms): 6758.0 | learning rate: 1.570E-04 | global batch size:    32 | lm loss: 1.053056E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2617/  500000 | consumed samples:        83744 | consumed tokens:    343015424 | elapsed time per iteration (ms): 6760.3 | learning rate: 1.570E-04 | global batch size:    32 | lm loss: 1.076563E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
 iteration     2618/  500000 | consumed samples:        83776 | consumed tokens:    343146496 | elapsed time per iteration (ms): 6763.1 | learning rate: 1.571E-04 | global batch size:    32 | lm loss: 1.076023E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.732 | TFLOPs: 147.57 |
time (ms)
 iteration     2619/  500000 | consumed samples:        83808 | consumed tokens:    343277568 | elapsed time per iteration (ms): 6760.3 | learning rate: 1.571E-04 | global batch size:    32 | lm loss: 1.085244E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.63 |
time (ms)
[2023-10-10 20:05:45,472] [INFO] [logging.py:96:log_dist] [Rank 0] step=2620, skipped=0, lr=[0.00015719999999999997], mom=[(0.9, 0.95)]
[2023-10-10 20:05:45,709] [INFO] [timer.py:208:stop] epoch=0/micro_step=2620/global_step=2620, RunningAvgSamplesPerSec=4.742757545133321, CurrSamplesPerSec=4.7440702889280315, MemAllocated=22.25GB, MaxMemAllocated=33.65GB
 iteration     2620/  500000 | consumed samples:        83840 | consumed tokens:    343408640 | elapsed time per iteration (ms): 6757.3 | learning rate: 1.572E-04 | global batch size:    32 | lm loss: 1.053842E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.736 | TFLOPs: 147.70 |
time (ms)
 iteration     2621/  500000 | consumed samples:        83872 | consumed tokens:    343539712 | elapsed time per iteration (ms): 6758.8 | learning rate: 1.573E-04 | global batch size:    32 | lm loss: 1.064721E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2622/  500000 | consumed samples:        83904 | consumed tokens:    343670784 | elapsed time per iteration (ms): 6755.7 | learning rate: 1.573E-04 | global batch size:    32 | lm loss: 1.078287E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.737 | TFLOPs: 147.73 |
time (ms)
 iteration     2623/  500000 | consumed samples:        83936 | consumed tokens:    343801856 | elapsed time per iteration (ms): 6758.2 | learning rate: 1.574E-04 | global batch size:    32 | lm loss: 1.064876E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.68 |
time (ms)
 iteration     2624/  500000 | consumed samples:        83968 | consumed tokens:    343932928 | elapsed time per iteration (ms): 6758.4 | learning rate: 1.574E-04 | global batch size:    32 | lm loss: 1.065929E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2625/  500000 | consumed samples:        84000 | consumed tokens:    344064000 | elapsed time per iteration (ms): 6761.4 | learning rate: 1.575E-04 | global batch size:    32 | lm loss: 1.096825E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.733 | TFLOPs: 147.61 |
time (ms)
 iteration     2626/  500000 | consumed samples:        84032 | consumed tokens:    344195072 | elapsed time per iteration (ms): 6758.9 | learning rate: 1.576E-04 | global batch size:    32 | lm loss: 1.092124E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.735 | TFLOPs: 147.67 |
time (ms)
 iteration     2627/  500000 | consumed samples:        84064 | consumed tokens:    344326144 | elapsed time per iteration (ms): 6759.5 | learning rate: 1.576E-04 | global batch size:    32 | lm loss: 1.068484E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.65 |
time (ms)
 iteration     2628/  500000 | consumed samples:        84096 | consumed tokens:    344457216 | elapsed time per iteration (ms): 6759.2 | learning rate: 1.577E-04 | global batch size:    32 | lm loss: 1.045203E-01 | loss scale: 1024.0 | actual seqlen:  4096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.734 | TFLOPs: 147.66 |
time (ms)
